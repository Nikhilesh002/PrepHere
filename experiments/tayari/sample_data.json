{
  "success": true,
  "questions": [
    {
      "_id": "677839235f4840fc45f6c8cc",
      "submissionId": {
        "_id": "677839235f4840fc45f6c8c8",
        "status": "approved",
        "adminComment": "Looks good!",
        "country": "India",
        "ctc": "40L-50L",
        "companyName": "Oportun",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735931682/kel8texignnwh4lzobb0.jpg"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Let's say you have a partitioned table, where one of the partition has huge amount of data and it is getting stuck. how do you handle this situation and what measures do you take?",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Spark partitions",
      "createdAt": "2025-01-03T19:23:15.878Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677839235f4840fc45f6c8cd",
      "submissionId": {
        "_id": "677839235f4840fc45f6c8c8",
        "status": "approved",
        "adminComment": "Looks good!",
        "country": "India",
        "ctc": "40L-50L",
        "companyName": "Oportun",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735931682/kel8texignnwh4lzobb0.jpg"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "How do you handle the CDC events during data ingestion? what are some of the best practices used?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " CDC events",
      "createdAt": "2025-01-03T19:23:15.878Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677839235f4840fc45f6c8ca",
      "submissionId": {
        "_id": "677839235f4840fc45f6c8c8",
        "status": "approved",
        "adminComment": "Looks good!",
        "country": "India",
        "ctc": "40L-50L",
        "companyName": "Oportun",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735931682/kel8texignnwh4lzobb0.jpg"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "create table samples (\nsample_date int,\nsample_time int,\ndevice_id int,\nsample_value int\n);\n \ninsert into samples (sample_date,sample_time,device_id,sample_value) values\n(20180701, 1010, 111, 11)\n,(20180701, 1011, 111, 12)\n,(20180701, 1012, 111, 13)\n,(20180701, 1013, 222, 11)\n,(20180701, 1014, 222, 11)\n,(20180701, 1015, 222, 12)\n,(20180701, 1016, 111, 12)\n,(20180701, 1017, 111, 11)\n,(20180701, 1018, 222, 13)\n,(20180701, 1019, 222, 12)\n,(20180701, 1020, 222, 13)\n,(20180701, 1021, 222, 12)\n,(20180701, 1022, 222, 12)\n,(20180701, 1023, 111, 12)\n,(20180701, 1024, 111, 13)\n,(20180701, 1025, 111, 13)\n,(20180701, 1026, 111, 12)\n,(20180701, 1027, 111, 13)\n,(20180701, 1028, 222, 14)\n,(20180701, 1029, 222, 13)\n,(20180701, 1030, 222, 14)\n,(20180701, 1031, 222, 14)\n,(20180701, 1032, 222, 14)\n,(20180701, 1033, 222, 14)\n,(20180701, 1034, 222, 14)\n,(20180701, 1035, 222, 14)\n,(20180701, 1036, 111, 13)\n,(20180701, 1037, 111, 13)\n,(20180701, 1038, 111, 14)\n,(20180701, 1039, 111, 13);\n \n  \nwrite sql to fetch rows with same device_id, same sample values and having sample_time values are consecutive\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Device Stats",
      "createdAt": "2025-01-03T19:23:15.877Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677839235f4840fc45f6c8cb",
      "submissionId": {
        "_id": "677839235f4840fc45f6c8c8",
        "status": "approved",
        "adminComment": "Looks good!",
        "country": "India",
        "ctc": "40L-50L",
        "companyName": "Oportun",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735931682/kel8texignnwh4lzobb0.jpg"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "find the top 5 employees who have the highest average sales per month in the last year (from the current date), considering only those employees who have made at least 10 sales during that period. Include the employee name, average monthly sales amount, and the total number of sales for each employee.\ntables:\nemployees (employee_id, employee_name)\nsales (sale_id, employee_id, sale_date, amount)\n \nemployee_id employee_name\n1\tJohn Smith\n2\tAlice Johnson\n3\tBob Williams\n4\tEva Brown\n5\tMichael Davis\n6\tSarah Wilson\n7\tDavid Garcia\n8\tLinda Rodriguez\nsale_id   employee_id  sale_date amount\n1\t1\t2023-08-15\t1500\n2\t1\t2023-09-20\t2000\n3\t1\t2023-10-10\t1800\n4\t1\t2023-11-05\t2200\n5\t1\t2023-12-12\t1900\n6\t1\t2024-01-18\t2100\n7\t1\t2024-02-25\t2300\n8\t1\t2024-03-01\t1700\n9\t1\t2024-04-07\t2400\n10\t1\t2024-05-14\t2000\n11\t1\t2024-06-21\t1800\n12\t1\t2024-07-28\t2500\n13\t2\t2023-09-01\t1000\n14\t2\t2023-10-05\t1200\n15\t2\t2023-11-10\t1500\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Highest average sales",
      "createdAt": "2025-01-03T19:23:15.877Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67783b1b5f4840fc45f6c8d6",
      "submissionId": {
        "_id": "67783b1b5f4840fc45f6c8d3",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "40L-50L",
        "companyName": "EPAM Systems",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735932372/laiiw94musa3a3pvh0sn.png"
        ],
        "yoe": "12-15",
        "role": "Data Architect"
      },
      "text": "Find the companies who have at least 2 users who speak both English and German in\npyspark\n\nData:\ndata = [(A, 1, English),\n(A, 1, German),\n(A, 2, English),\n(A, 2, German),\n(A, 3, German),\n(B, 1, English),\n(B, 2, German),\n(C, 1, English),\n(C, 2, German)]\n\nschema =(company_id, user_id, language)",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Languages spoken",
      "createdAt": "2025-01-03T19:31:39.698Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67783b1b5f4840fc45f6c8d7",
      "submissionId": {
        "_id": "67783b1b5f4840fc45f6c8d3",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "40L-50L",
        "companyName": "EPAM Systems",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735932372/laiiw94musa3a3pvh0sn.png"
        ],
        "yoe": "12-15",
        "role": "Data Architect"
      },
      "text": "what are some of the files generated when a spark job is executed and what info does they contain?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Spark files",
      "createdAt": "2025-01-03T19:31:39.698Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67783b1b5f4840fc45f6c8d5",
      "submissionId": {
        "_id": "67783b1b5f4840fc45f6c8d3",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "40L-50L",
        "companyName": "EPAM Systems",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735932372/laiiw94musa3a3pvh0sn.png"
        ],
        "yoe": "12-15",
        "role": "Data Architect"
      },
      "text": "Load records into the respective file based on the filename value and add the category\ncount for each file\n\nInput file:\nID, Name, catgry, fileName\n101,emp1, A, abc.txt\n102,emp2, B, bbc.txt\n103,emp3, C, abc.txt\n104,emp4, A, bbc.txt\n105,emp5, C, abc.txt\noutput files:\nabc.txt\n101,emp1, A\n103,emp3, C\n105,emp5, C\nA:1,B:0,c:2\nbbc.txt\n102,emp2, B\n104,emp4, A\nA:1, B:1,c:0",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Filename category",
      "createdAt": "2025-01-03T19:31:39.698Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67783bdc5f4840fc45f6c8e1",
      "submissionId": {
        "_id": "67783bdc5f4840fc45f6c8dd",
        "status": "approved",
        "adminComment": "Approved!!",
        "country": "India",
        "ctc": "50L-60L",
        "companyName": "Persistent Systems",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735932753/epphi7wvjemudcv753zx.png"
        ],
        "yoe": "12-15",
        "role": "Data Architect"
      },
      "text": "How do you execute notebook based on the file arrival?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Notebook execution",
      "createdAt": "2025-01-03T19:34:52.706Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67783bdc5f4840fc45f6c8e0",
      "submissionId": {
        "_id": "67783bdc5f4840fc45f6c8dd",
        "status": "approved",
        "adminComment": "Approved!!",
        "country": "India",
        "ctc": "50L-60L",
        "companyName": "Persistent Systems",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735932753/epphi7wvjemudcv753zx.png"
        ],
        "yoe": "12-15",
        "role": "Data Architect"
      },
      "text": "Write a Pyspark code to convert the following input dataframe into output dataframe?\n\nInput Structure:\nID | customerID\n1 12\n1 23\n1 34\n1 54\n2 45\n2 60\n\nOutput Structure:\nID customerID\n1 [12,23,34,54]\n2 [45,60]",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Pyspark dataframe",
      "createdAt": "2025-01-03T19:34:52.706Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67783bdc5f4840fc45f6c8df",
      "submissionId": {
        "_id": "67783bdc5f4840fc45f6c8dd",
        "status": "approved",
        "adminComment": "Approved!!",
        "country": "India",
        "ctc": "50L-60L",
        "companyName": "Persistent Systems",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735932753/epphi7wvjemudcv753zx.png"
        ],
        "yoe": "12-15",
        "role": "Data Architect"
      },
      "text": "Need to fix matches between country but there should not be no repetition match.\n\nInput:\n\nIndia\nPaksitan\nAustralia\nNew Zealand\n\nOutput:\nIndia vs Pakistan\nIndia Vs Australia\nIndia vs new Zealand\nPakistan vs Australia\nPakistan vs New Zealand\nAustralia vs New Zealand",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Match Fix",
      "createdAt": "2025-01-03T19:34:52.705Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677843f25f4840fc45f6c8f2",
      "submissionId": {
        "_id": "677843f25f4840fc45f6c8ed",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "The Math Co",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735934755/vqofwzqe0rb7tihtip56.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "1. what are init scripts\n2. difference between job cluster and normal cluster\n3. difference between data lake and delta lake\n4. what is unity catlog\n",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Spark Theory",
      "createdAt": "2025-01-03T20:09:22.579Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677843f25f4840fc45f6c8f0",
      "submissionId": {
        "_id": "677843f25f4840fc45f6c8ed",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "The Math Co",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735934755/vqofwzqe0rb7tihtip56.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "given schema with tables customers(cid,name) products(pid,pname,price) and sales(saleid,cid,pid,product,qty,store)\n1. find names of customer who have not made any purchase\n2. write query to find top 2 customers with the highest total order amount\n3. find the name of product with the lowest quantity\n\n\n\ncid name\n1 Alice\n2 Bob\n3 Carol\n4 David\n5 Eve\n\npid pname price\n101 Laptop 1200\n102 Mouse 25\n103 Keyboard 75\n104 Monitor 300\n105 Webcam 50\n\nsaleid cid pid qty store\n1 1 101 1 Store A\n2 1 102 2 Store B\n3 2 103 1 Store A\n4 2 101 1 Store C\n5 1 104 1 Store B\n6 3 102 5 Store A\n7 3 105 2 Store C\n8 1 103 1 Store A\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Sales stats",
      "createdAt": "2025-01-03T20:09:22.578Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677843f25f4840fc45f6c8ef",
      "submissionId": {
        "_id": "677843f25f4840fc45f6c8ed",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "The Math Co",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735934755/vqofwzqe0rb7tihtip56.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "python function to sort array\n2)given this input i= [0,1,0,5,4,0]\n#op: [1,4,5,0,0,0]\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Sort array",
      "createdAt": "2025-01-03T20:09:22.578Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677843f25f4840fc45f6c8f1",
      "submissionId": {
        "_id": "677843f25f4840fc45f6c8ed",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "The Math Co",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735934755/vqofwzqe0rb7tihtip56.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "given some json data and Find out the value of category_name.\n\nj={'invalid_data': {'gtin': []}, 'valid_data': [{'brand_name': 'SHEBA', 'category': {'category_name': 'CAT FOOD', 'segments_name': 'CAT TREATS', 'subcategory_name': 'CAT TREATS'} }] }\n",
      "images": [],
      "category": "scenario based",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " json parsing",
      "createdAt": "2025-01-03T20:09:22.579Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67784a795f4840fc45f6ca35",
      "submissionId": {
        "_id": "67784a795f4840fc45f6ca32",
        "status": "approved",
        "adminComment": "approved!",
        "country": "India",
        "ctc": "50L-60L",
        "companyName": "Databricks",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735936481/yiiu0weljlszuyrvdrzy.jpg"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "You have 2 tables namely tbl_a and tbl_b. Perform left join, inner join, full outer join on both the tables and give me the results when tbl_a data is selected\n\nTbl_a : 1 , 2, 1 NULL\n\nTbl_b: 1, 1, NULL ",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": "SQL Joins ",
      "createdAt": "2025-01-03T20:37:13.823Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67784a795f4840fc45f6ca36",
      "submissionId": {
        "_id": "67784a795f4840fc45f6ca32",
        "status": "approved",
        "adminComment": "approved!",
        "country": "India",
        "ctc": "50L-60L",
        "companyName": "Databricks",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735936481/yiiu0weljlszuyrvdrzy.jpg"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Find the max length of the substring which doesn't have any repeating characters for a given string \"str\"\n\nEX. Str=\"abcbdcab\" output: len=4 (\"dcab\")\nStr=\"bbbbb\" output: len=1 (\"b\") ",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Max substring length",
      "createdAt": "2025-01-03T20:37:13.823Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67784a795f4840fc45f6ca34",
      "submissionId": {
        "_id": "67784a795f4840fc45f6ca32",
        "status": "approved",
        "adminComment": "approved!",
        "country": "India",
        "ctc": "50L-60L",
        "companyName": "Databricks",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735936481/yiiu0weljlszuyrvdrzy.jpg"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Given two tables, Customers and Products, find all customers who spent less in the current month than they did in the previous month.\n\nSchema:\n\n    Customers:\n        Customer_id (INT, Primary Key)\n        User_name (VARCHAR)\n        City (VARCHAR)\n    Products:\n        customer_id (INT, Foreign Key referencing Customers.Customer_id)\n        product_id (INT)\n        purchase_date (DATE)\n        Money_spent (DECIMAL)\n\nSample Data:\n\nCustomers Table:\nCustomer_id\tUser_name\tCity\n1\t   Alice\tNew York\n2\tBob\tLos Angeles\n3\tCarol\tChicago\n4\tDavid\tHouston\n\nProducts Table:\ncustomer_id\tproduct_id\tpurchase_date\tMoney_spent\n1\t101\t2023-10-15\t100\n1\t102\t2023-10-20\t50\n1\t103\t2023-11-05\t75\n1\t104\t2023-11-10\t25\n2\t201\t2023-10-01\t200\n2\t202\t2023-11-15\t150\n3\t301\t2023-10-25\t30\n3\t302\t2023-11-20\t40\n4\t401\t2023-10-01\t100\n4\t402\t2023-11-15\t200\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Money spent less",
      "createdAt": "2025-01-03T20:37:13.823Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6778b9e85f4840fc45f6cc7a",
      "submissionId": {
        "_id": "6778b9e85f4840fc45f6cc78",
        "status": "approved",
        "adminComment": "We are delighted to inform you that your recent interview submission has been thoroughly reviewed and approved!  ",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "HCLTech",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735964416/uiwhtc6jgxufeg8ewqox.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "You are given two tables, TableA and TableB. Perform the following SQL operations and explain the results:\n\nTable1\tTable2\n1\t1\n1\t1\n1\t2\n2\t3\nNULL\t3\n4\tNULL",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " SQL Joins",
      "createdAt": "2025-01-04T04:32:40.752Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6778b9e85f4840fc45f6cc7b",
      "submissionId": {
        "_id": "6778b9e85f4840fc45f6cc78",
        "status": "approved",
        "adminComment": "We are delighted to inform you that your recent interview submission has been thoroughly reviewed and approved!  ",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "HCLTech",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735964416/uiwhtc6jgxufeg8ewqox.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "\nSaleID\tCustomerID\tProductID\tSaleAmount\tSaleDate\n1\t101\t201\t500\t2024-02-01\n2\t102\t202\t1500\t2024-05-15\n3\t101\t203\t700\t2024-08-03\n4\t103\t201\t200\t2024-10-19\n5\t101\t201\t300\t2024-01-07\n6\t104\t202\t1200\t2024-03-25\n7\t103\t203\t400\t2024-07-11\nFind the productID which was sold more than other products last 6 months?",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Product Sales",
      "createdAt": "2025-01-04T04:32:40.752Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6778b9e85f4840fc45f6cc7c",
      "submissionId": {
        "_id": "6778b9e85f4840fc45f6cc78",
        "status": "approved",
        "adminComment": "We are delighted to inform you that your recent interview submission has been thoroughly reviewed and approved!  ",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "HCLTech",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735964416/uiwhtc6jgxufeg8ewqox.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "You are given a table Employee with a column FullName that contains names in the format \"First Last\". Some names only have a first name, and others have both a first and a last name. Write an SQL query to:\n\nSplit the FullName into two separate columns:\nFirstName (everything before the first space).\nLastName (everything after the first space, or NULL if there is no second name).\nEmployee Table\nEmployeeID\tFullName\n1\tJohn Doe\n2\tAlice Johnson\n3\tBob\n4\tCarol Lee",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "User Names",
      "createdAt": "2025-01-04T04:32:40.752Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6778bc6f5f4840fc45f6cd3f",
      "submissionId": {
        "_id": "6778bc6f5f4840fc45f6cd3d",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Tiger Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735965303/ncqsx4uhb7dpb3yjfdhg.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write a Python function find_missing_number that takes a list of integers from 1 to n with one missing number, where n is the length of the list plus one. The function should return the missing number.\n\nExample:\npython\nfind_missing_number([1, 2, 4, 6, 3, 7, 8])",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Missing number",
      "createdAt": "2025-01-04T04:43:27.936Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6778bc6f5f4840fc45f6cd40",
      "submissionId": {
        "_id": "6778bc6f5f4840fc45f6cd3d",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Tiger Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735965303/ncqsx4uhb7dpb3yjfdhg.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Difference between where and group by in SQL?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " GroupBy function",
      "createdAt": "2025-01-04T04:43:27.936Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6778bc6f5f4840fc45f6cd41",
      "submissionId": {
        "_id": "6778bc6f5f4840fc45f6cd3d",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Tiger Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735965303/ncqsx4uhb7dpb3yjfdhg.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Is it possible to do window function without partition by or order by?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Window function",
      "createdAt": "2025-01-04T04:43:27.936Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6778bc6f5f4840fc45f6cd42",
      "submissionId": {
        "_id": "6778bc6f5f4840fc45f6cd3d",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Tiger Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735965303/ncqsx4uhb7dpb3yjfdhg.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Difference between count(*), count(1), count(column)?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Count() function",
      "createdAt": "2025-01-04T04:43:27.936Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6778bc6f5f4840fc45f6cd43",
      "submissionId": {
        "_id": "6778bc6f5f4840fc45f6cd3d",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Tiger Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735965303/ncqsx4uhb7dpb3yjfdhg.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Question:\nYou are given two tables, Orders and Products. The Orders table records each order made by a customer, and the Products table records product details.\n\nTables:\nOrders Table:\n\nOrderID\tCustomerID\tProductID\tOrderDate\tQuantity\n1\t101\t201\t2023-01-10\t2\n2\t102\t202\t2023-01-15\t1\n3\t101\t203\t2023-02-05\t3\n4\t103\t201\t2023-03-20\t4\n5\t104\t202\t2023-02-25\t1\nProducts Table:\n\nProductID\tProductName\tPrice\n201\tProduct A\t500\n202\tProduct B\t1500\n203\tProduct C\t700\nTask:\nWrite an SQL query to find the total revenue generated by each product in the first quarter of 2023 (from January 1, 2023, to March 31, 2023).\n\nReturn the following columns:\n\nProductID\nProductName\nTotalRevenue\nThe result should be sorted by TotalRevenue in descending order.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": "Revenue Generated ",
      "createdAt": "2025-01-04T04:43:27.936Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6778bc6f5f4840fc45f6cd44",
      "submissionId": {
        "_id": "6778bc6f5f4840fc45f6cd3d",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Tiger Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735965303/ncqsx4uhb7dpb3yjfdhg.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Question:\nYou are given two tables, Employees and Departments. The Employees table contains information about employees, including their department, and the Departments table contains information about each department.\n\nTables:\nEmployees Table:\n\nEmployeeID\tEmployeeName\tDepartmentID\tSalary\n1\tJohn Doe\t101\t50000\n2\tAlice Smith\t102\t60000\n3\tBob Johnson\t101\t55000\n4\tCarol Lee\t103\t70000\n5\tDave Brown\t102\t65000\nDepartments Table:\n\nDepartmentID\tDepartmentName\n101\tIT\n102\tHR\n103\tMarketing\nTask:\nWrite an SQL query to find the average salary of employees in each department, but only for departments where the average salary is greater than 55,000.\n\nReturn the following columns:\n\nDepartmentID\nDepartmentName\nAverageSalary\nThe result should be sorted by AverageSalary in descending order.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Average employee salary",
      "createdAt": "2025-01-04T04:43:27.936Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6778bc6f5f4840fc45f6cd45",
      "submissionId": {
        "_id": "6778bc6f5f4840fc45f6cd3d",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Tiger Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735965303/ncqsx4uhb7dpb3yjfdhg.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Question:\nYou are given two tables, Orders and Customers. The Orders table contains information about customer orders, and the Customers table contains information about customers.\n\nTables:\nOrders Table:\n\nOrderID\tCustomerID\tOrderDate\tOrderAmount\n1\t101\t2023-01-10\t500\n2\t102\t2023-01-15\t1500\n3\t103\t2023-02-05\t700\n4\t101\t2023-03-20\t200\n5\t104\t2023-03-25\t1200\n6\t102\t2023-04-10\t300\nCustomers Table:\n\nCustomerID\tCustomerName\tCity\n101\tJohn Doe\tNew York\n102\tAlice Smith\tLos Angeles\n103\tBob Johnson\tChicago\n104\tCarol Lee\tSan Francisco\nTask:\nWrite an SQL query to find the total order amount for each customer who has placed orders in both January and February 2023.\n\nReturn the following columns:\n\nCustomerID\nCustomerName\nTotalOrderAmount\nThe result should be sorted by TotalOrderAmount in descending order.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Customers order amount",
      "createdAt": "2025-01-04T04:43:27.936Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6778bca85f4840fc45f6cd60",
      "submissionId": {
        "_id": "6778bca85f4840fc45f6cd5e",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "PepsiCo",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735965017/iouk8qn2sizijr1glygs.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write a SQL query to find the topmost manager (head) for each employee in the company.\n\nCREATE TABLE Employees (\n    EmployeeID INT,\n    EmployeeName STRING,\n    ManagerID INT\n);\n\nINSERT INTO Employees (EmployeeID, EmployeeName, ManagerID)\nVALUES\n    (1, 'John', NULL),       -- Topmost Manager 1\n    (2, 'Alice', 1),\n    (3, 'Bob', 1),\n    (4, 'Carol', 2),\n    (5, 'Dave', 3),\n    (6, 'Eve', 4),\n    (7, 'Michael', NULL),    -- Topmost Manager 2\n    (8, 'Sarah', 7),\n    (9, 'Tom', 7),\n    (10, 'Lily', 8);\n\nHint - For Dave topmost manager head is John, For Lily topmost manager head is Michael\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Manager for each employee",
      "createdAt": "2025-01-04T04:44:24.557Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6778bca85f4840fc45f6cd61",
      "submissionId": {
        "_id": "6778bca85f4840fc45f6cd5e",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "PepsiCo",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735965017/iouk8qn2sizijr1glygs.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Find Number of rows returned after joining two datasets by inner join, left outer join, right outer join, full outer join, cross join\n\nDataSet A\n1\n1\n1\nNULL\n\nDataSet B\n1\n1\nNULL\nNULL",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " SQL Joins",
      "createdAt": "2025-01-04T04:44:24.557Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6778bca85f4840fc45f6cd62",
      "submissionId": {
        "_id": "6778bca85f4840fc45f6cd5e",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "PepsiCo",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735965017/iouk8qn2sizijr1glygs.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "How would you design an alerting mechanism in Azure Data Factory for long running Data Factory Pipelines.",
      "images": [],
      "category": "scenario based",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " Alerting mechanism",
      "createdAt": "2025-01-04T04:44:24.557Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6778c09e5f4840fc45f6ce52",
      "submissionId": {
        "_id": "6778c09e5f4840fc45f6ce50",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Wipro",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735966026/mwxrwdiu4rkxuxg0w1zj.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "What all optimization techniques have you incorporated in your databricks project ? \nWhat is liquid Clustering ?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "Optimzation techniques",
      "createdAt": "2025-01-04T05:01:18.885Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6778c09e5f4840fc45f6ce53",
      "submissionId": {
        "_id": "6778c09e5f4840fc45f6ce50",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Wipro",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735966026/mwxrwdiu4rkxuxg0w1zj.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "How would you implement SCD-2 in Pyspark and how would you handle scenarios where we need to delete record in a dimension table.",
      "images": [],
      "category": "scenario based",
      "difficulty": "Easy",
      "isFree": true,
      "summary": "SCD-2 records ",
      "createdAt": "2025-01-04T05:01:18.885Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6778c09e5f4840fc45f6ce54",
      "submissionId": {
        "_id": "6778c09e5f4840fc45f6ce50",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Wipro",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735966026/mwxrwdiu4rkxuxg0w1zj.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Implement map, filter, lambda functions on a python list.\nl = [1,2,3,4,5,6]",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Lambda function",
      "createdAt": "2025-01-04T05:01:18.886Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6778c09e5f4840fc45f6ce55",
      "submissionId": {
        "_id": "6778c09e5f4840fc45f6ce50",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Wipro",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1735966026/mwxrwdiu4rkxuxg0w1zj.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write SQL query to delete duplicate records from a dataset.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Delete duplicate records",
      "createdAt": "2025-01-04T05:01:18.886Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6779ab5e5f4840fc45f6d90a",
      "submissionId": {
        "_id": "6779ab5d5f4840fc45f6d908",
        "status": "approved",
        "adminComment": "Approving for now! Please ensure to provide sample data for the problem solving questions.",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Accenture",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736026665/kuaifp68rhjujcazliov.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write sql query to find second highest salary from each department.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Second highest salary",
      "createdAt": "2025-01-04T21:42:54.035Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6779ab5e5f4840fc45f6d90b",
      "submissionId": {
        "_id": "6779ab5d5f4840fc45f6d908",
        "status": "approved",
        "adminComment": "Approving for now! Please ensure to provide sample data for the problem solving questions.",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Accenture",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736026665/kuaifp68rhjujcazliov.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Implement SCD - Slowly changing dimension type 2 in scala/python",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " SCD Implementation",
      "createdAt": "2025-01-04T21:42:54.035Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6779ab5e5f4840fc45f6d90c",
      "submissionId": {
        "_id": "6779ab5d5f4840fc45f6d908",
        "status": "approved",
        "adminComment": "Approving for now! Please ensure to provide sample data for the problem solving questions.",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Accenture",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736026665/kuaifp68rhjujcazliov.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "If there are 10 failed Pipelines in monitor instead of rerunning one by one how will you rerun only failed Pipelines all together.",
      "images": [],
      "category": "project based",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Pipeline failure scenario",
      "createdAt": "2025-01-04T21:42:54.035Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677a13675f4840fc45f6dc2c",
      "submissionId": {
        "_id": "677a13675f4840fc45f6dc2a",
        "status": "approved",
        "adminComment": "Please ensure to always add sample data and schema for problem solving questions. Approving it for now!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Accenture",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736053279/ra0mnzl189ndddeksccl.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Consider you are having orders and customers table. \nFind out the customers who have spent most on their orders in the last month in SQL as well as Pyspark.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "Customers spent ",
      "createdAt": "2025-01-05T05:06:47.972Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677a13675f4840fc45f6dc2d",
      "submissionId": {
        "_id": "677a13675f4840fc45f6dc2a",
        "status": "approved",
        "adminComment": "Please ensure to always add sample data and schema for problem solving questions. Approving it for now!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Accenture",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736053279/ra0mnzl189ndddeksccl.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Though Spark does processing of data in memory why cache is required?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Spark cache",
      "createdAt": "2025-01-05T05:06:47.972Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677a13675f4840fc45f6dc2e",
      "submissionId": {
        "_id": "677a13675f4840fc45f6dc2a",
        "status": "approved",
        "adminComment": "Please ensure to always add sample data and schema for problem solving questions. Approving it for now!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Accenture",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736053279/ra0mnzl189ndddeksccl.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Can you write a SQL query to find the first highest salary as well as the lowest salary within each department?",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Lowest salary",
      "createdAt": "2025-01-05T05:06:47.972Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677a13675f4840fc45f6dc2f",
      "submissionId": {
        "_id": "677a13675f4840fc45f6dc2a",
        "status": "approved",
        "adminComment": "Please ensure to always add sample data and schema for problem solving questions. Approving it for now!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Accenture",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736053279/ra0mnzl189ndddeksccl.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "What is Change Data Capture? How did you implemented it in your project?\nHow the incremental load is implemented in the silver layer?",
      "images": [],
      "category": "project based",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " CDC implementation",
      "createdAt": "2025-01-05T05:06:47.972Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677a13675f4840fc45f6dc30",
      "submissionId": {
        "_id": "677a13675f4840fc45f6dc2a",
        "status": "approved",
        "adminComment": "Please ensure to always add sample data and schema for problem solving questions. Approving it for now!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Accenture",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736053279/ra0mnzl189ndddeksccl.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "How do you handle missing data or corrupted data in your project? ",
      "images": [],
      "category": "project based",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Missing Data",
      "createdAt": "2025-01-05T05:06:47.972Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677a13675f4840fc45f6dc31",
      "submissionId": {
        "_id": "677a13675f4840fc45f6dc2a",
        "status": "approved",
        "adminComment": "Please ensure to always add sample data and schema for problem solving questions. Approving it for now!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Accenture",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736053279/ra0mnzl189ndddeksccl.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "How do you load a file where the columns keeps changing?",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Column changes",
      "createdAt": "2025-01-05T05:06:47.972Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677a13675f4840fc45f6dc32",
      "submissionId": {
        "_id": "677a13675f4840fc45f6dc2a",
        "status": "approved",
        "adminComment": "Please ensure to always add sample data and schema for problem solving questions. Approving it for now!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Accenture",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736053279/ra0mnzl189ndddeksccl.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write a query to show customer_id for the customers that did not have any orders in 2023 from the customers table.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Customer Orders",
      "createdAt": "2025-01-05T05:06:47.973Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677a197e5f4840fc45f6dcc7",
      "submissionId": {
        "_id": "677a197d5f4840fc45f6dcc5",
        "status": "approved",
        "adminComment": "Looks good!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Kantar",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736053959/i9fhpkxurwwvua9zv8kc.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Consider we have table like this named market. \n \nMarketid\t         Item\t         Amount\tType\n1\t\t\tA\t\t50\t\tCurrent\n1\t\t\tB\t\t100\t\tCurrent\n1\t\t\tC\t\t60\t\tCurrent\n2\t\t\tA\t\t100\t\tCurrent\n2\t\t\tB\t\t60\t\tCurrent\n3\t\t\tC\t\t70\t\tCurrent\n4\t\t\tA\t\t50\t\tCurrent\n4\t\t\tC\t\t20\t\tCurrent\n1\t\t\tA\t\t40\t\tPrevious\n1\t\t\tB\t\t80\t\tPrevious\n1\t\t\tC\t\t70\t\tPrevious\n2\t\t\tA\t\t80\t\tPrevious\n2\t\t\tB\t\t50\t\tPrevious\n3\t\t\tC\t\t60\t\tPrevious\n4\t\t\tA\t\t40\t\tPrevious\n\nAlso note that formula for contribution looks something like this. \nContribution = ((sum of current amount by item for a market/total sum of current amount by market) â€“ (sum of previous amount by item for a market /total sum of previous amount by market))*100\n\nWrite a SQL query to find out the contribution which comes from each item.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " Contribution from each item",
      "createdAt": "2025-01-05T05:32:46.048Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677a197e5f4840fc45f6dcc8",
      "submissionId": {
        "_id": "677a197d5f4840fc45f6dcc5",
        "status": "approved",
        "adminComment": "Looks good!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Kantar",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736053959/i9fhpkxurwwvua9zv8kc.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Consider we have input which looks this.\n\n1|A|25|X|\n2|B|26|Y|\n3|C|27|Z\n\nWrite a code in python to get a output which looks like below. Note that '|' is also a alphabet.\n\nColumn1\tColumn2\tColumn3\tColumn4\n1\t\tA\t \t25\t\tX\n2\t\tB\t \t26\t\tY\n3\t\tC\t \t27\t\tZ\n\nFollow up question: How would you do it in pyspark?",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Data ordering",
      "createdAt": "2025-01-05T05:32:46.049Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677a197e5f4840fc45f6dcc9",
      "submissionId": {
        "_id": "677a197d5f4840fc45f6dcc5",
        "status": "approved",
        "adminComment": "Looks good!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Kantar",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736053959/i9fhpkxurwwvua9zv8kc.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Consider we have table department like below.\nUser\tDepartment\nA\tX\nA\tX\nB\tY\nC\tX\nC\tY\nD\tX\nD\tX\n\nHow would you remove duplicates in SQL? \nNote that User D has Department X in both the rows. This case should also be handled.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": "Duplicates in department ",
      "createdAt": "2025-01-05T05:32:46.049Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677a197e5f4840fc45f6dcca",
      "submissionId": {
        "_id": "677a197d5f4840fc45f6dcc5",
        "status": "approved",
        "adminComment": "Looks good!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Kantar",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736053959/i9fhpkxurwwvua9zv8kc.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "How would you automate the process of adding new columns into databricks notebook without manually changing it on Databricks notebook?",
      "images": [],
      "category": "project based",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Column addition",
      "createdAt": "2025-01-05T05:32:46.049Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677a19a25f4840fc45f6dcd2",
      "submissionId": {
        "_id": "677a19a15f4840fc45f6dcd0",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Aays Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736055089/vcufq1ihq5497lpq9kds.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "1.stored procedure vs Functions\n2.can use insert query inside SQL function\n3.types of join\n4. cross join vs self join\n5. what is window function and window function vs aggregated functions",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": "Basic SQL questions",
      "createdAt": "2025-01-05T05:33:22.021Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677a19a25f4840fc45f6dcd3",
      "submissionId": {
        "_id": "677a19a15f4840fc45f6dcd0",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Aays Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736055089/vcufq1ihq5497lpq9kds.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "Input Table:\nnum\n1\n2\n3\n4\n\nExpected result:\n\n1\n2\n2\n3\n3\n3\n4\n4\n4\n4",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Numbers repition",
      "createdAt": "2025-01-05T05:33:22.021Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677a19a25f4840fc45f6dcd4",
      "submissionId": {
        "_id": "677a19a15f4840fc45f6dcd0",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Aays Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736055089/vcufq1ihq5497lpq9kds.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "table:customer\n--emp_no\n--emp_name\n--salary\n--dep\n\nwrite a query to get department with at least 5 employee and salary in greater than 10000\n\nin both SQL and pyspark",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Department details",
      "createdAt": "2025-01-05T05:33:22.021Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677a218a5f4840fc45f6dd10",
      "submissionId": {
        "_id": "677a218a5f4840fc45f6dd0e",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Techmango Technology Services Private Limited",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736057077/ksbe7bhysooyv3bqalvu.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "difference between dict and set\nturple and list",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": "Python dict ",
      "createdAt": "2025-01-05T06:07:06.345Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677a218a5f4840fc45f6dd11",
      "submissionId": {
        "_id": "677a218a5f4840fc45f6dd0e",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Techmango Technology Services Private Limited",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736057077/ksbe7bhysooyv3bqalvu.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "how to handle errors in python\nerror handling (try,except,finally)",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Error handling",
      "createdAt": "2025-01-05T06:07:06.345Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677a218a5f4840fc45f6dd12",
      "submissionId": {
        "_id": "677a218a5f4840fc45f6dd0e",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Techmango Technology Services Private Limited",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736057077/ksbe7bhysooyv3bqalvu.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "what is lambda function and give example with code",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Lambda Function",
      "createdAt": "2025-01-05T06:07:06.345Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677a218a5f4840fc45f6dd13",
      "submissionId": {
        "_id": "677a218a5f4840fc45f6dd0e",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Techmango Technology Services Private Limited",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736057077/ksbe7bhysooyv3bqalvu.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "difference between group by and having",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": "GroupBy function",
      "createdAt": "2025-01-05T06:07:06.345Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677a218a5f4840fc45f6dd14",
      "submissionId": {
        "_id": "677a218a5f4840fc45f6dd0e",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Techmango Technology Services Private Limited",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736057077/ksbe7bhysooyv3bqalvu.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "\nwhy we need cloud service like azure , aws\nwhat is etl\nOLAP vs OLTP\nwhat is data warehouse\nbatch vs streaming processing\nwhat is NoSQL\nwhat is distributed computing",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " ETL Questions",
      "createdAt": "2025-01-05T06:07:06.345Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677a218a5f4840fc45f6dd15",
      "submissionId": {
        "_id": "677a218a5f4840fc45f6dd0e",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Techmango Technology Services Private Limited",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736057077/ksbe7bhysooyv3bqalvu.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "onprimes database vs cloud database",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Onprem database",
      "createdAt": "2025-01-05T06:07:06.345Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677a218a5f4840fc45f6dd16",
      "submissionId": {
        "_id": "677a218a5f4840fc45f6dd0e",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Techmango Technology Services Private Limited",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736057077/ksbe7bhysooyv3bqalvu.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "write a sql query to update a record in table for the emp_id 225 with salary 15000\n\nwhat is corelated subquery ,write a query using it",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " corelated subquery",
      "createdAt": "2025-01-05T06:07:06.345Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677a218a5f4840fc45f6dd17",
      "submissionId": {
        "_id": "677a218a5f4840fc45f6dd0e",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Techmango Technology Services Private Limited",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736057077/ksbe7bhysooyv3bqalvu.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "Employee\n--employeeid\n--name\n--department\n\nsalaries\n--id\n--employeeid\n--date\n--amount\n\nwrite a sql query to get top 2 department where employees get highest total salary in last 6 month",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Top employee salary",
      "createdAt": "2025-01-05T06:07:06.345Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677a2d725f4840fc45f6dd54",
      "submissionId": {
        "_id": "677a2d725f4840fc45f6dd51",
        "status": "approved",
        "adminComment": "approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "AST Space Mobile",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736059999/kstugjgvndtmlkpq4ead.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Find the total number of orders placed by each customer, excluding orders placed in June.\n\n\nTables :::::\n\n\nCustomers Table ::\n\nname,cust_id\nTeena,1\nSeema,2\nRevi,3\nGany,4\n\nOrders table ::::\n\ncust_id,order_date\n1,2015-12-18 \n1,2011-10-11\n2,2012-06-19\n2,2015-09-07\n2,2018-11-09\n3,2014-03-14\n",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736060210/uklxoa9ti6hzzo7qvo58.png"
      ],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Exclude orders in june",
      "createdAt": "2025-01-05T06:57:54.308Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677a2d725f4840fc45f6dd53",
      "submissionId": {
        "_id": "677a2d725f4840fc45f6dd51",
        "status": "approved",
        "adminComment": "approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "AST Space Mobile",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736059999/kstugjgvndtmlkpq4ead.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Write a query to find the department with the highest average salary for employees who have been with the company for more than 2 years?\n\n\nEmp Table ::\n\nSalary,DeptID,HireDate\n10000,1,2015-12-18 \n35000,2,2021-12-18\n27000,3,2020-12-18\n14000,3,2021-12-18\n\nDept Table ::\n\nDeptID,DeptName \n1,HR\n2,Finance\n3,Logistics\n4,Sales",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736060149/s1xjsdfiatnskr6g5zhz.png"
      ],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Highest average salary",
      "createdAt": "2025-01-05T06:57:54.308Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677a2d725f4840fc45f6dd55",
      "submissionId": {
        "_id": "677a2d725f4840fc45f6dd51",
        "status": "approved",
        "adminComment": "approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "AST Space Mobile",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736059999/kstugjgvndtmlkpq4ead.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "How to avoid OOM issues spark?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " OOM spark",
      "createdAt": "2025-01-05T06:57:54.309Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677a2ed85f4840fc45f6dd5f",
      "submissionId": {
        "_id": "677a2ed85f4840fc45f6dd5b",
        "status": "approved",
        "adminComment": "approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Infosys ",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736060380/bwzlgdcfmldbxqimry94.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Explain Caching in Spark Streaming ?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Spark streaming",
      "createdAt": "2025-01-05T07:03:52.482Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677a2ed85f4840fc45f6dd5d",
      "submissionId": {
        "_id": "677a2ed85f4840fc45f6dd5b",
        "status": "approved",
        "adminComment": "approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Infosys ",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736060380/bwzlgdcfmldbxqimry94.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Corresponding to each salesman, display their total customer count as represented below.\n\nSALESMAN      CUSTOMER\nAria   Nexoraa\nAria   SwiftKart\nMila   Zenoviya\nMila   WitalSpring\nMila   PureWive\nHenry  EkoNowa\nHenry  GreenPulze\nZayden SolarNext",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736060500/ujslgyquv0zd7oldbmzg.png"
      ],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Salesman total count",
      "createdAt": "2025-01-05T07:03:52.481Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677a2ed85f4840fc45f6dd60",
      "submissionId": {
        "_id": "677a2ed85f4840fc45f6dd5b",
        "status": "approved",
        "adminComment": "approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Infosys ",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736060380/bwzlgdcfmldbxqimry94.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "What is shuffling in Spark? When does it occur ? ",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Shuffling in spark",
      "createdAt": "2025-01-05T07:03:52.482Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677a2ed85f4840fc45f6dd5e",
      "submissionId": {
        "_id": "677a2ed85f4840fc45f6dd5b",
        "status": "approved",
        "adminComment": "approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Infosys ",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736060380/bwzlgdcfmldbxqimry94.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Identify the countries present in multiple continents\n\nCOUNTRY       CONTINENT\nEgypt  Africa\nPoland Europe\nIndia  Asia\nTurkiye       Asia\nTurkiye       Europe\nKazakhstan    Asia\nKazakhstan    Europe\nIndia  Asia",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736060560/hffnzm2jjrr7homld5e6.png"
      ],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Countries in continents",
      "createdAt": "2025-01-05T07:03:52.482Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677a6fcb5f4840fc45f6de24",
      "submissionId": {
        "_id": "677a6fcb5f4840fc45f6de1d",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Bluepi",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736076963/ntmbdgfa2eqpdnnml2ub.png",
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736076964/y6pg9r6vwfrgivpv9yno.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "We have a list and tuple, create a dict with key-value pair? which one you use as key?which one you use as value?",
      "images": [],
      "category": "scenario based",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Create a dictionary",
      "createdAt": "2025-01-05T11:40:59.252Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677a6fcb5f4840fc45f6de27",
      "submissionId": {
        "_id": "677a6fcb5f4840fc45f6de1d",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Bluepi",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736076963/ntmbdgfa2eqpdnnml2ub.png",
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736076964/y6pg9r6vwfrgivpv9yno.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "1. What is SCD? Different types of SCD?\n2. Difference b/w map and filter in python?\n3. What is generator in python?\n4. What is magic function in python?\n5. What is difference between generator function and normal function in python?\n6. Difference between NVL, NVL2 and Coalesce ?\n7. Difference between rank and dense_rank?\n8. Difference between star schema and galaxy schema?\n9. How to optimize any spark job?\n10. What is broadcast join?\n",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": "DE theory questions",
      "createdAt": "2025-01-05T11:40:59.253Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677a6fcb5f4840fc45f6de26",
      "submissionId": {
        "_id": "677a6fcb5f4840fc45f6de1d",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Bluepi",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736076963/ntmbdgfa2eqpdnnml2ub.png",
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736076964/y6pg9r6vwfrgivpv9yno.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "How to handle skewed data in spark? ",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Data skewness",
      "createdAt": "2025-01-05T11:40:59.253Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677a6fcb5f4840fc45f6de1f",
      "submissionId": {
        "_id": "677a6fcb5f4840fc45f6de1d",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Bluepi",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736076963/ntmbdgfa2eqpdnnml2ub.png",
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736076964/y6pg9r6vwfrgivpv9yno.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "eid, name, desig, date \n1, a, e, 11/12/2024\n2, b, e, 12/12/2024\n1, a, m, 12/12/2024\nWrite a SQL query to find eid who have latest designation.\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Latest designation",
      "createdAt": "2025-01-05T11:40:59.252Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677a6fcb5f4840fc45f6de20",
      "submissionId": {
        "_id": "677a6fcb5f4840fc45f6de1d",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Bluepi",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736076963/ntmbdgfa2eqpdnnml2ub.png",
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736076964/y6pg9r6vwfrgivpv9yno.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "eid, name, desig, date -- emp(dimension table)\n1, a, e, 11/12/2024\n\neid, name, desig, date -- emp_stage(staging table)\n2, b, e, 12/12/2024\n1, a, m, 12/12/2024\nWrite a incremental load query(Actually insert/update query) to insert data from emp_stage to emp. Scenerio was like latest data is coming, you have to keep on adding it.\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Incremental data load",
      "createdAt": "2025-01-05T11:40:59.252Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677a6fcb5f4840fc45f6de21",
      "submissionId": {
        "_id": "677a6fcb5f4840fc45f6de1d",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Bluepi",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736076963/ntmbdgfa2eqpdnnml2ub.png",
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736076964/y6pg9r6vwfrgivpv9yno.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "a b c\nb c d \nc d e \nAbove data is present in txt file. Write a word count program for this in python/spark.\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " word count",
      "createdAt": "2025-01-05T11:40:59.252Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677a6fcb5f4840fc45f6de23",
      "submissionId": {
        "_id": "677a6fcb5f4840fc45f6de1d",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Bluepi",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736076963/ntmbdgfa2eqpdnnml2ub.png",
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736076964/y6pg9r6vwfrgivpv9yno.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": " name = 'a b c' -- Write a code which will always provide last name in python? ",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": "Print last name",
      "createdAt": "2025-01-05T11:40:59.252Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677a6fcb5f4840fc45f6de25",
      "submissionId": {
        "_id": "677a6fcb5f4840fc45f6de1d",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Bluepi",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736076963/ntmbdgfa2eqpdnnml2ub.png",
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736076964/y6pg9r6vwfrgivpv9yno.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "What is persist in spark?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Persist in spark",
      "createdAt": "2025-01-05T11:40:59.253Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677a6fcb5f4840fc45f6de22",
      "submissionId": {
        "_id": "677a6fcb5f4840fc45f6de1d",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Bluepi",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736076963/ntmbdgfa2eqpdnnml2ub.png",
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736076964/y6pg9r6vwfrgivpv9yno.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "a = [1,1,2,2,3,3,4,4,4,5] -- Write a python program to find unique values without using any pre-defined func.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " UDF for unique values",
      "createdAt": "2025-01-05T11:40:59.252Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677a726c5f4840fc45f6de34",
      "submissionId": {
        "_id": "677a726b5f4840fc45f6de2f",
        "status": "approved",
        "adminComment": "approved!",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "LTIMindtree",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736077638/wjpqd735v5s4vd3k2jna.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "1. What is the Project Architecure/pipeline?\n2. What is the different source of system in project?\n3. What is the size of data\n4. Which file format are you using in the project?\n5. Where you are using Hive in you project?",
      "images": [],
      "category": "project based",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Project Questions",
      "createdAt": "2025-01-05T11:52:12.123Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677a726c5f4840fc45f6de32",
      "submissionId": {
        "_id": "677a726b5f4840fc45f6de2f",
        "status": "approved",
        "adminComment": "approved!",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "LTIMindtree",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736077638/wjpqd735v5s4vd3k2jna.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "What is the count of inner, left, right and outer join for below.\n      t1 - c1 - 1,1,1,2,2,3, null\n      t2 - c2 - 1,1,2,2,4,null,null\n      where t1 is table and column present in t1 is c1 & t2 is table and column present in t2 is c2.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " SQL Joins",
      "createdAt": "2025-01-05T11:52:12.123Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677a726c5f4840fc45f6de33",
      "submissionId": {
        "_id": "677a726b5f4840fc45f6de2f",
        "status": "approved",
        "adminComment": "approved!",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "LTIMindtree",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736077638/wjpqd735v5s4vd3k2jna.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "In table t1, 3 columns are present a, b, c with no primary key.\n       Write a SQL query to find the duplicate records.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Find duplicates",
      "createdAt": "2025-01-05T11:52:12.123Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677a726c5f4840fc45f6de36",
      "submissionId": {
        "_id": "677a726b5f4840fc45f6de2f",
        "status": "approved",
        "adminComment": "approved!",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "LTIMindtree",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736077638/wjpqd735v5s4vd3k2jna.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "There are several csv files are present in HDFS folder with state names like bihar.csv, kerala.csv etc.\nWrite a pyspark program where you have to add one more column with column name as \"State\" in each csv file and data of \"State\" column should be the filename.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Display the states based on filename",
      "createdAt": "2025-01-05T11:52:12.123Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677a726c5f4840fc45f6de31",
      "submissionId": {
        "_id": "677a726b5f4840fc45f6de2f",
        "status": "approved",
        "adminComment": "approved!",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "LTIMindtree",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736077638/wjpqd735v5s4vd3k2jna.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "    Table-tmp\nInput\nid\na\nb\nc\nd\ne\nf\n\nOutput\nid        column\na        [a,b,c,d,e,f]\nb        [a,b,c,d,e]\nc        [a,b,c,d]\nd        [a,b,c]\ne        [a,b]\nf        [a]",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " Python pattern print",
      "createdAt": "2025-01-05T11:52:12.123Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677a726c5f4840fc45f6de35",
      "submissionId": {
        "_id": "677a726b5f4840fc45f6de2f",
        "status": "approved",
        "adminComment": "approved!",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "LTIMindtree",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736077638/wjpqd735v5s4vd3k2jna.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "We have applied partition in a hive table. But when we are quering the data on that partition, data is not coming/showing. How you will resolve this issue so that I can see the data?",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Data is not visible",
      "createdAt": "2025-01-05T11:52:12.123Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677aaf7d5f4840fc45f6e080",
      "submissionId": {
        "_id": "677aaf7d5f4840fc45f6e07d",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Affine Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736093293/e4fpf0zxtnvhgl5hcdzg.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Given a python list,\nlst = [3,2,1,4,5,6,7,8,9,10]\n1. even_list = [2,4,6,8,10]\n2. odd_list = [3,1,5,7,9]\n3. sort both lists - [2,4,6,8,10], [1,3,5,7,9]\n4. multiply corresponding elements and sum them: (2*1 + 3*4 + 5*6 + 7*8 + 9*10 = 190)3,",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Arithmetic operations on lists",
      "createdAt": "2025-01-05T16:12:45.648Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677aaf7d5f4840fc45f6e081",
      "submissionId": {
        "_id": "677aaf7d5f4840fc45f6e07d",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Affine Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736093293/e4fpf0zxtnvhgl5hcdzg.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "What are attributes & measures? Can a dimension table have measures?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Dimensional modelling",
      "createdAt": "2025-01-05T16:12:45.648Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677aaf7d5f4840fc45f6e07f",
      "submissionId": {
        "_id": "677aaf7d5f4840fc45f6e07d",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Affine Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736093293/e4fpf0zxtnvhgl5hcdzg.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Given the table,\n  \nName\tSub1\tSub2\nX\t34\t45\nY\t45\t56\n\nConvert it into\nName\tSub\tMarks\nX\tSub1\t34\nX\tSub2\t45\nY\tSub1\t45\nY\tSub2\t56",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Data conversion",
      "createdAt": "2025-01-05T16:12:45.648Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677b36615f4840fc45f6e28d",
      "submissionId": {
        "_id": "677b36615f4840fc45f6e28b",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Affine Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736127762/ooznmmvaztzzeeuzrdtk.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Given a string, remove all characters that appear before the first digit. The resulting string should start with the first digit and include everything afterward.\nInput: 98271sdfs98\nOutput: 98271sdfs98\n\nInput: abex232cdes\nOutput: 232cdes",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Remove the characters before first digit",
      "createdAt": "2025-01-06T01:48:17.707Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677b36615f4840fc45f6e28f",
      "submissionId": {
        "_id": "677b36615f4840fc45f6e28b",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Affine Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736127762/ooznmmvaztzzeeuzrdtk.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "What is the surrogate key?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Surrogate key",
      "createdAt": "2025-01-06T01:48:17.707Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677b36615f4840fc45f6e28e",
      "submissionId": {
        "_id": "677b36615f4840fc45f6e28b",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Affine Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736127762/ooznmmvaztzzeeuzrdtk.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write a Python lambda function that checks whether a given number is even or odd. The function should return True for even numbers and False for odd numbers.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Lamba function for numbers",
      "createdAt": "2025-01-06T01:48:17.707Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677b45165f4840fc45f6e2bb",
      "submissionId": {
        "_id": "677b45165f4840fc45f6e2b9",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Indium Software",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736131097/qibgiomr3ztavzwskcda.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Q1.Pyspark coding problem\n================================\nI have 3 dataframes/tables named tasks, user and driver_city consisting of following columns \nfor tasks-task_id,no_of_tasks,task_cost \nfor user- user_id,user_city,distance_km\nfor driver_city driver_id,driver_city,start_time,end_time\ngive me pyspark ad SQL code to get amount earned by driver in a day,but the condition is cut off time is 5pm\"",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Amount earned by driver",
      "createdAt": "2025-01-06T02:51:02.425Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677b45165f4840fc45f6e2bc",
      "submissionId": {
        "_id": "677b45165f4840fc45f6e2b9",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Indium Software",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736131097/qibgiomr3ztavzwskcda.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Q2.Coding\n============\n data = [(\"\"2023-01-01\"\", \"\"AAPL\"\", 150.00), (\"\"2023-01-02\"\", \"\"AAPL\"\",\n 155.00), (\"\"2023-01-01\"\", \"\"GOOG\"\", 2500.00), (\"\"2023-01-02\"\", \"\"GOOG\"\",\n 2550.00), (\"\"2023-01-01\"\", \"\"MSFT\"\", 300.00), (\"\"2023-01-02\"\", \"\"MSFT\"\",\n 310.00)]\n create dataframe in pyspark\n find avg. stock value on daily basis for each stock\n find max avg stock value of each stock\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Average stock value",
      "createdAt": "2025-01-06T02:51:02.425Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677b45165f4840fc45f6e2bd",
      "submissionId": {
        "_id": "677b45165f4840fc45f6e2b9",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Indium Software",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736131097/qibgiomr3ztavzwskcda.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "If some job failed with out of memory error in production, what will be your approach to debug that\n",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Failed job in production",
      "createdAt": "2025-01-06T02:51:02.425Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677b46cf5f4840fc45f6e2cb",
      "submissionId": {
        "_id": "677b46cf5f4840fc45f6e2c9",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Infosys",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736132032/ti49pw48wzdtma7iugxb.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Q1.Pyspark coding\n==============\nEmp Id\temp_name\tmanagerid\tsalary\n1\tDavid\t3\t100\n2\tSam\t1\t200\n3\tJeff\t3\t2000\n4\tJacob\t4\t2000\nreturn managerid,Manager_name,Emp_id,emp_name, \nsalary where salary is the 2nd highest for employees under each manager.\n\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Second highest salary",
      "createdAt": "2025-01-06T02:58:23.803Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677b46cf5f4840fc45f6e2cc",
      "submissionId": {
        "_id": "677b46cf5f4840fc45f6e2c9",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Infosys",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736132032/ti49pw48wzdtma7iugxb.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Q2.Pyspark coding\n==============\nI have data frame which consists of following columns,give me pyspark code to get most purchased product\norder_id, product_id, quantity, price, cust_id\n\norder_schema=(order_id int, product_id int, quantity int, price int, cust_id int)\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": "Most purchased product",
      "createdAt": "2025-01-06T02:58:23.803Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677b46cf5f4840fc45f6e2cd",
      "submissionId": {
        "_id": "677b46cf5f4840fc45f6e2c9",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Infosys",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736132032/ti49pw48wzdtma7iugxb.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "If your spark job is running slow how would you approach to debug it",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Slowly running spark job",
      "createdAt": "2025-01-06T02:58:23.803Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677c0420d24f993c6c88995f",
      "submissionId": {
        "_id": "677c041fd24f993c6c88995c",
        "status": "approved",
        "adminComment": "Approved.",
        "country": "United States",
        "ctc": "70L-80L",
        "companyName": "Intraedge",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736180536/qgwk8tiya6tqluhnoxpv.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Write a python code, to find the sum of the numbers which do not have duplicates (i.e 1,3,6 => 10)\nnums = [1,2,3,2,7,7,7,6]\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Sum of non-duplicates",
      "createdAt": "2025-01-06T16:26:08.057Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677c0420d24f993c6c889960",
      "submissionId": {
        "_id": "677c041fd24f993c6c88995c",
        "status": "approved",
        "adminComment": "Approved.",
        "country": "United States",
        "ctc": "70L-80L",
        "companyName": "Intraedge",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736180536/qgwk8tiya6tqluhnoxpv.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Table A\ncol1\n1\nnull\n1\n\nTable B\ncol1\n1\n1\n1\n\nselect count(*) from A left join B on A.col1=B.col1",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " SQL Joins",
      "createdAt": "2025-01-06T16:26:08.057Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677c0420d24f993c6c889961",
      "submissionId": {
        "_id": "677c041fd24f993c6c88995c",
        "status": "approved",
        "adminComment": "Approved.",
        "country": "United States",
        "ctc": "70L-80L",
        "companyName": "Intraedge",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736180536/qgwk8tiya6tqluhnoxpv.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "specify where tranformations & actions are happening and explain\n\ndf1=spark.read.csv('sample.csv')\ndf2=df1.repartition(2)\ndf3=df2.where(age<40).select(age,gender,country).groupBy(Country).count()\ndf3.collect()\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": "Spark transformations ",
      "createdAt": "2025-01-06T16:26:08.057Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677c0420d24f993c6c88995e",
      "submissionId": {
        "_id": "677c041fd24f993c6c88995c",
        "status": "approved",
        "adminComment": "Approved.",
        "country": "United States",
        "ctc": "70L-80L",
        "companyName": "Intraedge",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736180536/qgwk8tiya6tqluhnoxpv.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Emp table\n\n| empname | location  | year | vaccination | infected |\n| ------- | --------- | ---- | ----------- | -------- |\n| A       | Delhi     | 2020 | No          | No       |\n| A       | Delhi     | 2021 | Yes         | Yes      |\n| A       | Delhi     | 2022 | Yes         | No       |\n| B       | Delhi     | 2020 | No          | Yes      |\n| B       | Delhi     | 2021 | Yes         | No       |\n| B       | Delhi     | 2022 | Yes         | Yes      |\n| C       | Bangalore | 2020 | Yes         | Yes      |\n| C       | Bangalore | 2021 | No          | No       |\n| C       | Bangalore | 2022 | Yes         | Yes      |\n| D       | Bangalore | 2020 | Yes         | No       |\n| D       | Bangalore | 2021 | Yes         | Yes      |\n| D       | Bangalore | 2022 | Yes         | No       |\n\nWrite a SQL query to fetch the empname those who were vaccinated a particular year but got infected the immediate next year.\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Employee who was vacinated",
      "createdAt": "2025-01-06T16:26:08.056Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677c0420d24f993c6c889962",
      "submissionId": {
        "_id": "677c041fd24f993c6c88995c",
        "status": "approved",
        "adminComment": "Approved.",
        "country": "United States",
        "ctc": "70L-80L",
        "companyName": "Intraedge",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736180536/qgwk8tiya6tqluhnoxpv.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "1.\tExplain partitioning & clustering in Bigquery\n2.\tHow will you decide which column to be used for partitioning & clustering\n3.\tCan we create index in Bigquery?\n4.\tOptimization techniques in Pyspark jobs\n5.\tData modeling in DW\n",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Spark theory questions",
      "createdAt": "2025-01-06T16:26:08.057Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677c259ad24f993c6c889b12",
      "submissionId": {
        "_id": "677c259ad24f993c6c889b10",
        "status": "approved",
        "adminComment": "approved.",
        "country": "United States",
        "ctc": "70L-80L",
        "companyName": "CTS",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736188517/ibp76zyri9yj51xcg4pa.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "GCP:\n1.\tWhat is dataproc?\n2.\tClasses used in pyspark job\n3.\tBasic configurations details for creating a dataproc cluster\n4.\tHow to load data without spinning clusters using dataproc\n5.\tDifferent sections in pyspark code. How to initiate spark shell?\n6.\tHow will you check logs in dataflow and dataproc\n7.\tHow to submit a dataproc job\n",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " DE theory questions",
      "createdAt": "2025-01-06T18:48:58.314Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677c259ad24f993c6c889b13",
      "submissionId": {
        "_id": "677c259ad24f993c6c889b10",
        "status": "approved",
        "adminComment": "approved.",
        "country": "United States",
        "ctc": "70L-80L",
        "companyName": "CTS",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736188517/ibp76zyri9yj51xcg4pa.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Airflow:\n\n1.\tWhat is Apache Airflow?\n2.\tHow will you create a new dag code to be able to reflect in Apache Airflow?\n3.\tWhere can you view the code in Airflow? Can we edit the code in Airflow UI?\n4.\tWhere will you check logs in Airflow?\n5.\tHow will you send notification on dag failure?\n6.\tWhat are the different operators you have used in dag?\n7.\tWhat are the main sections in dag?\n8.\tHow will you set dependencies between tasks in dag?\n",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": false,
      "summary": "Airflow questions ",
      "createdAt": "2025-01-06T18:48:58.314Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677c259ad24f993c6c889b15",
      "submissionId": {
        "_id": "677c259ad24f993c6c889b10",
        "status": "approved",
        "adminComment": "approved.",
        "country": "United States",
        "ctc": "70L-80L",
        "companyName": "CTS",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736188517/ibp76zyri9yj51xcg4pa.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Employee:\nemployee_id| emp_name |dept_id   |salary\n-------------|-------------|------------|------\n\t1\t   |\tAlice       |101\t         |80000\n\t1\t   |\tBob         |101\t         |75000\n\t1\t   |\tCharlie    |101\t         |90000\n\t1\t   |\tDavid      |102\t         |60000\n\t1\t   |\tEva         |102\t         |65000\n\t1\t   |\tFrank      |102\t         |62000\n\t1\t   |\tGrace      |103\t         |70000\n\t1\t   |\tHelen      |103\t         |82000\n\t1\t   |\tIan           |103\t         |91000\n\nWrite a query to find the top 2 highest-paid employees from each department. ",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Highest paid employees",
      "createdAt": "2025-01-06T18:48:58.316Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677c259ad24f993c6c889b14",
      "submissionId": {
        "_id": "677c259ad24f993c6c889b10",
        "status": "approved",
        "adminComment": "approved.",
        "country": "United States",
        "ctc": "70L-80L",
        "companyName": "CTS",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736188517/ibp76zyri9yj51xcg4pa.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Write a python function to count number of vowels in a word.\n\nO/P:\nWord: apple, Vowels: 2\nWord: banana, Vowels: 3\nWord: grape, Vowels: 2\nWord: sky, Vowels: 0\nWord: rhythm, Vowels: 0\nWord: umbrella, Vowels: 3\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Count the vowels",
      "createdAt": "2025-01-06T18:48:58.314Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677cfad0d24f993c6c88a160",
      "submissionId": {
        "_id": "677cfad0d24f993c6c88a15d",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Bitwise",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736243173/vymvabngvkjuhlmjsnfx.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "How do you handle the data skew in spark jobs",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Data skewness",
      "createdAt": "2025-01-07T09:58:40.649Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677cfad0d24f993c6c88a161",
      "submissionId": {
        "_id": "677cfad0d24f993c6c88a15d",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Bitwise",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736243173/vymvabngvkjuhlmjsnfx.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Given The data of Node and Its parent nodes, Give me the output whether the node is a root , leaf or branch node\nRoot - The starting node, with no parents\nLeaf - node with no child\nbranch - node with a child, that is not root.\t\nNode\tParent\n1\t2\n3\t2\n6\t8\n9\t8\n2\t5\n8\t5\n5\t\n6\t\n\t",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Find the right node",
      "createdAt": "2025-01-07T09:58:40.650Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677cfad0d24f993c6c88a162",
      "submissionId": {
        "_id": "677cfad0d24f993c6c88a15d",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Bitwise",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736243173/vymvabngvkjuhlmjsnfx.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "How do you write an incremental update data pipeline with the following sample data\n\nemp_data : \n \nemp_id mob_no   Address                Flag\n123         7777777         Bangalore                Y\n456   8888888         Chennai                     Y\n789   9999999         Pune                        Y\n124   6666666         Hyderabad                Y\n333   9199191         Delhi                        Y\n \nemp_file :  latest data\n \nemp_id mob_no   Address\n789   9999999   Bangalore\n124   6666666   Hyderabad\n333   9199191   Bangalore\n444   7171717   Jaipur\n \n \nResult :\n \nemp_id  mob_no  Address           Flag\n123   7777777   Bangalore          Y\n456   8888888   Chennai            Y\n789   9999999   Pune               N\n124   6666666   Hyderabad          Y\n333   9199191   Delhi              N\n444   7171717   Jaipur             Y\n789   9999999   Bangalore          Y\n333   9199191   Bangalore          Y\n\n\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Incremental data update",
      "createdAt": "2025-01-07T09:58:40.650Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677d45ced24f993c6c88a3ba",
      "submissionId": {
        "_id": "677d45ced24f993c6c88a3b6",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Accenture",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736262534/pdxw1aid1iqlawwpx1w5.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Take an example and demonstrate how to read an array as a data frame.\nHow to convert an RDD into a data frame?\nHow to define custom schema?",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Array as a dataframe",
      "createdAt": "2025-01-07T15:18:38.671Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677d45ced24f993c6c88a3bb",
      "submissionId": {
        "_id": "677d45ced24f993c6c88a3b6",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Accenture",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736262534/pdxw1aid1iqlawwpx1w5.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Difference between repartition and coalesce?\nDifference between cache and persist?\nDifference between Wide and Narrow transformations?\nWhat is data skewness and how to handle it?\nExplain DAG?\nDifference between Broadcast variable & Accumulators?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Spark theory questions",
      "createdAt": "2025-01-07T15:18:38.671Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677d45ced24f993c6c88a3bd",
      "submissionId": {
        "_id": "677d45ced24f993c6c88a3b6",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Accenture",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736262534/pdxw1aid1iqlawwpx1w5.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Spark code to add a new column as â€œfull nameâ€ concatenating first name and last name?\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " New column in spark",
      "createdAt": "2025-01-07T15:18:38.671Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677d45ced24f993c6c88a3b8",
      "submissionId": {
        "_id": "677d45ced24f993c6c88a3b6",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Accenture",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736262534/pdxw1aid1iqlawwpx1w5.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "What is the difference between RDD, Dataframe & Dataset? What is the difference between Spark & MapReduce?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": "RDD differance ",
      "createdAt": "2025-01-07T15:18:38.671Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677d45ced24f993c6c88a3b9",
      "submissionId": {
        "_id": "677d45ced24f993c6c88a3b6",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Accenture",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736262534/pdxw1aid1iqlawwpx1w5.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Different compression techniques in parquet? Why should we use the Parquet format? Other columnar storage formats?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Compression techniques",
      "createdAt": "2025-01-07T15:18:38.671Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677d45ced24f993c6c88a3bc",
      "submissionId": {
        "_id": "677d45ced24f993c6c88a3b6",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Accenture",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736262534/pdxw1aid1iqlawwpx1w5.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Difference between rank, dense_rank, and row_number()?\n",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Rank functions",
      "createdAt": "2025-01-07T15:18:38.671Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677e0206d24f993c6c88a8ef",
      "submissionId": {
        "_id": "677e0206d24f993c6c88a8eb",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Deloitte ",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736310919/cwxszztactftsw6ndaro.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Given a table with 2 columns, id and value like below:\nID\nValue\n\n1\nA\n\n2\nB\n\n3\nc\n\n\nDisplay the result as below using SQL & Spark:\nA, B, C ",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Display the alphabets ",
      "createdAt": "2025-01-08T04:41:42.645Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677e0206d24f993c6c88a8ee",
      "submissionId": {
        "_id": "677e0206d24f993c6c88a8eb",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Deloitte ",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736310919/cwxszztactftsw6ndaro.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "How to find duplicates from the given table using SQL & Spark?\nHow to find the duplicate records and save them in another path in spark?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Find duplicates",
      "createdAt": "2025-01-08T04:41:42.645Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677e0206d24f993c6c88a8ed",
      "submissionId": {
        "_id": "677e0206d24f993c6c88a8eb",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Deloitte ",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736310919/cwxszztactftsw6ndaro.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "\nGiven input,\nC1\nC2\n\nABC\nDEF\nPQR\n\n\n       Produce the output,\n       \nC1\nC2\n\nABC\nPQR\n\nDEF\nPQR\n\n\nGiven input,\nEmpld\nDate\nExpenses\n\n1\n21-01-2022\n50\n\n1\n22-02-2022\n100\n\n1\n04-03-2023\n120\n\n1\n04-05-2023\n300\n\n2\n03-03-2022\n100\n\n2\n04-04-2022\n300\n\n\nProduce the output,\nEmpld\nDate\nExpenses\n\n1\n21-01-2022\n50\n\n1\n22-02-2022\n150\n\n1\n04-03-2023\n270\n\n1\n04-05-2023\n570\n\n2\n03-03-2022\n100\n\n2\n04-04-2022\n400\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Produce the data in given pattern",
      "createdAt": "2025-01-08T04:41:42.644Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677e8e3cd24f993c6c88ac82",
      "submissionId": {
        "_id": "677e8e3bd24f993c6c88ac80",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "KPMG",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736346484/qgxoskpuhrbartacqlhc.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Que1 - Write an SQL query to find the month with the highest expenditure.\nQue2 - Write an SQL query to calculate the expenditure for each month\n\nItem\t  Expenditure\tDate   \nApple\t400\t    1-Jul-23\nBananas\t200\t    4-Jul-23\nCarrots\t100\t    3-Jun-23\nGuava\t50\t   20-Jun-23",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Highest expenditure",
      "createdAt": "2025-01-08T14:39:56.142Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677e8e3cd24f993c6c88ac84",
      "submissionId": {
        "_id": "677e8e3bd24f993c6c88ac80",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "KPMG",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736346484/qgxoskpuhrbartacqlhc.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Que - Write Python or Scala program\n\ninput = \"Happy New Year\"\n\noutput 1:\nYear New Happy\n \noutput 2:\nyppah wen raey\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": "Reverse order of words",
      "createdAt": "2025-01-08T14:39:56.142Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677e8e3cd24f993c6c88ac85",
      "submissionId": {
        "_id": "677e8e3bd24f993c6c88ac80",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "KPMG",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736346484/qgxoskpuhrbartacqlhc.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "How many executor cores can be allocated in a 20-node Spark cluster, where each node has 16 CPU cores and 64 GB of RAM?",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Spark resources allocation",
      "createdAt": "2025-01-08T14:39:56.142Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677e8e3cd24f993c6c88ac83",
      "submissionId": {
        "_id": "677e8e3bd24f993c6c88ac80",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "KPMG",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736346484/qgxoskpuhrbartacqlhc.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Que -Write an SQL query to find 2nd highest score in each department.\n\nStudent\tDepartment\tPoints\nRam\tECE\t9\nAjay\tECE\t9.2\nGopal\tECE\t9\nNikhil\tEEE\t8.8\nSai\tEEE\t8.5\nChaand\tEEE\t8.9\nVimal\tMech\t9\nRaju\tMech\t9\nNaveen\tMech\t9\nAditya\tCSE\t9.2\nShweta\tCSE\t9.4\nPriya\tCSE\t9.1\nManisha\tCSE\t9\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": "Highest score in each dept ",
      "createdAt": "2025-01-08T14:39:56.142Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677ebeabd24f993c6c88af56",
      "submissionId": {
        "_id": "677ebeabd24f993c6c88af54",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "Czech Republic",
        "ctc": "30L-40L",
        "companyName": "EPAM",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736359126/trpcjogsbzcvkn0yu5ep.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "SQL Question -\nwith source_table as(\nSELECT  'a1' as customer , 'swift' as product, 'maruti' as brand\nUNION ALL\nSELECT 'a2','vento','volkswagen'\nUNION ALL\nSELECT 'a2','polo','volkswagen'\nUNION ALL\nSELECT 'a1','hector','mg'\nUNION ALL\nSELECT 'a2','tiguan','volkswagen'\nUNION ALL\nSELECT 'a3','swift','maruti'\nUNION ALL\nSELECT 'a3','scross','maruti'\n)\nselect * from source_table\n \n\n-- normal-has bought multiple products from multiple brands\n-- loyal_customer-has bought products only from single brand\n-- Write sql query to find brand and number of loyal customers?",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Loyal customers",
      "createdAt": "2025-01-08T18:06:35.385Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677ebeabd24f993c6c88af58",
      "submissionId": {
        "_id": "677ebeabd24f993c6c88af54",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "Czech Republic",
        "ctc": "30L-40L",
        "companyName": "EPAM",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736359126/trpcjogsbzcvkn0yu5ep.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "input - \"aaabbccdaaabdd\"\noutput - \"a3b2c2d1a3b1d2\"\nWrite a Python program to transform the input string?",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " character count in string",
      "createdAt": "2025-01-08T18:06:35.386Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677ebeabd24f993c6c88af57",
      "submissionId": {
        "_id": "677ebeabd24f993c6c88af54",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "Czech Republic",
        "ctc": "30L-40L",
        "companyName": "EPAM",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736359126/trpcjogsbzcvkn0yu5ep.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "How do you handle late arriving data in your incremental loads?",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Late arriving records",
      "createdAt": "2025-01-08T18:06:35.386Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677ec08cd24f993c6c88af64",
      "submissionId": {
        "_id": "677ec08cd24f993c6c88af62",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "Czech Republic",
        "ctc": "40L-50L",
        "companyName": "MSD",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736359805/ocpgalhkftd4tbbsb5tm.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Find the count of each letters in a word using SQL\nINSERT INTO sample_table (text_column) VALUES\n('this'),\n('another'),\n('text');",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " character count",
      "createdAt": "2025-01-08T18:14:36.691Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677ec08cd24f993c6c88af66",
      "submissionId": {
        "_id": "677ec08cd24f993c6c88af62",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "Czech Republic",
        "ctc": "40L-50L",
        "companyName": "MSD",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736359805/ocpgalhkftd4tbbsb5tm.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "How to split the delimiter and load into a dataframe using pyspark\nName~|Age\nVirat, Kohli~|28\nAndrew, Simond~|137\nGeogre, Bush~|159\nFlintoff, David~|12\nAdam, James~|20",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Split the delimiter",
      "createdAt": "2025-01-08T18:14:36.691Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677ec08cd24f993c6c88af65",
      "submissionId": {
        "_id": "677ec08cd24f993c6c88af62",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "Czech Republic",
        "ctc": "40L-50L",
        "companyName": "MSD",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736359805/ocpgalhkftd4tbbsb5tm.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "how you can secure the s3 bucket?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " secure s3 bucket",
      "createdAt": "2025-01-08T18:14:36.691Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677f60c5d24f993c6c88b0c7",
      "submissionId": {
        "_id": "677f60c5d24f993c6c88b0c4",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Ernst & Young",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736400635/dgmfawdejigrnmnnltns.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Ques - Write a Python 3 program to check for duplicates in a given list of items and print only the duplicates.\narr = [10, 20, 20, 10, 10, 20, 5, 20]",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": "Duplicates in a list ",
      "createdAt": "2025-01-09T05:38:13.515Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677f60c5d24f993c6c88b0c6",
      "submissionId": {
        "_id": "677f60c5d24f993c6c88b0c4",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Ernst & Young",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736400635/dgmfawdejigrnmnnltns.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Que-How many records will be present in the result for each of the following joins?\n\nLeft Join\nRight Join\nInner Join\nFull Outer Join\n\nColumn 1\n0\n1\n2\nNULL\n\nColumn 2\n2\n4\nNULL\nNULL",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": "SQL Joins ",
      "createdAt": "2025-01-09T05:38:13.515Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677f60c5d24f993c6c88b0c8",
      "submissionId": {
        "_id": "677f60c5d24f993c6c88b0c4",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Ernst & Young",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736400635/dgmfawdejigrnmnnltns.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Que - Create a DataFrame with the following column names: order_id, order_date, customer_id, payment_status. Perform the following manipulations:\n\n1.Add a new column with the current timestamp as current_date.\n2.Drop duplicates based on the primary key (order_date, customer_id).\n3.Drop the order_id column.\n\nlist_1 = [\n    [1, \"2013-07-25\", 11599, \"CLOSED\"],\n    [2, \"2014-07-25\", 256, \"PENDING_PAYMENT\"],\n    [3, \"2013-07-25\", 11599, \"COMPLETE\"],\n    [4, \"2019-07-25\", 8827, \"CLOSED\"]\n]\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Order data transformations",
      "createdAt": "2025-01-09T05:38:13.515Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677fa5e4d24f993c6c88b1db",
      "submissionId": {
        "_id": "677fa5e3d24f993c6c88b1d9",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Astrosoft Technologies",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736418546/wzxrjtmp0dhct9zjubmm.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "Python\nlst=[1,2,4,9,1,6,7] get prime numbers from the list",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Prime numbers in list",
      "createdAt": "2025-01-09T10:33:08.005Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677fa5e4d24f993c6c88b1dc",
      "submissionId": {
        "_id": "677fa5e3d24f993c6c88b1d9",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Astrosoft Technologies",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736418546/wzxrjtmp0dhct9zjubmm.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "SQL\nWrite a query to delete duplicates from table",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": "  Delete duplicates",
      "createdAt": "2025-01-09T10:33:08.005Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677fa5e4d24f993c6c88b1dd",
      "submissionId": {
        "_id": "677fa5e3d24f993c6c88b1d9",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Astrosoft Technologies",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736418546/wzxrjtmp0dhct9zjubmm.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "in redshift how do u get data from a file residing in s3",
      "images": [],
      "category": "scenario based",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Fetch data into redshift",
      "createdAt": "2025-01-09T10:33:08.005Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677fa7f8d24f993c6c88b1e9",
      "submissionId": {
        "_id": "677fa7f8d24f993c6c88b1e7",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Apexon",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736418770/jqlx2sgicsapxdavhb7q.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "1. Catalyst Optimizer and Adaptive Query Execution (AQE): - How both help in optimization",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Catalyst Optimizer",
      "createdAt": "2025-01-09T10:42:00.350Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677fa7f8d24f993c6c88b1eb",
      "submissionId": {
        "_id": "677fa7f8d24f993c6c88b1e7",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Apexon",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736418770/jqlx2sgicsapxdavhb7q.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "3. How broadcast join help in optimization for skew Data",
      "images": [],
      "category": "theoretical",
      "difficulty": "Hard",
      "isFree": false,
      "summary": "Broadcast in data skewness",
      "createdAt": "2025-01-09T10:42:00.351Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677fa7f8d24f993c6c88b1ec",
      "submissionId": {
        "_id": "677fa7f8d24f993c6c88b1e7",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Apexon",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736418770/jqlx2sgicsapxdavhb7q.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Python Program to Check if a String is Palindrome or Not",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Palindrome string",
      "createdAt": "2025-01-09T10:42:00.351Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "677fa7f8d24f993c6c88b1ea",
      "submissionId": {
        "_id": "677fa7f8d24f993c6c88b1e7",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Apexon",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736418770/jqlx2sgicsapxdavhb7q.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "2. Airflow Task rerun: - does it generate same run ID and we need to give different ID\n",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Airflow task rerun",
      "createdAt": "2025-01-09T10:42:00.351Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677fa7f8d24f993c6c88b1ed",
      "submissionId": {
        "_id": "677fa7f8d24f993c6c88b1e7",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Apexon",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736418770/jqlx2sgicsapxdavhb7q.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "sort and merge 2 list.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Sort & merge",
      "createdAt": "2025-01-09T10:42:00.351Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677fc3cad24f993c6c88b306",
      "submissionId": {
        "_id": "677fc3cad24f993c6c88b303",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "EXL Services",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736425734/nzkgbrhb7rgogjmhswpp.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Find the record having the latest date for each ID - to answer in both SQL and Pyspark\n +----+------------+--------+\n  | id | date       | value  |\n  +----+------------+--------+\n  | 1  | 2024-01-16 | AA     |\n  | 2  | 2023-05-17 | BB     |\n  | 1  | 2023-06-13 | AC     |\n  | 2  | 2024-03-18 | AD     |\n  +----+------------+--------+ ",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Latest ID data",
      "createdAt": "2025-01-09T12:40:42.950Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677fc3cad24f993c6c88b307",
      "submissionId": {
        "_id": "677fc3cad24f993c6c88b303",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "EXL Services",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736425734/nzkgbrhb7rgogjmhswpp.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| id          | int     |\n| num         | varchar |\n+-------------+---------+\nid is the Unique key for this table.\nid is an autoincrement column.\n\nFind all numbers that appear at least three times consecutively.\n\nReturn the result table in any order.\n\nExample 1:\n\nInput: \nLogs table:\n+----+-----+\n| id | num |\n+----+-----+\n| 1  | 1   | \n| 2  | 1   |\n| 3  | 1   |\n| 4  | 2   |\n| 5  | 1   |\n| 6  | 2   |\n| 7  | 2   |\n+----+-----+\nOutput: \n+-----------------+\n| ConsecutiveNums |\n+-----------------+\n| 1               |\n+-----------------+\nExplanation: 1 is the only number that appears consecutively for at least three times.\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "Consecutive appearance  ",
      "createdAt": "2025-01-09T12:40:42.950Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "677fc3cad24f993c6c88b305",
      "submissionId": {
        "_id": "677fc3cad24f993c6c88b303",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "EXL Services",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736425734/nzkgbrhb7rgogjmhswpp.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "What is data modeling?\nWhat are Star and Snowflake schemas?\nWrite a high level data model that has many-to-many mappings?\nWhat are SCD types 0,1,2? And where do you use them?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": "DE theory",
      "createdAt": "2025-01-09T12:40:42.950Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6780e994d24f993c6c88bbd3",
      "submissionId": {
        "_id": "6780e993d24f993c6c88bbd0",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Delloite",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736501203/jvwofhumcphbgq2ll7xo.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Explain the concept of dimensional modeling in data warehouses. How does it differ from normalized modeling, and in which scenarios would you prefer one over the other? Provide examples to support your answer",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Dimensional Modelling",
      "createdAt": "2025-01-10T09:34:12.134Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6780e994d24f993c6c88bbd5",
      "submissionId": {
        "_id": "6780e993d24f993c6c88bbd0",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Delloite",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736501203/jvwofhumcphbgq2ll7xo.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "What are SCD?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " SCD",
      "createdAt": "2025-01-10T09:34:12.134Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6780e994d24f993c6c88bbd2",
      "submissionId": {
        "_id": "6780e993d24f993c6c88bbd0",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Delloite",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736501203/jvwofhumcphbgq2ll7xo.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "You are given a dataset of customer transactions stored as a PySpark DataFrame:\n\nCustomerID\tTransactionDate\tAmount\tCategory\n101\t2024-12-01\t500\tElectronics\n102\t2024-12-02\t150\tGroceries\n101\t2024-12-03\t300\tApparel\n102\t2024-12-04\t100\tGroceries\n103\t2024-12-05\t250\tElectronics\n\nWrite a PySpark code to calculate the total spending per customer.\nFilter the customers who have spent more than 400 in total.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Customer spend transactions",
      "createdAt": "2025-01-10T09:34:12.134Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6780e994d24f993c6c88bbd6",
      "submissionId": {
        "_id": "6780e993d24f993c6c88bbd0",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Delloite",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736501203/jvwofhumcphbgq2ll7xo.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "About the optimization technique used in SQL and Pyspark.",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Optimization techniques",
      "createdAt": "2025-01-10T09:34:12.134Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6780e994d24f993c6c88bbd4",
      "submissionId": {
        "_id": "6780e993d24f993c6c88bbd0",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Delloite",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736501203/jvwofhumcphbgq2ll7xo.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "You are given two tables:\n\nCustomers\n\nCustomerID\tName\tCity\n1\tAlice\tNew York\n2\tBob\tLondon\n3\tCharlie\tParis\n\nOrders\n\nOrderID\tCustomerID\tOrderAmount\tOrderDate\n101\t1\t500\t2024-11-01\n102\t2\t200\t2024-11-02\n103\t3\t300\t2024-11-03\n104\t1\t400\t2024-11-04\n\nWrite an SQL query to find:\n\nThe total order amount for each customer along with their name and city.\nCustomers who have placed more than one order and the total amount spent.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "Customers orders ",
      "createdAt": "2025-01-10T09:34:12.134Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6780f190d24f993c6c88bc6f",
      "submissionId": {
        "_id": "6780f190d24f993c6c88bc6b",
        "status": "approved",
        "adminComment": "approved!",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Aidetic",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736502485/c8gjtomlkisfhlftkms8.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Given a table named Sales:\nSaleID\tProductID\tSaleAmount\tSaleDate\n1\t101\t500\t2024-10-01\n2\t102\t300\t2024-10-02\n3\t101\t400\t2024-10-03\n4\t103\t600\t2024-10-04\nAnd a table named Products:\nProductID\tProductName\tCategory\n101\tLaptop\tElectronics\n102\tPhone\tElectronics\n103\tChair\tFurniture\nWrite a query to calculate total sales for each product category.\nIdentify the product with the highest sales amount.\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " Highest sales in product",
      "createdAt": "2025-01-10T10:08:16.795Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6780f190d24f993c6c88bc70",
      "submissionId": {
        "_id": "6780f190d24f993c6c88bc6b",
        "status": "approved",
        "adminComment": "approved!",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Aidetic",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736502485/c8gjtomlkisfhlftkms8.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "You are given a list of dictionaries representing students' scores:\nWrite a Python program to calculate the average score for each student.\nFind the name of the student with the highest average score.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Average score of students",
      "createdAt": "2025-01-10T10:08:16.795Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6780f190d24f993c6c88bc6d",
      "submissionId": {
        "_id": "6780f190d24f993c6c88bc6b",
        "status": "approved",
        "adminComment": "approved!",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Aidetic",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736502485/c8gjtomlkisfhlftkms8.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "What are surrogate keys, and why are they preferred over natural keys in dimensional modeling? Provide scenarios where surrogate keys can lead to better performance or simplify design.\n\n",
      "images": [],
      "category": "theoretical",
      "difficulty": "Hard",
      "isFree": true,
      "summary": " Surrogate Keys",
      "createdAt": "2025-01-10T10:08:16.795Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6780f190d24f993c6c88bc6e",
      "submissionId": {
        "_id": "6780f190d24f993c6c88bc6b",
        "status": "approved",
        "adminComment": "approved!",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Aidetic",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736502485/c8gjtomlkisfhlftkms8.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "You have a PySpark DataFrame of employees and their salaries:\nEmployeeID\tDepartment\tSalary\tDateHired\n1\tHR\t50000\t2020-06-15\n2\tIT\t75000\t2018-09-20\n3\tHR\t60000\t2022-03-11\n4\tIT\t72000\t2021-12-01\nWrite a PySpark code to calculate the average salary per department.\nFilter out departments where the average salary is less than 60,000.\nAdd a column indicating how many years each employee has worked in the company (based on the current date)",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Employee experience in dept",
      "createdAt": "2025-01-10T10:08:16.795Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6780f190d24f993c6c88bc72",
      "submissionId": {
        "_id": "6780f190d24f993c6c88bc6b",
        "status": "approved",
        "adminComment": "approved!",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Aidetic",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736502485/c8gjtomlkisfhlftkms8.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "You are tasked with designing a data model for an e-commerce system. The requirements include:\n\nTracking customers and their addresses.\nStoring product details like categories and prices.\nRecording orders placed by customers, including timestamps and quantities.\nDraw an Entity-Relationship (ER) diagram for the data model.\nDescribe how you would normalize this model to the third normal form (3NF).\n",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " E-Commerce Data Model",
      "createdAt": "2025-01-10T10:08:16.795Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6780f190d24f993c6c88bc71",
      "submissionId": {
        "_id": "6780f190d24f993c6c88bc6b",
        "status": "approved",
        "adminComment": "approved!",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Aidetic",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736502485/c8gjtomlkisfhlftkms8.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Explain the concept of shuffle operations in PySpark. Why are shuffle operations costly, and how can their impact be minimized? Provide examples of transformations in PySpark that result in shuffle operations",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Spark shuffling",
      "createdAt": "2025-01-10T10:08:16.795Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67821793d24f993c6c88c300",
      "submissionId": {
        "_id": "67821793d24f993c6c88c2fb",
        "status": "approved",
        "adminComment": "approved.",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Coforge",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736578563/sbvkyxknft4ordxx4qvu.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Given a text file having a unstructured text (fixed width file), search a word ex: test and get the frequency of that word as output in entire file",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " Frequency of word",
      "createdAt": "2025-01-11T07:02:43.414Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67821793d24f993c6c88c2fe",
      "submissionId": {
        "_id": "67821793d24f993c6c88c2fb",
        "status": "approved",
        "adminComment": "approved.",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Coforge",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736578563/sbvkyxknft4ordxx4qvu.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Difference between lineage and DAG",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Lineage & DAG",
      "createdAt": "2025-01-11T07:02:43.414Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67821793d24f993c6c88c2fd",
      "submissionId": {
        "_id": "67821793d24f993c6c88c2fb",
        "status": "approved",
        "adminComment": "approved.",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Coforge",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736578563/sbvkyxknft4ordxx4qvu.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "project Architecture",
      "images": [],
      "category": "project based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Project Architecture",
      "createdAt": "2025-01-11T07:02:43.414Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67821793d24f993c6c88c301",
      "submissionId": {
        "_id": "67821793d24f993c6c88c2fb",
        "status": "approved",
        "adminComment": "approved.",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Coforge",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736578563/sbvkyxknft4ordxx4qvu.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "val data = Seq(\n  (1, \"#\", \"\"),\n  (2, \"dd\", \"$\"),\n  (3, \"NA\", \"5000\"),\n  (4, \"John\", \"NA\"),\n  (5, \"\", \"6000\")\n)\n \nval specialChars = List(\"#\", \"$\", \"%\", \"&\", \"@\")\n\nspecial chars should be broadcasted\n\ncompare both data and special chars , if cols in data having any of the special chars replace it with null",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Special characters in data",
      "createdAt": "2025-01-11T07:02:43.414Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67821793d24f993c6c88c302",
      "submissionId": {
        "_id": "67821793d24f993c6c88c2fb",
        "status": "approved",
        "adminComment": "approved.",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Coforge",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736578563/sbvkyxknft4ordxx4qvu.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "val data = Seq(\n  (101, \"[pizza,samosa,idli]\"),\n  (102, \"[kachori,sambhar,idli]\"),\n  (103, \"[dosa,vada,pizza]\"),\n  (104, \"[samosa,idli,chai]\"),\n  (105, \"[pizza,chai,dosa]\")\n)\n\ngiven orderid and orders. i want aggregated output as number of times each item is orderd",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": false,
      "summary": "Count of items ordered ",
      "createdAt": "2025-01-11T07:02:43.414Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67821793d24f993c6c88c2ff",
      "submissionId": {
        "_id": "67821793d24f993c6c88c2fb",
        "status": "approved",
        "adminComment": "approved.",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Coforge",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736578563/sbvkyxknft4ordxx4qvu.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "difference between repartition and coalesce , explain it in paint(in pc)",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Repartition & Coalesce",
      "createdAt": "2025-01-11T07:02:43.414Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67821793d24f993c6c88c303",
      "submissionId": {
        "_id": "67821793d24f993c6c88c2fb",
        "status": "approved",
        "adminComment": "approved.",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Coforge",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736578563/sbvkyxknft4ordxx4qvu.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "input : Hi Hello World\noutput : World Hello Hi\n\nsolve using python",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Reverse the sentance",
      "createdAt": "2025-01-11T07:02:43.414Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67821c51d24f993c6c88c325",
      "submissionId": {
        "_id": "67821c51d24f993c6c88c320",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Affine",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736579257/c4tgip7bhyieq9woark7.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "I have deleted one partition from HDFS end , now will my metastore identify that \nmissed partition ?",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Missing partitions",
      "createdAt": "2025-01-11T07:22:57.269Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67821c51d24f993c6c88c327",
      "submissionId": {
        "_id": "67821c51d24f993c6c88c320",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Affine",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736579257/c4tgip7bhyieq9woark7.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "How you will decide the Spark Configuration properties",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Spark configuration properties",
      "createdAt": "2025-01-11T07:22:57.269Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67821c51d24f993c6c88c329",
      "submissionId": {
        "_id": "67821c51d24f993c6c88c320",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Affine",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736579257/c4tgip7bhyieq9woark7.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Name|Age|Education|Year\nRam|28|Maths,Physics,Chemistry|2021\nRakesh|29|Biology,Physics,Chemistry|2021\nMadhu|21|Maths,Physics,Chemistry|2021\nSuman|21|Maths,Physics|2021\nRadhika|21||2021\n\nprocess the data and transform the column \"Education\". expalin the variations of explode (explode,explode_outer,poseexplode,poseexplode_outer)",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": false,
      "summary": "Explode function",
      "createdAt": "2025-01-11T07:22:57.270Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67821c51d24f993c6c88c328",
      "submissionId": {
        "_id": "67821c51d24f993c6c88c320",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Affine",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736579257/c4tgip7bhyieq9woark7.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "    val data = Seq(\n      (1, Seq(2, 3, 4)),\n      (2, Seq(1, 3, 4)),\n      (3, Seq(1, 2)),\n      (4, Seq(1, 2))\n    )\n\ngiven userid and friendslist. find the mutual friends between two friends",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " Mutual friend list",
      "createdAt": "2025-01-11T07:22:57.269Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67821c51d24f993c6c88c326",
      "submissionId": {
        "_id": "67821c51d24f993c6c88c320",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Affine",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736579257/c4tgip7bhyieq9woark7.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": " What is the diff between stages and tasks ?\ndiiference between cache and persist?\ndifference between client and cluster mode?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": "Spark UI",
      "createdAt": "2025-01-11T07:22:57.269Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67821c51d24f993c6c88c324",
      "submissionId": {
        "_id": "67821c51d24f993c6c88c320",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Affine",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736579257/c4tgip7bhyieq9woark7.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "I want to change my internal table to external table , what is the command ?",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Hive managed table",
      "createdAt": "2025-01-11T07:22:57.269Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67821c51d24f993c6c88c32a",
      "submissionId": {
        "_id": "67821c51d24f993c6c88c320",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Affine",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736579257/c4tgip7bhyieq9woark7.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "two sum in scala",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Sum of 2 numbers in scala",
      "createdAt": "2025-01-11T07:22:57.270Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67821c51d24f993c6c88c322",
      "submissionId": {
        "_id": "67821c51d24f993c6c88c320",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Affine",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736579257/c4tgip7bhyieq9woark7.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Project Architecture and related questions",
      "images": [],
      "category": "project based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Project Architecture",
      "createdAt": "2025-01-11T07:22:57.269Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67821c51d24f993c6c88c32b",
      "submissionId": {
        "_id": "67821c51d24f993c6c88c320",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Affine",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736579257/c4tgip7bhyieq9woark7.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "given an array, push the zeros to end and print the rearranged array using scala",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Rearranged array",
      "createdAt": "2025-01-11T07:22:57.270Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67821c51d24f993c6c88c323",
      "submissionId": {
        "_id": "67821c51d24f993c6c88c320",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Affine",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736579257/c4tgip7bhyieq9woark7.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Explain the Hive Architecture ?\nWhat is meant by METASTORE ?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Hive metastore",
      "createdAt": "2025-01-11T07:22:57.269Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67828052d24f993c6c88c679",
      "submissionId": {
        "_id": "67828051d24f993c6c88c676",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Astrosoft Technologies",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736605238/uyexww0u2mfraot0ftvs.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "There are n children standing in a line. Each child is assigned a rating value given in the integer array ratings.\n\nYou are giving candies to these children subjected to the following requirements:\n\nEach child must have at least one candy.\nChildren with a higher rating get more candies than their neighbors.\nReturn the minimum number of candies you need to have to distribute the candies to the children.\nInput: [1,2,2]\nOutput: 4",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " Candies to children",
      "createdAt": "2025-01-11T14:29:38.171Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67828052d24f993c6c88c67a",
      "submissionId": {
        "_id": "67828051d24f993c6c88c676",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Astrosoft Technologies",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736605238/uyexww0u2mfraot0ftvs.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "write a program to check give string is palindrome or not \nstr=\" A man , a plane, a canal\"",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Palindrome string",
      "createdAt": "2025-01-11T14:29:38.171Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67828052d24f993c6c88c678",
      "submissionId": {
        "_id": "67828051d24f993c6c88c676",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Astrosoft Technologies",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736605238/uyexww0u2mfraot0ftvs.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "There is a file in lambda A and how to do you move that same file to lambda B",
      "images": [],
      "category": "scenario based",
      "difficulty": "Easy",
      "isFree": false,
      "summary": "File in Lambda",
      "createdAt": "2025-01-11T14:29:38.171Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67828d60d24f993c6c88c6c2",
      "submissionId": {
        "_id": "67828d60d24f993c6c88c6bf",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Tiger Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736608484/fedy8jztinldmpqi9aly.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Input:\ntable\nid\tname\n1\tIndia\n2\tPakistan\n3\tBangladesh\n4\tSrilanka\n5\tAfghanistan\n\noutput:\nIndia Vs Pakistan\nPakistan Vs Bangladesh\nSrilanka Vs Afghanistan\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Matches between countries",
      "createdAt": "2025-01-11T15:25:20.766Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67828d60d24f993c6c88c6c1",
      "submissionId": {
        "_id": "67828d60d24f993c6c88c6bf",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Tiger Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736608484/fedy8jztinldmpqi9aly.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Input: \nstudent_id\t\tsubject\t\tmarks\n1\t\tEnglish\t\t50\n1\t\tMaths\t\t90\n1\t\tScience\t\t70\n2\t\tEnglish\t\t60\n2\t\tMaths\t\t80\n2\t\tScience\t\t90\n\noutput:\nsubject,first_mark\nThe output should contain subject and first_mark of each subject in descending order.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Top marks in each subject",
      "createdAt": "2025-01-11T15:25:20.766Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67828d60d24f993c6c88c6c3",
      "submissionId": {
        "_id": "67828d60d24f993c6c88c6bf",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Tiger Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736608484/fedy8jztinldmpqi9aly.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "What is difference betweem hive internal and external table?\nWhy Spark is faster than MP?\nWhat is repartition in Spark?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Spark theory",
      "createdAt": "2025-01-11T15:25:20.766Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67849208d24f993c6c88cca1",
      "submissionId": {
        "_id": "67849207d24f993c6c88cc9f",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "synchrony",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736741139/lrrvw8qffmwzwf7lisft.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "what is Lazy evaluation in spark\nDifference between cache and persist and their syntax\n",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Lazy evaluation",
      "createdAt": "2025-01-13T04:09:44.092Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67849208d24f993c6c88cca3",
      "submissionId": {
        "_id": "67849207d24f993c6c88cc9f",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "synchrony",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736741139/lrrvw8qffmwzwf7lisft.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Given below 2 tables what are outupts for each join\nTable 1\nId\n1\nNull\nNull\n1 \n\nTable 2\nId\nNull\n1\nNull\n1 \n\ninner join \nleft outer join \nright outer \nfull \n",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " SQL Joins",
      "createdAt": "2025-01-13T04:09:44.092Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67849208d24f993c6c88cca5",
      "submissionId": {
        "_id": "67849207d24f993c6c88cc9f",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "synchrony",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736741139/lrrvw8qffmwzwf7lisft.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Below is the in input generate output as below which consists of no of not null values in each column \t \nCol A\tCol B\tCol C\n1\t1\t1\n2\t2\t2\n3\tNULL\t3\n4\tNULL\tNULL\n5\tNULL\tNULL\n \t \t \n \t \t \nOutput\t \t \nCol A\tCol B\tCol C\n5\t2\t3\n\nUse of union fuction\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " Count non-null values",
      "createdAt": "2025-01-13T04:09:44.092Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67849208d24f993c6c88cca2",
      "submissionId": {
        "_id": "67849207d24f993c6c88cc9f",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "synchrony",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736741139/lrrvw8qffmwzwf7lisft.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "you have a csv file with columns adhaar_ID , name , dob, transaction_id, trancsaction_amount, load_timestamp on hdfs path \"/another/hdfs/path/csv_adhaar\"\nadhaar_ID is like a nation id for a person living in India\nname : name of the person who did a transaction \ndob : dob of the person who did a transaction\ntransaction_id: id for each transaction done\ntransaction_amount : amount used for transaction\nload_timestamp : time when the transaction loaded into the table.\nhas context menu\n\nfind the person who did the second least transaction done last month using spark\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Aadhaar Transaction",
      "createdAt": "2025-01-13T04:09:44.092Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67849208d24f993c6c88cca4",
      "submissionId": {
        "_id": "67849207d24f993c6c88cc9f",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "synchrony",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736741139/lrrvw8qffmwzwf7lisft.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "We have 3 tables A,B,C .write a sql query to fetch details from table B which are not in A,C\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Fetch details from tables",
      "createdAt": "2025-01-13T04:09:44.092Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67866f79d24f993c6c88d57c",
      "submissionId": {
        "_id": "67866f79d24f993c6c88d57a",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Zeta",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736863112/xj63i3hxqmvd2tbbdgwo.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "what is set in python \n",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": "Python set ",
      "createdAt": "2025-01-14T14:06:49.607Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67866f79d24f993c6c88d57e",
      "submissionId": {
        "_id": "67866f79d24f993c6c88d57a",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Zeta",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736863112/xj63i3hxqmvd2tbbdgwo.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Table Name : Products\n\nColumn_Name\tType\n\nproduct_id\tint\nproduct_name\tvarchar(50)\ncategory\tvarchar(50)\n\nproduct_id is Primary Key of this table.\n\nTable Name : Sales\n\nColumn_Name\tType\n\nproduct_id\tint\nyear\tint\ntotal_sales_revenue\tDECIMAL(10, 2)\n\n\nproduct_id, year is the Primary Key of this table.\nproduct_id is the Foreign key to Products table.\n\nWrite a sql query to find the products whose total sales revenue has increased every year. Include the product_id , product_name and category in the result. Sort the result by product_id.\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Increase in sales revenue",
      "createdAt": "2025-01-14T14:06:49.607Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67866f79d24f993c6c88d57f",
      "submissionId": {
        "_id": "67866f79d24f993c6c88d57a",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Zeta",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736863112/xj63i3hxqmvd2tbbdgwo.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Table Name : login_details\n\nColumn Name\tType\ntimes\ttime\nstatus\tvarchar(3)\n\ntimes is the primary key column for this table and increasing in order.\n'in'\n'out'\n\n\nThis table provides login and logoff details of one user.\n\nWrite a SQL query to to reqpresent the different periods (in mins) when user was logged in.\n\n\n\n\n\ntimes\tstatus\n10:00:00\ton\n10:01:00\ton\n10:02:00\ton\n10:03:00\toff\n10:04:00\ton\n10:05:00\ton\n10:06:00\toff\n10:07:00\toff\n10:08:00\toff\n10:09:00\ton\n10:10:00\ton\n10:11:00\ton\n10:12:00\ton\n10:13:00\toff\n10:14:00\toff\n10:15:00\ton\n10:16:00\toff\n10:17:00\toff\n\n\n\nlog_on\tlog_off\tduration\n10:00:00\t10:03:00\t3\n10:04:00\t10:06:00\t2\n10:09:00\t10:13:00\t4\n10:15:00\t10:16:00\t1",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " Users login activity",
      "createdAt": "2025-01-14T14:06:49.607Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67866f79d24f993c6c88d580",
      "submissionId": {
        "_id": "67866f79d24f993c6c88d57a",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Zeta",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736863112/xj63i3hxqmvd2tbbdgwo.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "write a program to find repeated words from given list",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Repeated words",
      "createdAt": "2025-01-14T14:06:49.607Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67866f79d24f993c6c88d57d",
      "submissionId": {
        "_id": "67866f79d24f993c6c88d57a",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Zeta",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736863112/xj63i3hxqmvd2tbbdgwo.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "write a program to find the repeated word in given list.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "  Repeated words",
      "createdAt": "2025-01-14T14:06:49.607Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678761dad24f993c6c88db72",
      "submissionId": {
        "_id": "678761dad24f993c6c88db6e",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Accenture",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736924839/ge0lzdhtfjgqv87xbkib.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Find the 3-month rolling average of total revenue from purchases given a table with users, their purchase amount, and date purchased (YYYY-MM-DD). Output the year-month (YYYY-MM) and 3-month rolling average of revenue, sorted from earliest month to latest month.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " Rolling average of revenue",
      "createdAt": "2025-01-15T07:20:58.597Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678761dad24f993c6c88db70",
      "submissionId": {
        "_id": "678761dad24f993c6c88db6e",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Accenture",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736924839/ge0lzdhtfjgqv87xbkib.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Assume that you are working with Big Data in a project that follows the Star Schema data warehousing model. In this architecture, you have fact tables and dimension tables. There may be situations where the dimension tables are relatively small, while the fact tables are extremely large. You are tasked with preparing a report that combines both the fact and dimension tables.\n\nGiven this scenario, what strategies or methods would you use to optimize the processing speed when combining data from these tables? How would you ensure faster query performance and efficient processing in this case?",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Processing dimensional modelling tables",
      "createdAt": "2025-01-15T07:20:58.597Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678761dad24f993c6c88db71",
      "submissionId": {
        "_id": "678761dad24f993c6c88db6e",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Accenture",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736924839/ge0lzdhtfjgqv87xbkib.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Suppose you have two dataframes:\nThe first dataframe contains columns ID (integer) and name.\nThe second dataframe contains columns ID (string) and salary.\nIf you attempt to join these two dataframes on the ID column, what will be the behavior when the data types of ID differ (i.e., one being an integer and the other a string)? Specifically, how will SQL Server handle this join operation, and will the join succeed?",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "Spark dataframes join ",
      "createdAt": "2025-01-15T07:20:58.597Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6787c757d24f993c6c88e02b",
      "submissionId": {
        "_id": "6787c757d24f993c6c88e028",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "American Airlines",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736951425/fxeqhp5bbbtadcmud5ez.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Implement SCD2 in Address table",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Implementation of SCD-2",
      "createdAt": "2025-01-15T14:33:59.281Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6787c757d24f993c6c88e02c",
      "submissionId": {
        "_id": "6787c757d24f993c6c88e028",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "American Airlines",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736951425/fxeqhp5bbbtadcmud5ez.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "What are the different type of SCDs? Explain with examples.",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": "Types of SCD ",
      "createdAt": "2025-01-15T14:33:59.281Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6787c757d24f993c6c88e02a",
      "submissionId": {
        "_id": "6787c757d24f993c6c88e028",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "American Airlines",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1736951425/fxeqhp5bbbtadcmud5ez.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "You have 2 tables namely A and B. Perform left join, inner join, full outer join on both the tables and give the join results\n\nA :\n\n 1\n 2\n 1\n NULL\n\nB:\n 1\n 1\n NULL",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": "SQL Joins ",
      "createdAt": "2025-01-15T14:33:59.281Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "678899ffd24f993c6c88e521",
      "submissionId": {
        "_id": "678899ffd24f993c6c88e51e",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "CAPGEMINI",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737003319/hyhb4bwlg5sd1sdc3uk0.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Input:\ndata1 = [(\"Alice\", 1), (\"Bob\", 2), (\"Charlie\", 3)]\n\ndata2 = [(1, \"HR\"), (2, \"Finance\"), (4, \"IT\")]\n\ndata1_schema = [\"name\", \"dept_id\"]\n\ndata2_schema= [\"dept_id\", \"department\"]\n\nJoin these two tables and display the below output in pyspark:\n1,\"Alice\",\"HR\"\n2,\"Bob\",\"Finance\"\n4,NULL,\"IT\"",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": "  Spark dataframe role display",
      "createdAt": "2025-01-16T05:32:47.734Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678899ffd24f993c6c88e523",
      "submissionId": {
        "_id": "678899ffd24f993c6c88e51e",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "CAPGEMINI",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737003319/hyhb4bwlg5sd1sdc3uk0.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Emp - id, location, salary \nDep - depid, emp_id\n\nemp_data = [(1,'blr',10000),(2,'chn',20000),(3,'pune',5000)]\nemp_schema = ['id','location','salary']\n\ndep_data = [(10,1),(10,2),(20,3)]\ndep_schema = ['depid','empid']\nfrom depid 10 how many emp we have in Pune and total salary in pyspark?",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " ",
      "createdAt": "2025-01-16T05:32:47.734Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678899ffd24f993c6c88e520",
      "submissionId": {
        "_id": "678899ffd24f993c6c88e51e",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "CAPGEMINI",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737003319/hyhb4bwlg5sd1sdc3uk0.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Input:\ndata1 = [(\"Alice\", 1), (\"Bob\", 2), (\"Charlie\", 3)] \n\ndata2 = [(1, \"HR\"), (2, \"Finance\"), (4, \"IT\")]\n\ndata1_schema = [\"name\", \"dept_id\"]\n\ndata2_schema= [\"dept_id\", \"department\"]\n\nJoin these two tables and display the below output in pyspark:\n1,\"Alice\",\"HR\"\n2,\"Bob\",\"Finance\"",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Spark dataframe dept display",
      "createdAt": "2025-01-16T05:32:47.734Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678899ffd24f993c6c88e522",
      "submissionId": {
        "_id": "678899ffd24f993c6c88e51e",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "CAPGEMINI",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737003319/hyhb4bwlg5sd1sdc3uk0.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "DIfference between list and tuple\n",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " List & Tuple",
      "createdAt": "2025-01-16T05:32:47.734Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6788c0fad24f993c6c88e646",
      "submissionId": {
        "_id": "6788c0f9d24f993c6c88e643",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Kirana Capital",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737014419/brwtqcavrlu2xo4gdd4f.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "what is ingress in k8's",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Ingress in K8",
      "createdAt": "2025-01-16T08:19:06.070Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6788c0fad24f993c6c88e64a",
      "submissionId": {
        "_id": "6788c0f9d24f993c6c88e643",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Kirana Capital",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737014419/brwtqcavrlu2xo4gdd4f.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Need to derive the due column from the data. There a table with columns load_id, demand,collection, demanddate,collectiondate.\nUser a demand a loan amount daily as 100. he needs to pay to bank daily basics i.e,  collection column. if the user paid on that day then due will be zero as user paid on the same day right only. If he skips the amount which he needs pay then due will be one, one next day user requested 100 and paid 100 then due will one because the previous day he didnt paid right so due will be one. attaching the details below.\nInput - demand,collection, demanddate,collectiondate \n   100 100 2025010120250101 \n  100 100 20250102 20250102 \n  100 0 20250103 20250103 \n  100 100 20250104 20250104 \n  100 0 20250105 20250105 \n  100 300 20250106 20250106 . \noutput - \ndemand,collection, demanddate,collectiondate, due \n   100 100 2025010120250101 0\n  100 100 20250102 20250102 0\n  100 0 20250103 20250103 1\n  100 100 20250104 20250104 1\n  100 0 20250105 20250105 2\n  100 300 20250106 20250106 0. \n\nSummary of the question if user paid the demanded amount the due will be 0, if user skips amount the due will be 1, due will increase as days will increase if wont pay, user skips for two days then due will 2(5 row). if user paid all the due amount then due will become zero(last row). \n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " User due loan amount",
      "createdAt": "2025-01-16T08:19:06.071Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6788c0fad24f993c6c88e648",
      "submissionId": {
        "_id": "6788c0f9d24f993c6c88e643",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Kirana Capital",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737014419/brwtqcavrlu2xo4gdd4f.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "what are clustering key in snowfalke",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " clustering key in snowflake",
      "createdAt": "2025-01-16T08:19:06.071Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6788c0fad24f993c6c88e649",
      "submissionId": {
        "_id": "6788c0f9d24f993c6c88e643",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Kirana Capital",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737014419/brwtqcavrlu2xo4gdd4f.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "find the second highest salary from the table",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Second highest salary",
      "createdAt": "2025-01-16T08:19:06.071Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6788c0fad24f993c6c88e647",
      "submissionId": {
        "_id": "6788c0f9d24f993c6c88e643",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Kirana Capital",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737014419/brwtqcavrlu2xo4gdd4f.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "how can we reduced snowflake cost. and explain snowflake architecture ",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Reduce snowflake cost",
      "createdAt": "2025-01-16T08:19:06.070Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6788c0fad24f993c6c88e645",
      "submissionId": {
        "_id": "6788c0f9d24f993c6c88e643",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Kirana Capital",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737014419/brwtqcavrlu2xo4gdd4f.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "how the data is stored in snowflake",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Data storage in redshift",
      "createdAt": "2025-01-16T08:19:06.070Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6788fdd5d24f993c6c88e850",
      "submissionId": {
        "_id": "6788fdd5d24f993c6c88e84c",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "delloite",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737030527/psat9ila6zkdkaofp4uy.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "write a pyspark program to find the word count of a given txt file\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import split, explode, regexp, regexp_extract, col\n\nspark=SparkSession.builder.appName(\"count\").master(\"local\").getOrCreate()\ndf=spark.read.text(\"D:\\python_final\\word_count_sample.txt\")\ndf.show()\ndf_split=df.withColumn(\"result\",split(\"value\",\" \")).drop(\"value\")\ndf_explode=df_split.withColumn(\"words\",explode(df_split[\"result\"]))\ndf_explode.show()\ndf_explode.groupby(\"words\").count().orderBy(col(\"count\").desc()).show()",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Word count in txt file",
      "createdAt": "2025-01-16T12:38:45.538Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6788fdd5d24f993c6c88e84f",
      "submissionId": {
        "_id": "6788fdd5d24f993c6c88e84c",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "delloite",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737030527/psat9ila6zkdkaofp4uy.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "I have a data with 2 columns id and count we have to display name column based on the value of an count column and count column should be like 0 to count\ninput:+---+-----+\n| id|count|\n+---+-----+\n|  1|    2|\n|  2|    3|\n|  3|    4|\n+---+-----+\noutput:\n+---+---+\n| id|seq|\n+---+---+\n|  1|  0|\n|  1|  1|\n|  2|  0|\n|  2|  1|\n|  2|  2|\n|  3|  0|\n|  3|  1|\n|  3|  2|\n|  3|  3|\nsolution:\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import expr, explode\nfrom pyspark.sql.functions import concat_ws,collect_list\n\n# Initialize Spark session\nspark = SparkSession.builder.appName(\"RepeatIDs\").getOrCreate()\n\n# Create a DataFrame with 'id' and 'count' columns\ndata = [(1, 2), (2, 3), (3, 4)]\ncolumns = [\"id\", \"count\"]\n\ndf = spark.createDataFrame(data, columns)\ndf.show()\n\n# Create a sequence from 0 to count-1, then expand it using explode\ndf.createOrReplaceTempView(\"repeat\")\ndf_expanded = (df.withColumn(\n    \"seq\", explode(expr(\"sequence(0, count - 1)\")))).drop(\"count\")\ndf_expanded.show()\n#df_expanded.selectExpr(\"id\", \"explode(seq) as repeated\").show() # Explode sequence to rows\n\n# Show the result\n\ndf_expanded.show(truncate=False)\nspark.sql(\"select id,explode(sequence(0,count-1)) from repeat\").show()\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Spark dataframes sequencing",
      "createdAt": "2025-01-16T12:38:45.538Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6788fdd5d24f993c6c88e84e",
      "submissionId": {
        "_id": "6788fdd5d24f993c6c88e84c",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "delloite",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737030527/psat9ila6zkdkaofp4uy.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Suppose you're reading the data from csv files but it has multiple delimiters how can you read the data from csv in pyspark \ndf_final_csv=df_csv2.withColumn(\"value\",expr(\"regexp_replace(value,'[^a-zA-Z0-9]',',')\"))",
      "images": [],
      "category": "scenario based",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Handling multiple delimiters",
      "createdAt": "2025-01-16T12:38:45.538Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67894b3ed24f993c6c88ea67",
      "submissionId": {
        "_id": "67894b3ed24f993c6c88ea65",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "EPAM",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737049930/fbvo4wc5a0r8qykp6gle.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Given a dataframe containing the customer transactions - \nschema\n----------------------------------------\ncustomer_id                     String\ntransaction_timestamp    Timestamp\n----------------------------------------\nFind the distinct number of customers who ordered at least once every month in the past year",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Distinct orders from customers",
      "createdAt": "2025-01-16T18:09:02.788Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67894b3ed24f993c6c88ea68",
      "submissionId": {
        "_id": "67894b3ed24f993c6c88ea65",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "EPAM",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737049930/fbvo4wc5a0r8qykp6gle.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "- Explain AQE, what are the benefits of AQE. How does AQE help (Dynamically Coalescing, Dynamically handling Partition Skew, Dynamically Switching Join Strategies).\n- Have used UDFs in Spark? What is your opinion about the same? What is it's impact on performance? How about vectorized UDFs?\n- Databricks and different types of compute in Databricks.\n- What are the different join strategies in Spark?\n- Have you used constraints in Databricks?\n- What is Delta format? What is the advantage it gives? Explain vacuum command?\n- What is small file problem? How can you solve it?\n- What are the different security options in BigQuery?\n- What are the different types of storage in BigQuery?\n- What is row level and column level security in BigQuery?\n",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " DE theory",
      "createdAt": "2025-01-16T18:09:02.788Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67894b3ed24f993c6c88ea69",
      "submissionId": {
        "_id": "67894b3ed24f993c6c88ea65",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "EPAM",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737049930/fbvo4wc5a0r8qykp6gle.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Given a file, read the contents of the file and then create a word counter function using python file handler(Not using Pyspark or pandas, use the python basic file handler here)",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": "Python file handler ",
      "createdAt": "2025-01-16T18:09:02.788Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678951fdd24f993c6c88eb09",
      "submissionId": {
        "_id": "678951fcd24f993c6c88eb05",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Quantium Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737051896/o8vmfyekob1xhdlyeq69.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "You have a Spark pipeline that is working properly in Dev environment, you finished your development and testing and you are releasing it for UAT in the UAT environment, but there you notice that the Spark job is taking too long to complete. How would you approach this situation? What could be the case?\nHint - the data in Dev and UAT can vary significantly in size and pattern.",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Data testing in UAT",
      "createdAt": "2025-01-16T18:37:49.163Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678951fdd24f993c6c88eb07",
      "submissionId": {
        "_id": "678951fcd24f993c6c88eb05",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Quantium Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737051896/o8vmfyekob1xhdlyeq69.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Given multiple data sources -> DBs like Oracle/Postgres, Flat files, APIs, SFTP etc. Design an end to end architecture in GCP using different services such that it can fulfill both batch and real time data needs for the end users. The solution should have an efficient way to store and process huge amount of data and provisions for end users to query the data and do dashboarding.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Design architecture handling batch&real data",
      "createdAt": "2025-01-16T18:37:49.163Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678951fdd24f993c6c88eb08",
      "submissionId": {
        "_id": "678951fcd24f993c6c88eb05",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Quantium Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737051896/o8vmfyekob1xhdlyeq69.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Follow up to the design question\n1) What are some high level optimization techniques that you would use in your data warehouse? Explain them.\n2) How do you make sure that the entire workflow is automated?\n3) Will you choose different ingestion tools for different data sources? What is your opinion?\n4) How about making sure that the data is secured and only the right people have access to it?",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Data design questions",
      "createdAt": "2025-01-16T18:37:49.163Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67895569d24f993c6c88eb32",
      "submissionId": {
        "_id": "67895569d24f993c6c88eb30",
        "status": "approved",
        "adminComment": "Approved",
        "country": "United Kingdom",
        "ctc": "60L-70L",
        "companyName": "BLOOMBERG",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737053541/prcak4p5og1wiipfsv7x.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "1) SQL Challenge: \n\nYou have been given two tables: \"orders\" and \"customers.\" The \"orders\" table contains order information, including the order ID, customer ID, order date, and order amount. The \"customers\" table contains customer information, including the customer ID, customer name, and customer city. \n\nWrite a SQL query to retrieve the top 5 customers (based on the total order amount) from the city of \"London\" who have placed at least 2 orders. The result should include the customer name, city, and total order amount. \n\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Top customers in london",
      "createdAt": "2025-01-16T18:52:25.246Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67895569d24f993c6c88eb34",
      "submissionId": {
        "_id": "67895569d24f993c6c88eb30",
        "status": "approved",
        "adminComment": "Approved",
        "country": "United Kingdom",
        "ctc": "60L-70L",
        "companyName": "BLOOMBERG",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737053541/prcak4p5og1wiipfsv7x.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "\n3) PySpark Challenge: \n\nYou have been given a dataset containing information about user activity on a website. The dataset consists of the following columns: \"user_id\" (integer), \"timestamp\" (timestamp), \"page_visited\" (string). Your task is to write a PySpark program to perform the following operations: \n\nRead the dataset into a PySpark DataFrame. \n\nCalculate the total count of page visits for each user. \n\nFind the user with the highest number of page visits. \n\nCalculate the average number of page visits per user. \n\nWrite the results to a new CSV file named \"user_activity_summary.csv\" with the following columns: \"user_id,\" \"total_page_visits,\" \"average_page_visits\". \n\nFor this challenge, you can assume that the dataset is in a CSV file format and the column delimiter is a comma. ",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "Page visitors in pyspark",
      "createdAt": "2025-01-16T18:52:25.246Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67895569d24f993c6c88eb33",
      "submissionId": {
        "_id": "67895569d24f993c6c88eb30",
        "status": "approved",
        "adminComment": "Approved",
        "country": "United Kingdom",
        "ctc": "60L-70L",
        "companyName": "BLOOMBERG",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737053541/prcak4p5og1wiipfsv7x.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "2) Python Challenge: \n\nYou are given a CSV file named \"data.csv\" that contains customer information. The file has the following columns: \" name,\" \"address,\" \"email,\" and \"phone.\" Your task is to write a Python program to read the CSV file and perform the following operations: \n\nValidate the email addresses and phone numbers to ensure they are in the correct format. \n\nWrite the cleaned data to a new CSV file named \"cleaned_data.csv\" with the same column structure. \n\nFor email validation, assume a valid email address has the format: username@domain.com. For phone number validation, assume a valid phone number has 10 digits (no other characters). \n\nNote: You can use the built-in csv module in Python to read and write CSV files. \n\nRemove any leading or trailing whitespace from the values in the \"customer_name,\" \"email,\" and \"phone_number\" columns. \n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " CSV data processing",
      "createdAt": "2025-01-16T18:52:25.246Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678b36b1d24f993c6c88efee",
      "submissionId": {
        "_id": "678b36b1d24f993c6c88efec",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Natwest",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737176261/xhjn4itnsexbxvzlgobk.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "We will have the employee table empid and mgrid \nwirte the Pyspark query for to find the manager level  and employee count reporting to them ",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Employees reporting to manager",
      "createdAt": "2025-01-18T05:05:53.607Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678b36b1d24f993c6c88eff0",
      "submissionId": {
        "_id": "678b36b1d24f993c6c88efec",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Natwest",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737176261/xhjn4itnsexbxvzlgobk.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "explain you project architecture and your role and your teams roles.",
      "images": [],
      "category": "project based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Project Architecture",
      "createdAt": "2025-01-18T05:05:53.607Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "678b36b1d24f993c6c88eff1",
      "submissionId": {
        "_id": "678b36b1d24f993c6c88efec",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Natwest",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737176261/xhjn4itnsexbxvzlgobk.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "we have 2 tables tableA and tableB with column B how many rows output for all 4 join types\nA   B\n1    1\n1    1\n      1\n      1",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " SQL Joins",
      "createdAt": "2025-01-18T05:05:53.607Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "678b36b1d24f993c6c88efef",
      "submissionId": {
        "_id": "678b36b1d24f993c6c88efec",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Natwest",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737176261/xhjn4itnsexbxvzlgobk.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "Which is frequent used file format and explain different file formats and their usage in your project.",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " File formats in project",
      "createdAt": "2025-01-18T05:05:53.607Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "678b3abfd24f993c6c88effd",
      "submissionId": {
        "_id": "678b3abfd24f993c6c88effb",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Mcafee",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737177251/vtgl8szfjhgczvofqr1m.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "we have customer table with orderdate, orderid, customerid,qty the output should be the with customerid and days_taken_to_2nd_order_from1st and  days_taken_to_3rd_order_from1st",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737177532/pcbshbskuirvyag6p036.png"
      ],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Days taken for next order",
      "createdAt": "2025-01-18T05:23:11.983Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678b3abfd24f993c6c88efff",
      "submissionId": {
        "_id": "678b3abfd24f993c6c88effb",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Mcafee",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737177251/vtgl8szfjhgczvofqr1m.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "how are you migrating the databricks workflows.",
      "images": [],
      "category": "project based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Databricks migration",
      "createdAt": "2025-01-18T05:23:11.983Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "678b3abfd24f993c6c88effe",
      "submissionId": {
        "_id": "678b3abfd24f993c6c88effb",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Mcafee",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737177251/vtgl8szfjhgczvofqr1m.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "we have susbscriptions table with subid,tansactionid,duration in the out the duration should be concated as a single value for the respective subid.",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737177728/bchhqs7faxw55kvv9hya.png"
      ],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "combine subscriptions",
      "createdAt": "2025-01-18T05:23:11.983Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678b5989d24f993c6c88f091",
      "submissionId": {
        "_id": "678b5989d24f993c6c88f08d",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Axa XL",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737185011/nrkjhmk6yki5hqjwdzfr.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "In below mention PySpark Operation, how many will be executed in driver node vs worker node\nFunction Invocation\nFilter \nMap\nResult and Formatting\nreduceByKeys\nSave file to AWS S3 Bucket",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Execution tasks",
      "createdAt": "2025-01-18T07:34:33.441Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678b5989d24f993c6c88f08f",
      "submissionId": {
        "_id": "678b5989d24f993c6c88f08d",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Axa XL",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737185011/nrkjhmk6yki5hqjwdzfr.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Given the below dataset using pyspark, find the employee with 2nd highest salary\nemp_id|name|salary|dept_id\n1|Donald|2600|Sales\n2|Douglas|2600|Sales\n3|Jennifer|4400|IT\n4|Michael|13000|IT\n5|Pat|6000|HR\n6|Susan|6500|IT\n7|Hermann|10000|IT\n8|Shelley|12008|Sales\n9|William|8300|HR\n10|Steven|24000|IT\n11|Neena|17000|HR\n12|Lex|17000|IT\n13|Alexander|9000|Sales\n14|Bruce|6000|HR\n15|David|4800|IT",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Employee second highest salary",
      "createdAt": "2025-01-18T07:34:33.441Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "678b5989d24f993c6c88f092",
      "submissionId": {
        "_id": "678b5989d24f993c6c88f08d",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Axa XL",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737185011/nrkjhmk6yki5hqjwdzfr.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Given the below dataset, read the file in PySpark and transform the dataset such that is has 3 columns :- first_name, last_name, age. \nName ~| Age\nArjun, Kapoor ~| 25\nAlia, Bhatt ~| 24\nDeepika, Padukone ~| 26\nRanbir, Kapoor ~|26",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Actors data transformation",
      "createdAt": "2025-01-18T07:34:33.442Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678b5989d24f993c6c88f090",
      "submissionId": {
        "_id": "678b5989d24f993c6c88f08d",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Axa XL",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737185011/nrkjhmk6yki5hqjwdzfr.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Given below 2 tables using SQL, find all the number of records from left, right and inner join output\ntable 1 :\n1\n2\n1\n2\n4\nNULL\n\ntable 2:\n1\n1\n2\n2\n3\nNULL",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " SQL Joins",
      "createdAt": "2025-01-18T07:34:33.441Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "678b5f53d24f993c6c88f0ba",
      "submissionId": {
        "_id": "678b5f53d24f993c6c88f0b7",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": " McKinsey",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737185937/diazmq98jqdcqlrnvjhz.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write a SQL query to retrieve number of customers who have made a purchase in last 30 days but did not purchase anything in the previous 30 days",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " No purchase made",
      "createdAt": "2025-01-18T07:59:15.579Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678b5f53d24f993c6c88f0bd",
      "submissionId": {
        "_id": "678b5f53d24f993c6c88f0b7",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": " McKinsey",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737185937/diazmq98jqdcqlrnvjhz.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Given the below PySpark script, how many time will the script actually execute?\n\ndf1 = spark.read.parquet()\ndf2 = df1.filter()\ndf3 = df2.groupBy().agg()\ndf4 = df3.filter()\n\ndf4.write.parquet()\ndf4.count()",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Count script execution",
      "createdAt": "2025-01-18T07:59:15.579Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678b5f53d24f993c6c88f0bb",
      "submissionId": {
        "_id": "678b5f53d24f993c6c88f0b7",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": " McKinsey",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737185937/diazmq98jqdcqlrnvjhz.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "How many types of transformations are present in PySpark. State with an example for each",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Pyspark transformations",
      "createdAt": "2025-01-18T07:59:15.579Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678b5f53d24f993c6c88f0bc",
      "submissionId": {
        "_id": "678b5f53d24f993c6c88f0b7",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": " McKinsey",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737185937/diazmq98jqdcqlrnvjhz.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Describe a ETL pipeline you deployed on AWS service. What all transformation did you apply? How did you perform delta detection? How did you orchestrate your pipeline etc",
      "images": [],
      "category": "project based",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Delta data detection",
      "createdAt": "2025-01-18T07:59:15.579Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678b5f53d24f993c6c88f0b9",
      "submissionId": {
        "_id": "678b5f53d24f993c6c88f0b7",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": " McKinsey",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737185937/diazmq98jqdcqlrnvjhz.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "For every 6 cups of coffee I buy, I would get 7th cup for free. Write a program in python that prints total number of cups I will get given 'n' cups as input",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Totals cups of coffee",
      "createdAt": "2025-01-18T07:59:15.579Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678b74d4d24f993c6c88f0f3",
      "submissionId": {
        "_id": "678b74d4d24f993c6c88f0f0",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "EPAM",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737192231/ik6fxuwilrffrnjprvm5.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "2)\nhow to delete logical duplicates from table?\ncol1 Col2\nA     B\nB     A\nC     D\nD     C\nE     F\n\noutput:\ncol1 col2\nA     B\nC     D\nE     F\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Delete logical duplicates",
      "createdAt": "2025-01-18T09:31:00.611Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678b74d4d24f993c6c88f0f2",
      "submissionId": {
        "_id": "678b74d4d24f993c6c88f0f0",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "EPAM",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737192231/ik6fxuwilrffrnjprvm5.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Q1). mother asked you to bring 2 types of Fruits from Market. You went to Market. Fruit Vendor has the following Fruits\nFruit\n-----\nApple\nBananas\nOranges\n \nYou called your Mom to asked which 2 sets of fruits needs to brought ?\noutput:\nApple, Oranges\nApple Bananas\nBananas Oranges\nWrite a sql query for the above output",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Fruits combination",
      "createdAt": "2025-01-18T09:31:00.611Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678b74d4d24f993c6c88f0f4",
      "submissionId": {
        "_id": "678b74d4d24f993c6c88f0f0",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "EPAM",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737192231/ik6fxuwilrffrnjprvm5.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "3)Python\nrotate the array by K elements [1,2,3,4,5,6] k=3\noutput: [4,5,6,1,2,3]",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Rotate an array",
      "createdAt": "2025-01-18T09:31:00.611Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678b7827d24f993c6c88f104",
      "submissionId": {
        "_id": "678b7826d24f993c6c88f100",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "KOTAK BANK",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737193276/hvcuon1ovhznkckmcwrj.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Write a Code to load nested JSON with dynamic schema in table using pyspark",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Load nested JSON",
      "createdAt": "2025-01-18T09:45:11.007Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "678b7827d24f993c6c88f103",
      "submissionId": {
        "_id": "678b7826d24f993c6c88f100",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "KOTAK BANK",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737193276/hvcuon1ovhznkckmcwrj.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Search target Element in Rotated Sorted Array and return its index(solve it in log(n) complexity)\narr=[4,5,6,7,1,2,3] target=1\noutput: 4\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Index of sorted array",
      "createdAt": "2025-01-18T09:45:11.007Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678b7827d24f993c6c88f102",
      "submissionId": {
        "_id": "678b7826d24f993c6c88f100",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "KOTAK BANK",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737193276/hvcuon1ovhznkckmcwrj.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "python\n1) flatten the nested list [1,2,3,[4,5,[1,2,3]]] \noutput: [1,2,3,4,5,1,2,3]",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Flatten nested list",
      "createdAt": "2025-01-18T09:45:11.007Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678bf5f6d24f993c6c88f44d",
      "submissionId": {
        "_id": "678bf5f6d24f993c6c88f448",
        "status": "approved",
        "adminComment": "Approved",
        "country": "United Kingdom",
        "ctc": "60L-70L",
        "companyName": "Bloomberg UK PLC",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737225150/jevedbklqfknpgbwceo3.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "Data Question : My data is coming from 5 Sources A,B,C,D & E, I have to maintain whole data in one single table how i manage that?",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Data from 5 sources",
      "createdAt": "2025-01-18T18:41:58.612Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678bf5f6d24f993c6c88f44b",
      "submissionId": {
        "_id": "678bf5f6d24f993c6c88f448",
        "status": "approved",
        "adminComment": "Approved",
        "country": "United Kingdom",
        "ctc": "60L-70L",
        "companyName": "Bloomberg UK PLC",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737225150/jevedbklqfknpgbwceo3.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "2. Create a schema in spark, take any example & include various datatype",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Schema in spark",
      "createdAt": "2025-01-18T18:41:58.612Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "678bf5f6d24f993c6c88f44c",
      "submissionId": {
        "_id": "678bf5f6d24f993c6c88f448",
        "status": "approved",
        "adminComment": "Approved",
        "country": "United Kingdom",
        "ctc": "60L-70L",
        "companyName": "Bloomberg UK PLC",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737225150/jevedbklqfknpgbwceo3.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "3. Python Question:\n\nInput : [1,1,2,2,2,3,3,3,3,1]\n\nResult: (1,2),(2,3),(3,4),(1,1)",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "Frequency of numbers ",
      "createdAt": "2025-01-18T18:41:58.612Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678bf5f6d24f993c6c88f44a",
      "submissionId": {
        "_id": "678bf5f6d24f993c6c88f448",
        "status": "approved",
        "adminComment": "Approved",
        "country": "United Kingdom",
        "ctc": "60L-70L",
        "companyName": "Bloomberg UK PLC",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737225150/jevedbklqfknpgbwceo3.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "1. Python Question :\nInput : Put values of list A in list B as shown below\n\nA = [1,2,3,4,5,5,1,1,3,6]\n\nB = [{},[],()]\n\nOutput : [{1,1,1},[2],(3,3),{4},[5,5],(6)]",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " List values formatting",
      "createdAt": "2025-01-18T18:41:58.612Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678de6c2d24f993c6c88fd33",
      "submissionId": {
        "_id": "678de6c2d24f993c6c88fd31",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Publicis Sapient",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737351328/wn5ig5dnkdn1nnoiuli3.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Context: You are tasked with analyzing clickstream data to understand user behavior on a platform. The platform's clickstream data is stored in the following table:\n\nTable: Clickstream\n\n+--------------+-----------+-------------------------------------+\n| Column Name  | Data Type | Description                         |\n+--------------+-----------+-------------------------------------+\n| UserId       | INT       | Unique identifier for each user.    |\n| ClickTime    | DATETIME  | Timestamp of a user's click event.  |\n+--------------+-----------+-------------------------------------+\n\n+--------+---------------------+\n| UserId | ClickTime           |\n+--------+---------------------+\n| 1      | 2025-01-20 10:00:00 |\n| 1      | 2025-01-20 10:15:00 |\n| 1      | 2025-01-20 11:00:00 |\n| 2      | 2025-01-20 09:00:00 |\n| 2      | 2025-01-20 09:45:00 |\n+--------+---------------------+\n\n\nRequirements:\n\nA new session starts if either:\nIt is the first click for the user.\nThe time difference between two consecutive clicks exceeds 30 minutes.\n\nFor each user, determine using Pyspark:\n1. The total number of sessions (TotalSessions).\n2. The total time spent across all sessions (TotalTimeSpent), calculated as the sum of the durations of all their sessions.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " User clicks in platform",
      "createdAt": "2025-01-20T06:01:38.339Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678de6c2d24f993c6c88fd35",
      "submissionId": {
        "_id": "678de6c2d24f993c6c88fd31",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Publicis Sapient",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737351328/wn5ig5dnkdn1nnoiuli3.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "1.How can you control the number of partitions in a DataFrame or RDD?\n2.What are the implications of too many or too few partitions on performance?\n3.How does PySpark handle data shuffling, and how can you minimize its impact?\n4.Why are DataFrames considered more efficient than RDDs in PySpark?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Spark Theory",
      "createdAt": "2025-01-20T06:01:38.339Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "678de6c2d24f993c6c88fd34",
      "submissionId": {
        "_id": "678de6c2d24f993c6c88fd31",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Publicis Sapient",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737351328/wn5ig5dnkdn1nnoiuli3.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Scenario: You are tasked with analyzing the performance using SQL of 4 teams participating in the Asia Cup. The match results are stored in the following table:\n\n+-------------+---------+--------------------------------------+\n| Column Name | Data Type | Description                        |\n+-------------+---------+--------------------------------------+\n| MatchId     | INT      | Unique identifier for each match.   |\n| TeamA       | VARCHAR  | Name of the first team.             |\n| TeamB       | VARCHAR  | Name of the second team.            |\n| RunsA       | INT      | Runs scored by Team A.              |\n| RunsB       | INT      | Runs scored by Team B.              |\n| MatchDate   | DATE     | Date on which the match occurred.   |\n+-------------+---------+--------------------------------------+\nSample Data:\n\n\n+---------+--------+--------+-------+-------+------------+\n| MatchId | TeamA  | TeamB  | RunsA | RunsB | MatchDate  |\n+---------+--------+--------+-------+-------+------------+\n| 1       | India  | Pakistan | 250   | 200   | 2025-01-10 |\n| 2       | India  | Sri Lanka| 300   | 320   | 2025-01-12 |\n| 3       | Pakistan | Bangladesh | 280   | 275   | 2025-01-14 |\n| 4       | Sri Lanka | Bangladesh | 310   | 290   | 2025-01-16 |\n| 5       | India  | Bangladesh | 270   | 260   | 2025-01-18 |\n+---------+--------+--------+-------+-------+------------+\nRequirements:\n\n1.Determine the total matches played by each team.\n2. Calculate the number of matches won by each team (a team wins if it scores more runs than its opponent).\n3. Rank the teams based on their total wins.\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " Asia cup matches",
      "createdAt": "2025-01-20T06:01:38.339Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678ded13d24f993c6c88fd55",
      "submissionId": {
        "_id": "678ded13d24f993c6c88fd51",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Tiger Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737354404/jdnnaeniv9ebyclwxv2x.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "1. How would you handle incremental data loading in a data warehouse to minimize processing time and system overhead?\n2. What are the advantages and disadvantages of using a star schema compared to a snowflake schema?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " DE theory",
      "createdAt": "2025-01-20T06:28:35.421Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "678ded13d24f993c6c88fd53",
      "submissionId": {
        "_id": "678ded13d24f993c6c88fd51",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Tiger Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737354404/jdnnaeniv9ebyclwxv2x.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Question 1:\n\nScenario: A company tracks employee attendance data in the following table:\n\n+-------------+----------+---------------------+\n| Column Name | Data Type | Description |\n+-------------+----------+---------------------+\n| EmployeeId | INT | Unique employee ID. |\n| CheckIn | DATETIME | Employee check-in time. |\n| CheckOut | DATETIME | Employee check-out time. |\n| Date | DATE | Date of attendance. |\n+-------------+----------+---------------------+\nSample Data:\n\n+------------+---------------------+---------------------+------------+\n| EmployeeId | CheckIn | CheckOut | Date |\n+------------+---------------------+---------------------+------------+\n| 1 | 2025-01-01 09:00:00 | 2025-01-01 17:00:00 | 2025-01-01 |\n| 1 | 2025-01-02 09:30:00 | 2025-01-02 16:45:00 | 2025-01-02 |\n| 2 | 2025-01-01 10:00:00 | 2025-01-01 18:00:00 | 2025-01-01 |\n| 3 | 2025-01-01 08:45:00 | 2025-01-01 17:15:00 | 2025-01-01 |\n| 3 | 2025-01-02 08:50:00 | 2025-01-02 17:10:00 | 2025-01-02 |\n+------------+---------------------+---------------------+------------+\nRequirements:\n\n1.Calculate the total working hours for each employee for each day using SQL.\n2.Find the employee with the maximum total working hours across all dates using SQL.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Employee attendance tracker",
      "createdAt": "2025-01-20T06:28:35.421Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "678ded13d24f993c6c88fd54",
      "submissionId": {
        "_id": "678ded13d24f993c6c88fd51",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Tiger Analytics",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737354404/jdnnaeniv9ebyclwxv2x.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Scenario: You are analyzing the sales performance of an online store using the following table:\n\n+--------------+-----------+-----------------------------+\n| Column Name | Data Type | Description |\n+--------------+-----------+-----------------------------+\n| OrderId | INT | Unique identifier for orders. |\n| CustomerId | INT | Unique identifier for customers. |\n| OrderDate | DATE | Date when the order was placed. |\n| Amount | DECIMAL | Total amount of the order. |\n| Region | VARCHAR | Region where the order was placed. |\n+--------------+-----------+-----------------------------+\nSample Data:\n\n+---------+------------+------------+--------+--------+\n| OrderId | CustomerId | OrderDate | Amount | Region |\n+---------+------------+------------+--------+--------+\n| 1 | 101 | 2025-01-01 | 200.50 | North |\n| 2 | 102 | 2025-01-01 | 150.00 | South |\n| 3 | 103 | 2025-01-02 | 300.75 | East |\n| 4 | 101 | 2025-01-03 | 120.00 | North |\n| 5 | 102 | 2025-01-03 | 180.50 | West |\n+---------+------------+------------+--------+--------+\nRequirements: Write an SQL query to generate below insights\n\n1.Calculate the total sales amount per region.\n2.Find the top 3 customers based on their total purchase amount.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Online sales performance",
      "createdAt": "2025-01-20T06:28:35.421Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6790629ad24f993c6c890618",
      "submissionId": {
        "_id": "6790629ad24f993c6c890615",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Tekion",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737515298/xkx5kksuglrlurc0owcq.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "Customer data is stored in table which contains a column mobile number. Write an sql query or pyspark code to check if the mobile number is in given format(xxxx-xxx-xxx)",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Mobile number format",
      "createdAt": "2025-01-22T03:14:34.253Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6790629ad24f993c6c89061a",
      "submissionId": {
        "_id": "6790629ad24f993c6c890615",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Tekion",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737515298/xkx5kksuglrlurc0owcq.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "How to decide the number of workers in AWS Glue",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " AWS Glue workers",
      "createdAt": "2025-01-22T03:14:34.253Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6790629ad24f993c6c890619",
      "submissionId": {
        "_id": "6790629ad24f993c6c890615",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Tekion",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737515298/xkx5kksuglrlurc0owcq.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "What is the maximum runtime for lambda",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Lambda runtime",
      "createdAt": "2025-01-22T03:14:34.253Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6790629ad24f993c6c890617",
      "submissionId": {
        "_id": "6790629ad24f993c6c890615",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Tekion",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737515298/xkx5kksuglrlurc0owcq.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "Write a python code to identify the common the prefix in the list of the string provided.\nexample: [\"flask\",\"flank\",\"flower\"]  ans: \"fl\"",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Common prefix",
      "createdAt": "2025-01-22T03:14:34.253Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6790b352d24f993c6c89081e",
      "submissionId": {
        "_id": "6790b351d24f993c6c89081a",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Recro",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737535836/gc1ruw1wkgdiyolpnik1.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "What is a decorator? explain it with an example.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Decorator in python",
      "createdAt": "2025-01-22T08:58:58.061Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6790b352d24f993c6c89081f",
      "submissionId": {
        "_id": "6790b351d24f993c6c89081a",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Recro",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737535836/gc1ruw1wkgdiyolpnik1.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "What is repartition and coalesce? when will you use them?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": false,
      "summary": "Repartition in spark ",
      "createdAt": "2025-01-22T08:58:58.062Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6790b352d24f993c6c89081c",
      "submissionId": {
        "_id": "6790b351d24f993c6c89081a",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Recro",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737535836/gc1ruw1wkgdiyolpnik1.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Given the FruitHarvest table, write a SQL query to retrieve the record ID, farm ID, harvest date, harvest quantity, and the average harvest quantity over the current harvest and the three preceding harvests for the same farm. The result should be ordered by farm ID and harvest date.\n \nTable:\nrecord_id\tfarm_id\tharvest_date\tharvest_quantity\n1\t701\t2023-03-01\t120\n2\t701\t2023-03-10\t150\n3\t701\t2023-03-20\t180\n4\t701\t2023-03-30\t200\n5\t702\t2023-04-01\t220\n6\t702\t2023-04-10\t250\n7\t702\t2023-04-20\t270\n8\t702\t2023-04-30\t300",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "Fruit farm harvesting ",
      "createdAt": "2025-01-22T08:58:58.061Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6790b352d24f993c6c89081d",
      "submissionId": {
        "_id": "6790b351d24f993c6c89081a",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Recro",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737535836/gc1ruw1wkgdiyolpnik1.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "write a code to trigger the pipeline in adf.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": "Trigger pipeline in ADF",
      "createdAt": "2025-01-22T08:58:58.061Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6790b79cd24f993c6c89082e",
      "submissionId": {
        "_id": "6790b79cd24f993c6c89082b",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Affine",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737537064/nnoxqmyxmsnrbkqgo6gi.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write a SQL query to get an output as an output table.\n\nt1 Country\n----------\nIndia\t\nSrilanka\nAustralia\nPakistan\n \nt2 Country\n--------\nIndia\nSrilanka\nAustralia\nPakistan\n \nOutput\n=====\nCountry1   Country2\t\t\n-------------------\nIndia      Srilanka\nIndia      Australia\nIndia      Pakistan\nSrilanka   Australia\nSrilanka   Pakistan\nAustralia  Pakistan",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Countries combination",
      "createdAt": "2025-01-22T09:17:16.828Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6790b79cd24f993c6c89082d",
      "submissionId": {
        "_id": "6790b79cd24f993c6c89082b",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Affine",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737537064/nnoxqmyxmsnrbkqgo6gi.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write a SQL query to get the output as an output table.\nInput table\ncommunication_code\tevent_type\ncom1\t              Sent\ncom2\t              Open\ncom3\t              Sent\ncom1\t              Bounced\ncom3\t              Bounced\ncom2\t              Sent\ncom2\t              Sent\ncom1\t              Bounced\n\n\nOutput\n======= \ncommunication_code\tSent\tOpen\tBounced\ncom1\t             1\t     0\t      2\ncom2\t             2\t     1\t      0\ncom3\t             1\t     0\t      1",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": "communication codes ",
      "createdAt": "2025-01-22T09:17:16.828Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6790b79cd24f993c6c89082f",
      "submissionId": {
        "_id": "6790b79cd24f993c6c89082b",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Affine",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737537064/nnoxqmyxmsnrbkqgo6gi.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write a SQL query to get the max salary from the each department.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Max salary from dept",
      "createdAt": "2025-01-22T09:17:16.828Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6790b79cd24f993c6c890830",
      "submissionId": {
        "_id": "6790b79cd24f993c6c89082b",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Affine",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737537064/nnoxqmyxmsnrbkqgo6gi.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "How do you handle a schema change in Azure Data Factory?",
      "images": [],
      "category": "scenario based",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Schema change in ADF",
      "createdAt": "2025-01-22T09:17:16.829Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6790b79cd24f993c6c890831",
      "submissionId": {
        "_id": "6790b79cd24f993c6c89082b",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Affine",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737537064/nnoxqmyxmsnrbkqgo6gi.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Explain your current project in brief.",
      "images": [],
      "category": "project based",
      "difficulty": "Easy",
      "isFree": true,
      "summary": "Current project ",
      "createdAt": "2025-01-22T09:17:16.829Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6790b98fd24f993c6c890841",
      "submissionId": {
        "_id": "6790b98fd24f993c6c89083f",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "aptlytech",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737537616/hckrw5yxms8llunrllws.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Q1. How do you monitor your data pipeline?",
      "images": [],
      "category": "project based",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Data pipelines monitoring",
      "createdAt": "2025-01-22T09:25:35.981Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6790b98fd24f993c6c890843",
      "submissionId": {
        "_id": "6790b98fd24f993c6c89083f",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "aptlytech",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737537616/hckrw5yxms8llunrllws.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "How do you handle the Sev2 incident in your project?",
      "images": [],
      "category": "project based",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Severity-2 issue",
      "createdAt": "2025-01-22T09:25:35.981Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6790b98fd24f993c6c890844",
      "submissionId": {
        "_id": "6790b98fd24f993c6c89083f",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "aptlytech",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737537616/hckrw5yxms8llunrllws.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write a SQL query to get the second highest salary.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Second highest salary",
      "createdAt": "2025-01-22T09:25:35.982Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6790b98fd24f993c6c890845",
      "submissionId": {
        "_id": "6790b98fd24f993c6c89083f",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "aptlytech",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737537616/hckrw5yxms8llunrllws.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "What would be the output of the below code?\n\nresult = joinedDF.select('cust_name').filter(joinedDF.lob = 4 AND datediff(current_date(),joinedDF.booking_date)=30).show()\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Dataframe output",
      "createdAt": "2025-01-22T09:25:35.982Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6790b98fd24f993c6c890842",
      "submissionId": {
        "_id": "6790b98fd24f993c6c89083f",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "aptlytech",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737537616/hckrw5yxms8llunrllws.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Could you share the challenges you encountered while implementing the project?",
      "images": [],
      "category": "project based",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Project challanges ",
      "createdAt": "2025-01-22T09:25:35.981Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6790e056d24f993c6c89098c",
      "submissionId": {
        "_id": "6790e056d24f993c6c890985",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Neudesic",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737547610/d8xakw6nxzstf5vfzzeq.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "What is Autoloader in Databricks?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": "Autoloader in databricks ",
      "createdAt": "2025-01-22T12:11:02.903Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6790e056d24f993c6c89098a",
      "submissionId": {
        "_id": "6790e056d24f993c6c890985",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Neudesic",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737547610/d8xakw6nxzstf5vfzzeq.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Explain how memory allocation will be done in Python and Spark?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Memory allocation in spark",
      "createdAt": "2025-01-22T12:11:02.902Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6790e056d24f993c6c890988",
      "submissionId": {
        "_id": "6790e056d24f993c6c890985",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Neudesic",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737547610/d8xakw6nxzstf5vfzzeq.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "You are given a dataset with date, product_id, and sales_qty. Some rows contain null values for sales_qty. You are asked to forward-fill the missing values with the last non-null value per product_id in time order\n\nNote: Do not use any in-built functions\n \ndata = [\n    (\"2024-01-01\", 101, 10),\n    (\"2024-01-02\", 101, None),\n    (\"2024-01-03\", 101, 15),\n    (\"2024-01-01\", 102, 20),\n    (\"2024-01-02\", 102, None),\n    (\"2024-01-03\", 102, None),\n\n]\n \ncolumns = [\"date\", \"product_id\", \"sales_qty\"]",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Forward filling values",
      "createdAt": "2025-01-22T12:11:02.902Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6790e056d24f993c6c890987",
      "submissionId": {
        "_id": "6790e056d24f993c6c890985",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Neudesic",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737547610/d8xakw6nxzstf5vfzzeq.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "You are given a dataset containing customer information. Some fields have NULL values. Write code to replace NULL values with default values. For the age column, replace NULL with the average age, and for the city column, replace NULL with 'Unknown'.\n\ndata = [\n    (1, \"John\", 25, \"New York\"),\n    (2, \"Sarah\", None, \"San Francisco\"),\n    (3, \"Michael\", 40, None),\n    (4, \"Jessica\", None, \"Los Angeles\"),\n    (5, \"David\", 35, \"Seattle\")\n]\n \ncolumns = [\"customer_id\", \"name\", \"age\", \"city\"]",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Customer info dataframe",
      "createdAt": "2025-01-22T12:11:02.902Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6790e056d24f993c6c89098b",
      "submissionId": {
        "_id": "6790e056d24f993c6c890985",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Neudesic",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737547610/d8xakw6nxzstf5vfzzeq.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "What is Catalyst optimizer in Spark?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " catalyst optimizer",
      "createdAt": "2025-01-22T12:11:02.902Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6790e056d24f993c6c890989",
      "submissionId": {
        "_id": "6790e056d24f993c6c890985",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Neudesic",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737547610/d8xakw6nxzstf5vfzzeq.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "You are working for an e-commerce platform that tracks customer transactions. You are given a dataset containing customer_id, purchase_date, product_id, and quantity. The platform wants to analyze repeat purchases. Your task is to identify the customers who bought the same product on more than one occasion within a 30-day window.\n \ndata = [\n    (101, \"2024-01-01\", 201, 2),\n    (101, \"2024-01-15\", 201, 3),\n    (102, \"2024-01-02\", 202, 1),\n    (103, \"2024-02-05\", 203, 5),\n    (103, \"2024-02-10\", 203, 2),\n    (101, \"2024-03-01\", 201, 1),\n]\n \ncolumns = [\"customer_id\", \"purchase_date\", \"product_id\", \"quantity\"]",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Repeat order customers",
      "createdAt": "2025-01-22T12:11:02.902Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6791bda9d24f993c6c891223",
      "submissionId": {
        "_id": "6791bda9d24f993c6c891221",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "EY ",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737604125/vrtwjc9jca0ygjhiq3je.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Wordcupnum\tCountry\n1\tWest Indies\n2\tWest Indies\n3\tIndia\n4\tAustralia\n5\tPakistan\n6\tSri Lanka\n7\tAustralia\n8\tAustralia\n9\tAustralia\n10\tIndia\n11\tAustralia\n12\tEngland\n13\tAustralia\nFind consecutive winner using pyspark",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737604183/e1slpsgbyteyxikjg6cb.png"
      ],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Consecutive winter",
      "createdAt": "2025-01-23T03:55:21.846Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6791bda9d24f993c6c891225",
      "submissionId": {
        "_id": "6791bda9d24f993c6c891221",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "EY ",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737604125/vrtwjc9jca0ygjhiq3je.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "01. Let's assume through SFTP File came and resided on S3 and duplicate came . We need both old and new file how do you keep both ?\n02. How do you schedule the Glue job ? \n03. Why event based approach is feasible for running Glue Job ? If Yes how ? If No why ?\n04. Glue architecture ?\n05. spark-submit\n06. What transformation have you done ?\n07. There are junk values in the file/data frame that is read how do you find it and rectify it\n08. How do you deploy?\n09.  Let's say there are 100s of projects and you need to give required access for projects for required AWS Service how would you automate ?\nAny reason to choose Terraform over CloudFormation when IAC on AWS can be done using AWS CloudFormation.\n10. Difference between SparkSession, SparkContext and Hivecontext\n11. Why service will you use for Notifying users , Keep the notification in queue the delete the notification ?\n12. There are different ways to connect to on-premise Database to AWS i.e. DMS,JDBC,GLUE-Connection when all does the same work\nwhat's the need for different ways?\n13. Let assume you have 100 files yesterday in S3 Bucket , Today you see 70 files . 30 Files are delete . You have not implemented CloudWatch logging \nHow do you verify the delete files ?\n14. Let assume there is a long running job, redshift team reports that data is not refreshing ? How do you handle this issue ? What may be the cause ?\n15. How do you know data skewness happened and how do you conclude the issue reason ?\n",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737604493/o4lx6t7ttq3t58e4lznl.png"
      ],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " DE scenarios",
      "createdAt": "2025-01-23T03:55:21.846Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6791bda9d24f993c6c891224",
      "submissionId": {
        "_id": "6791bda9d24f993c6c891221",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "EY ",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737604125/vrtwjc9jca0ygjhiq3je.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Customer table:\n+------------+-------------+\n| customer_id | customer_name |\n+------------+-------------+\n| 101 | Alice |\n| 102 | Bob |\n| 103 | Charlie |\n+------------+-------------+\n\nOrders table:\n+-------------+------------+--------------+-------------+-------------+\n| order_id | sale_date | order_cost | customer_id | seller_id |\n+-----------+----------+------------+-----------+-----------+\n| 1 | 2020-03-01 | 1500 | 101 | 1 |\n| 2 | 2020-05-25 | 2400 | 102 | 2 |\n| 3 | 2019-05-25 | 800 | 101 | 3 |\n| 4 | 2020-09-13 | 1000 | 103 | 2 |\n| 5 | 2019-02-11 | 700 | 101 | 2 |\n+-----------+----------+------------+-----------+-----------\n+Seller table:\n+-----------+-----------+\n| seller_id | seller_name |\n+-----------+-----------+\n| 1 | Daniel |\n| 2 | Elizabeth |\n| 3 | Frank\n\nWrite an SQL query to report the names of all sellers who did not make any sales in 2020",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737604404/uqjlmkevuk9tsemxwvud.png"
      ],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " No sales made",
      "createdAt": "2025-01-23T03:55:21.846Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6791c1a0d24f993c6c89124f",
      "submissionId": {
        "_id": "6791c1a0d24f993c6c89124c",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "CGI ",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737604824/rmyupcq5iyfr8wjnx1mi.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "PySpark Question :\n Give a Employee Table .Find the top 2 salaries for each department.\n\nemp_id\temp_name\tdepartment_id\tsalary\n1\tAlice\t1\t100000\n2\tBob\t        1\t90000\n3\tCharlie\t1\t95000\n4\tDavid\t2\t120000\n5\tEve\t        2\t110000\n6\tFrank\t2\t115000\n7\tGrace\t3\t85000\n8\tHarry\t3\t80000\n9\tIvy\t        3\t88000\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Top salaries in dept",
      "createdAt": "2025-01-23T04:12:16.613Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6791c1a0d24f993c6c891250",
      "submissionId": {
        "_id": "6791c1a0d24f993c6c89124c",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "CGI ",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737604824/rmyupcq5iyfr8wjnx1mi.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "01. Introduce about Yourself , Latest Project.\n02. Why AWS Glue ? Why not AWS EMR ?\n03. Have you used Dynamic Data frame in your project ?\n04. How is Schema Evolution Handled .\n05. Have you worked on NoSQL / AWS DynamoDB ? What is Pagination\n06. Have you used AWS Step Function , have you used Cloud Formation or Terraform ? \n07. How do you delete 10 years data without writing Code\n08. Have you worked or do you know on CI/CD ?\n   how do you do unit testing ?\n09. Have you used any APIs.\n10. what is Vertical and Horizontal Scaling?\n11. Do you use OOPS concepts in Project like polymorphism, inheritance ?\n12. How do you find duplicates count in the data frame.\n13. Suppose there is a Data frame , need to change the datatype of one column to String Type from Int Type how do you do ?\n14. What is Executors ? Spark Architecture .\n15. What is Logical and Physical Plan ?\n16. Difference between drop, truncate, purge in spark.",
      "images": [],
      "category": "project based",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " DE scenario questions",
      "createdAt": "2025-01-23T04:12:16.613Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6791c1a0d24f993c6c89124e",
      "submissionId": {
        "_id": "6791c1a0d24f993c6c89124c",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "CGI ",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737604824/rmyupcq5iyfr8wjnx1mi.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Python question :\n      input_list=[0,1,2,3,4,5,6,7,8,9]\n      output_list=[{0,8},{1,7},{2,6},{3,5}]\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Python list pattern",
      "createdAt": "2025-01-23T04:12:16.612Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6791faa1d24f993c6c89145a",
      "submissionId": {
        "_id": "6791faa0d24f993c6c891456",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "JoulestoWatts",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737619590/lt4kqqyetylm8y4bj9yd.jpg"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Difference between star schema and snowflake schema ",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": "Snowflake schema",
      "createdAt": "2025-01-23T08:15:29.005Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6791faa1d24f993c6c891458",
      "submissionId": {
        "_id": "6791faa0d24f993c6c891456",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "JoulestoWatts",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737619590/lt4kqqyetylm8y4bj9yd.jpg"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Get  customer who are placing highest orders from below tables\n\ncustomers\n+----+----------+\n| ID | Name     |\n+----+----------+\n| 1  | John     |\n| 2  | Alice    |\n| 3  | Bob      |\n| 4  | Sarah    |\n+----+----------+\n\norders\n+-----+------------+\n| ID  | CustomerID |\n+-----+------------+\n| 101 | 1          |\n| 102 | 2          |\n| 103 | 3          |\n| 104 | 1          |\n| 105 | 3          |\n| 106 | 4          |\n| 107 | 2          |\n| 108 | 3          |\n+-----+------------+",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Highest orders placed",
      "createdAt": "2025-01-23T08:15:29.004Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6791faa1d24f993c6c891459",
      "submissionId": {
        "_id": "6791faa0d24f993c6c891456",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "JoulestoWatts",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737619590/lt4kqqyetylm8y4bj9yd.jpg"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Get the expected output from below python input:\ninput = [1,2,{2,3},[5,4]]\noutput: [1,2,3,4,5]",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " Python input lists",
      "createdAt": "2025-01-23T08:15:29.005Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67926c33d24f993c6c8917b8",
      "submissionId": {
        "_id": "67926c33d24f993c6c8917b6",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "LTIMindtree",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737649006/wncat4vpzefrytchttyn.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "read 2 csv files from S3.\n1st CSV - remove DOB NULL records\n2nd CSV - remove duplicate from SSN \nJoin both and write to other s3 bucket",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "CSV files operations ",
      "createdAt": "2025-01-23T16:20:03.241Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67926c33d24f993c6c8917b9",
      "submissionId": {
        "_id": "67926c33d24f993c6c8917b6",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "LTIMindtree",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737649006/wncat4vpzefrytchttyn.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write a query to fetch details of employees whose EmpLname ends with an alphabet â€˜Aâ€™ and contains five alphabets",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Employee name",
      "createdAt": "2025-01-23T16:20:03.241Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67926c33d24f993c6c8917ba",
      "submissionId": {
        "_id": "67926c33d24f993c6c8917b6",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "LTIMindtree",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737649006/wncat4vpzefrytchttyn.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write an SQL query to create an empty table with the same structure as some other table.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " SQL table structure",
      "createdAt": "2025-01-23T16:20:03.242Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6792e58fd24f993c6c8919bf",
      "submissionId": {
        "_id": "6792e58ed24f993c6c8919bd",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "dbs",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737680206/gtkfkqwdkkj66r9vpcej.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "id,dept,date,sales\n1,electronics,01-09-22,2000\n2,dresses,03-09-22,10000\n1,fitness,07-09-2022,23000\n2, groceries,10-09-2022,14000\n3,sweets,03-09-2022,5000\n3,restaurant,04-09-2022,6000\n1,shoes,12-09-2022,8000\n2,computers,15-09-2022,6700\n\ncreate dataframe using the CSV data guven above. assume it is in a CSV file\n    find the details of customer id 1\n    find the total of all customers between the start date and end date\n    find which customer gives maximum sales\n    find on which day each customer gets the highest sales\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Customers orders in CSV",
      "createdAt": "2025-01-24T00:57:51.032Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6792e58fd24f993c6c8919c0",
      "submissionId": {
        "_id": "6792e58ed24f993c6c8919bd",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "dbs",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737680206/gtkfkqwdkkj66r9vpcej.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "val list1 = List(1, 2, 3)\nval list2 = List(\"a\",\"b\", \"c\")\n\no/p: List(a1,b2, c3)",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Python lists",
      "createdAt": "2025-01-24T00:57:51.033Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6792e58fd24f993c6c8919c1",
      "submissionId": {
        "_id": "6792e58ed24f993c6c8919bd",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "dbs",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737680206/gtkfkqwdkkj66r9vpcej.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "you are running 2 processes at same time which are running into load data at same hive table into the same partition at sametime. What do you think will happen. Both the jobs will run fine? or one of the fail or one of them succeed.",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " 2 parallel spark jobs",
      "createdAt": "2025-01-24T00:57:51.033Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6792e793d24f993c6c8919cb",
      "submissionId": {
        "_id": "6792e793d24f993c6c8919c7",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "KPI Partners",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737680579/rzggd1boswfc6ib0psyn.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "you are taking 2 parameters. one is jar name and 2nd parameter you are reading is hdfs destinition location. You want to read the jar and inside the jar there are lot .proprties files. After reading the jar you have extract all the .properties files from jar and place them in the destinition hdfs localton which is provided a second parameter. Can you please write a shell script for that.",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Hdfs jar script",
      "createdAt": "2025-01-24T01:06:27.319Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6792e793d24f993c6c8919c9",
      "submissionId": {
        "_id": "6792e793d24f993c6c8919c7",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "KPI Partners",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737680579/rzggd1boswfc6ib0psyn.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Write a dataframe to handle below json schema\n{\n\"group\" : {},\n\"lang\" : [ \n    [ 1, \"scala\", \"functional\" ], \n    [ 2, \"java\",\"object\" ], \n    [ 3, \"py\",\"interpreted\" ]\n]\n}",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Pyspark json schema",
      "createdAt": "2025-01-24T01:06:27.319Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6792e793d24f993c6c8919cd",
      "submissionId": {
        "_id": "6792e793d24f993c6c8919c7",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "KPI Partners",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737680579/rzggd1boswfc6ib0psyn.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "What is highest temparature in each year ?\n\nI/p\nCITY,YEAR,TEMP\nBanglore,2020,35\nChennai,2020,31\nMumbai,2020,32\nChennai,2021,26\nHyderabad,2021,32\nMumbai,2021,31\n\nO/p\nCITY,YEAR,TEMP\nBanglore,2020,35\nHyderabad,2021,32",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "Highest temperature ",
      "createdAt": "2025-01-24T01:06:27.319Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6792e793d24f993c6c8919cc",
      "submissionId": {
        "_id": "6792e793d24f993c6c8919c7",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "KPI Partners",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737680579/rzggd1boswfc6ib0psyn.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Have you worked on any encryption decryption functionalities. What kind of data you deal with?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Data encryption",
      "createdAt": "2025-01-24T01:06:27.319Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6792e793d24f993c6c8919ca",
      "submissionId": {
        "_id": "6792e793d24f993c6c8919c7",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "KPI Partners",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737680579/rzggd1boswfc6ib0psyn.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": " Remove the special characters in name column using data frame\nid,name,roll_num\n1,\"\"\"\"Narayana\"\"\"\",100\n2,\"NarayanaNew\"\",200",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Special characters removal",
      "createdAt": "2025-01-24T01:06:27.319Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67931a6fd24f993c6c891b63",
      "submissionId": {
        "_id": "67931a6ed24f993c6c891b5f",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Creditsafe Technology",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737693492/mpgqhjm9jctihpfv1gbv.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Write a function to locate the left insertion point for a specified value in sorted order.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " Left insertion point",
      "createdAt": "2025-01-24T04:43:27.132Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67931a6fd24f993c6c891b66",
      "submissionId": {
        "_id": "67931a6ed24f993c6c891b5f",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Creditsafe Technology",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737693492/mpgqhjm9jctihpfv1gbv.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Write SQL query to find running total from a table",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": "Running total ",
      "createdAt": "2025-01-24T04:43:27.132Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67931a6fd24f993c6c891b62",
      "submissionId": {
        "_id": "67931a6ed24f993c6c891b5f",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Creditsafe Technology",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737693492/mpgqhjm9jctihpfv1gbv.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Write Python/Pyspark code to do following:\n1. Read 2 tables from oracle db\n2. join tables\n3. Convert to csv\n4. Convert to json\n5. Upload to s3",
      "images": [],
      "category": "scenario based",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " Pyspark file operations",
      "createdAt": "2025-01-24T04:43:27.132Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67931a6fd24f993c6c891b64",
      "submissionId": {
        "_id": "67931a6ed24f993c6c891b5f",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Creditsafe Technology",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737693492/mpgqhjm9jctihpfv1gbv.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "We are loading the output from below query to a file everyday. This process is taking more time, How to optimize it?\n\nQuery:\nselcct * from tabl1\nunion\nselcct * from tabl2\nunion\nselcct * from tabl3\nunion\nselcct * from tabl4",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " File loading process",
      "createdAt": "2025-01-24T04:43:27.132Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67931a6fd24f993c6c891b65",
      "submissionId": {
        "_id": "67931a6ed24f993c6c891b5f",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Creditsafe Technology",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737693492/mpgqhjm9jctihpfv1gbv.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Explain different techniques to fill null values? Write code for it in Pyspark/Python",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Fill null values",
      "createdAt": "2025-01-24T04:43:27.132Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "679346edd24f993c6c891dba",
      "submissionId": {
        "_id": "679346edd24f993c6c891db8",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "50L-60L",
        "companyName": "Door Dash",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737704850/iopja7hmxb5fxfyi0kms.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Given an array of integers and a value, determine if there are any two integers in the array whose sum is equal to the given value. Return true if the sum exists and return false if it does not.\n\nConsider this array and the target sums:\n\nPython solution \ndef find_sum_of_two(A, val):\n  found_values = set()\n  for a in A:\n    if val - a in found_values:\n      return True\n\n    found_values.add(a)\n    \n  return False\n\nv = [5, 7, 1, 2, 8, 4, 3]\ntest = [3, 20, 1, 2, 7]\n\nfor i in range(len(test)):\n  output = find_sum_of_two(v, test[i])\n  print(\"find_sum_of_two(v, \" + str(test[i]) + \") = \" + str(output))",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Sum of integers in array",
      "createdAt": "2025-01-24T07:53:17.602Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "679346edd24f993c6c891dbb",
      "submissionId": {
        "_id": "679346edd24f993c6c891db8",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "50L-60L",
        "companyName": "Door Dash",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737704850/iopja7hmxb5fxfyi0kms.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "List the Products Ordered in a Period (this question directly pickup from leet code \n\n+------------------+---------+\n| Column Name      | Type    |\n+------------------+---------+\n| product_id       | int     |\n| product_name     | varchar |\n| product_category | varchar |\n+------------------+---------+\nproduct_id is the primary key (column with unique values) for this table.\nThis table contains data about the company's products.\n \n\nTable: Orders\n\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| product_id    | int     |\n| order_date    | date    |\n| unit          | int     |\n+---------------+---------+\nThis table may have duplicate rows.\nproduct_id is a foreign key (reference column) to the Products table.\nunit is the number of products ordered in order_date.\n \n\nWrite a solution to get the names of products that have at least 100 units ordered in February 2020 and their amount.\n\nReturn the result table in any order.\n\nThe result format is in the following example.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Fetch name of the products",
      "createdAt": "2025-01-24T07:53:17.602Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "679346edd24f993c6c891dbc",
      "submissionId": {
        "_id": "679346edd24f993c6c891db8",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "50L-60L",
        "companyName": "Door Dash",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737704850/iopja7hmxb5fxfyi0kms.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Average Delivery Time per Restaurant\nAs an analyst at DoorDash, you are asked to measure the performance of restaurant partners. One important measure is the average delivery time associated with each restaurant. Assume that we calculate the delivery time by the difference between the order time and delivery completion time. Can you write a SQL query to find the average delivery time for each restaurant?\n\nPlease consider the following tables:\n\norders Example Input:\norder_id\torder_time\tdelivery_time\trestaurant_id\tcustomer_id\n0001\t08/25/2021 18:00:00\t08/25/2021 18:40:00\t100\t123\n0002\t08/25/2021 19:00:00\t08/25/2021 19:30:00\t200\t265\n0003\t08/25/2021 20:00:00\t08/25/2021 20:40:00\t200\t362\n0004\t08/25/2021 21:00:00\t08/25/2021 21:35:00\t300\t192\n0005\t08/25/2021 22:00:00\t08/25/2021 22:45:00\t100\t981\nExample Output:\nrestaurant_id\tavg_delivery_time_in_minutes\n100\t42.5\n200\t35.0\n300\t35.0",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": "Average delivery time per restaurant ",
      "createdAt": "2025-01-24T07:53:17.602Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67938b25d24f993c6c891f61",
      "submissionId": {
        "_id": "67938b25d24f993c6c891f5e",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Deloitte",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737722645/an75smdzhngohmbb5xld.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write sql query to get Nth highest salary",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Nth highest salary",
      "createdAt": "2025-01-24T12:44:21.305Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67938b25d24f993c6c891f62",
      "submissionId": {
        "_id": "67938b25d24f993c6c891f5e",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Deloitte",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737722645/an75smdzhngohmbb5xld.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Find the customer who purchased items from all category using SQL & pysaprk\nCustomer - name , cat_id\nCategory - cat_id, pur_id\npurchase - purchase_id,cat_id",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " All items purchase",
      "createdAt": "2025-01-24T12:44:21.305Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67938b25d24f993c6c891f63",
      "submissionId": {
        "_id": "67938b25d24f993c6c891f5e",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Deloitte",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737722645/an75smdzhngohmbb5xld.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "How would you group products with different prices using PySpark?\nAnswer : using collect_list",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Products grouping",
      "createdAt": "2025-01-24T12:44:21.305Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67938b25d24f993c6c891f60",
      "submissionId": {
        "_id": "67938b25d24f993c6c891f5e",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Deloitte",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737722645/an75smdzhngohmbb5xld.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Give the count of rows in result for Inner join, left join, right join, full outer join\n for the following tables\n\nTable 1 \nid -1,1,1,1,1\n\nTable2\nId - 1,1,1,1,1,1",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " SQL Joins",
      "createdAt": "2025-01-24T12:44:21.305Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679709bed24f993c6c89273c",
      "submissionId": {
        "_id": "679709bed24f993c6c892739",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "50L-60L",
        "companyName": "QRT",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737951421/yvt7u7vl6kf6qqrnfrni.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "remove duplicates from array \n\nGiven an integer array nums sorted in non-decreasing order, remove some duplicates in-place such that each unique element appears at most twice. The relative order of the elements should be kept the same.\n\nSince it is impossible to change the length of the array in some languages, you must instead have the result be placed in the first part of the array nums. More formally, if there are k elements after removing the duplicates, then the first k elements of nums should hold the final result. It does not matter what you leave beyond the first k elements.\n\nReturn k after placing the final result in the first k slots of nums.\n\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Relative order of elements",
      "createdAt": "2025-01-27T04:21:18.950Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "679709bed24f993c6c89273d",
      "submissionId": {
        "_id": "679709bed24f993c6c892739",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "50L-60L",
        "companyName": "QRT",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737951421/yvt7u7vl6kf6qqrnfrni.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "find the top 3 salaries from each department and order them by descending order. ",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Top 3 salaries",
      "createdAt": "2025-01-27T04:21:18.950Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679709bed24f993c6c89273b",
      "submissionId": {
        "_id": "679709bed24f993c6c892739",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "50L-60L",
        "companyName": "QRT",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737951421/yvt7u7vl6kf6qqrnfrni.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Given an array nums with n objects colored red, white, or blue, sort them in-place so that objects of the same color are adjacent, with the colors in the order red, white, and blue.\n\nWe will use the integers 0, 1, and 2 to represent the color red, white, and blue, respectively.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "Coloured objects ",
      "createdAt": "2025-01-27T04:21:18.950Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6797c244d24f993c6c892a1b",
      "submissionId": {
        "_id": "6797c244d24f993c6c892a18",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "Canada",
        "ctc": "20L-30L",
        "companyName": "Avanade",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737998678/l9tok075svdgggl3mnu8.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "2.SQL: We have 4 tables, employees, jobtitle, salary, address\n1. write a query to display the first_name, last_name, jobtitle and salary of each employee. (JOINS)\n2. write a query to display the first_name, last_name of employees whose address is not present in the address table. (LEFT JOIN)\n3. write a query to display the first_name, last_name and the most recent address of each employee. (Window functions and CTE)",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Employee table functions",
      "createdAt": "2025-01-27T17:28:36.342Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6797c244d24f993c6c892a1a",
      "submissionId": {
        "_id": "6797c244d24f993c6c892a18",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "Canada",
        "ctc": "20L-30L",
        "companyName": "Avanade",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737998678/l9tok075svdgggl3mnu8.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Imagine you are doing a migration project and you have ingested 1000 records from a table and after doing data cleaning and transformations as per business requirement, the target has 800 records in it. Now, the QA teams comes back to you and says that as per their testing, there should be 900 records, not 800. How would you handle such scenario?\n\n",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Data migration scenario",
      "createdAt": "2025-01-27T17:28:36.342Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6797c244d24f993c6c892a1c",
      "submissionId": {
        "_id": "6797c244d24f993c6c892a18",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "Canada",
        "ctc": "20L-30L",
        "companyName": "Avanade",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1737998678/l9tok075svdgggl3mnu8.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Python: We have a list with file names of some csv files that we want to load to a target. We also have a base input path and base output path. Write a function, to read all the csv files and load them as parquet files in the output path.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " CSV file loading",
      "createdAt": "2025-01-27T17:28:36.342Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6797cb89d24f993c6c892a32",
      "submissionId": {
        "_id": "6797cb89d24f993c6c892a30",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "CitiusTech",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738001041/baoodkcgwrgldza08r3t.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Find Cumulative Sum\n\nid sales\n1   20\n2   40\n3    50\n4    90\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Cumulative sum",
      "createdAt": "2025-01-27T18:08:09.784Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6797cb89d24f993c6c892a33",
      "submissionId": {
        "_id": "6797cb89d24f993c6c892a30",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "CitiusTech",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738001041/baoodkcgwrgldza08r3t.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write a pyspark code\n1. read csv file\n2. Do deduplication\n3. Create new column age_category on given condition\n4. write the final dataframe as a delta table and partition it on age_caegory.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " Pysarpk CSV operations",
      "createdAt": "2025-01-27T18:08:09.784Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "6797cb89d24f993c6c892a34",
      "submissionId": {
        "_id": "6797cb89d24f993c6c892a30",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "CitiusTech",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738001041/baoodkcgwrgldza08r3t.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "UNION and UNION ALL, HAVING and WHERE difference.",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " SQL functions difference ",
      "createdAt": "2025-01-27T18:08:09.784Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6797cb89d24f993c6c892a35",
      "submissionId": {
        "_id": "6797cb89d24f993c6c892a30",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "CitiusTech",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738001041/baoodkcgwrgldza08r3t.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Which LTS you used?, Then Explain OPTIMIZE and Z ORDER",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " LTS usage",
      "createdAt": "2025-01-27T18:08:09.784Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "6797cb89d24f993c6c892a36",
      "submissionId": {
        "_id": "6797cb89d24f993c6c892a30",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "CitiusTech",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738001041/baoodkcgwrgldza08r3t.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "What is Dimensional modelling, Types of Schemas and what is durable key and surrogate key",
      "images": [],
      "category": "theoretical",
      "difficulty": "Hard",
      "isFree": true,
      "summary": "Dimensional modelling ",
      "createdAt": "2025-01-27T18:08:09.784Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67989a81d24f993c6c892b06",
      "submissionId": {
        "_id": "67989a80d24f993c6c892b02",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "KPI Partners",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738053475/ual3uslj8mw5ukhfpojx.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Achieve expected output from Input table.\n\nInput table\n------------\nEmp Floor\n\na    1\n\nb    4\n\nc    5\n\na    3\n\nd    2\n\nd    6\n\nOutput table\n---------------\nEmp Floor\n\na    Multiple\n\nb    4\n\nc    5\n\nd   Multiple\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "Employees in floors ",
      "createdAt": "2025-01-28T08:51:13.115Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67989a81d24f993c6c892b04",
      "submissionId": {
        "_id": "67989a80d24f993c6c892b02",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "KPI Partners",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738053475/ual3uslj8mw5ukhfpojx.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Left join output of these 2 tables\n\nTable 1\t\nID \tcol1\n1\tA\n2\tC\n3\tB\nnull\tnull\nnull\tnull\n\t\n\n\nTable 2\t\nID \tcol1\n2\tE\n2\tF\n3\tF\nnull\tnull",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " SQL Joins",
      "createdAt": "2025-01-28T08:51:13.114Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67989a81d24f993c6c892b05",
      "submissionId": {
        "_id": "67989a80d24f993c6c892b02",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "KPI Partners",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738053475/ual3uslj8mw5ukhfpojx.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write a program to generate below output using python.\n\nExpected output:\n------------------\n1\n121\n12321\n1234321\n123454321\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Generate sequence pattern",
      "createdAt": "2025-01-28T08:51:13.114Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "679a2520d24f993c6c89303a",
      "submissionId": {
        "_id": "679a2520d24f993c6c893034",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "EXL Services",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738154885/evfrzxucoav5ale4eqll.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write a pyspark code to get highest 3 salaries in each department",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Highest salary in dept",
      "createdAt": "2025-01-29T12:54:56.604Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679a2520d24f993c6c893036",
      "submissionId": {
        "_id": "679a2520d24f993c6c893034",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "EXL Services",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738154885/evfrzxucoav5ale4eqll.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Difference between SCD type2 and type3.Show with an example",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " SCD Types",
      "createdAt": "2025-01-29T12:54:56.604Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679a2520d24f993c6c893039",
      "submissionId": {
        "_id": "679a2520d24f993c6c893034",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "EXL Services",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738154885/evfrzxucoav5ale4eqll.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write a sql query for below type of table to get third highest salary in each department also consider department having less than 3 employees\nempid empname depid salary",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Dept with less employees",
      "createdAt": "2025-01-29T12:54:56.604Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679a2520d24f993c6c893037",
      "submissionId": {
        "_id": "679a2520d24f993c6c893034",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "EXL Services",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738154885/evfrzxucoav5ale4eqll.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "For below tables write the count of outputs for every join\nTable A\n1\n1\n \nTable B\n1\n1\n1",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " SQL Joins",
      "createdAt": "2025-01-29T12:54:56.604Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679a2520d24f993c6c893038",
      "submissionId": {
        "_id": "679a2520d24f993c6c893034",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "EXL Services",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738154885/evfrzxucoav5ale4eqll.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write SQL query to get output as below \ncountry\nind\naus\nnz\n\n output\nind vs aus\nind vs nz\naus vs nz",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "Cricket matches ",
      "createdAt": "2025-01-29T12:54:56.604Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "679b159ad24f993c6c893396",
      "submissionId": {
        "_id": "679b159ad24f993c6c893394",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "TCS",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738216670/lzoy5bvnabov2wgdsut4.jpg"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "How do we remove duplicates from file using Datastage",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Datastage duplicates",
      "createdAt": "2025-01-30T06:00:58.642Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679b159ad24f993c6c893398",
      "submissionId": {
        "_id": "679b159ad24f993c6c893394",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "TCS",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738216670/lzoy5bvnabov2wgdsut4.jpg"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Load 10 input files to 10 target tables at a time which has different metadata\n",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": "Load files with different metadata ",
      "createdAt": "2025-01-30T06:00:58.642Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679b159ad24f993c6c89339a",
      "submissionId": {
        "_id": "679b159ad24f993c6c893394",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "TCS",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738216670/lzoy5bvnabov2wgdsut4.jpg"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "I have 10 Million records in source and target 5 million records were populated then \njob was aborted again i go and compile and run the job when that time job will run from\n 5million 1 record to remain records how?",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " Records population in table",
      "createdAt": "2025-01-30T06:00:58.642Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "679b159ad24f993c6c893397",
      "submissionId": {
        "_id": "679b159ad24f993c6c893394",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "TCS",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738216670/lzoy5bvnabov2wgdsut4.jpg"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "How do we handle large dataset & tune the performance in datastage",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Peformance tuning in datastage",
      "createdAt": "2025-01-30T06:00:58.642Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679b159ad24f993c6c893399",
      "submissionId": {
        "_id": "679b159ad24f993c6c893394",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "TCS",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738216670/lzoy5bvnabov2wgdsut4.jpg"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "How do we reverse a string in datastage",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": true,
      "summary": " String reverse",
      "createdAt": "2025-01-30T06:00:58.642Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679b4211d24f993c6c8934c9",
      "submissionId": {
        "_id": "679b4211d24f993c6c8934c6",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Clairvoyant",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738227759/up1lxviktwvegi35uydp.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "4. Write pySpark code for below scanrio\nInput:\n('James','Java'),\n('James','Python'),\n('James','Python'),\n('Anna','PHP'),\n('Anna','Javascript'),\n('Maria','Java'),\n('Maria','C++'),\n('James','Scala'),\n('Anna','PHP'),\n('Anna','HTML')\nOutput:\njames, [java,pyhton,scala]",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Pyspark languages list",
      "createdAt": "2025-01-30T09:10:41.256Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679b4211d24f993c6c8934cb",
      "submissionId": {
        "_id": "679b4211d24f993c6c8934c6",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Clairvoyant",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738227759/up1lxviktwvegi35uydp.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "10. SQL window funtions\n11. AWS EMR and lambda funtions\n12. How to build realtime ETL pipeline in AWS\n",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " DE theory questions",
      "createdAt": "2025-01-30T09:10:41.256Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679b4211d24f993c6c8934ca",
      "submissionId": {
        "_id": "679b4211d24f993c6c8934c6",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Clairvoyant",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738227759/up1lxviktwvegi35uydp.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "5.Write python code to print all the substrings from given input string\n6.Write SQL Query for Number of employees falling in each band\n \nInput file:\nempid,empsal\n102, 20000,\n103, 30000,\n140, 56999,\n\nOutput:\nbandwidth, number of employee in that bandwidth\n 0-10000 , 0\n 10001-20000, 1\n 20001-30000,1",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Employees salary bandwidth",
      "createdAt": "2025-01-30T09:10:41.256Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "679b4211d24f993c6c8934c8",
      "submissionId": {
        "_id": "679b4211d24f993c6c8934c6",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Clairvoyant",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738227759/up1lxviktwvegi35uydp.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "1. Spark Architecture.\n2. Diff b/w RDD and Df\n3. Spark performance tuning steps & realtime scenario'scenario",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": "Spark questions ",
      "createdAt": "2025-01-30T09:10:41.256Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679b6075d24f993c6c893668",
      "submissionId": {
        "_id": "679b6074d24f993c6c893666",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Oracle",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738235899/ewacqkbgpim9jbmpjqcg.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "1.Given a file which is big (~ 1Gb) and a small file small file (~ 100 mb)  you have to read both files and find out the pincodes with top 5 population.\n \nBig file                                                                                 Small file\ncity_id  city_name   population  country                           city id.        pincode\n1           Hyderabad    1000000       India                             1                500032",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Pincode with highest population",
      "createdAt": "2025-01-30T11:20:21.131Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "679b6075d24f993c6c893669",
      "submissionId": {
        "_id": "679b6074d24f993c6c893666",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Oracle",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738235899/ewacqkbgpim9jbmpjqcg.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "2.SQL Query for match Fixers:\nId, TeamName\n1, India\n2, Australia\n3, England\n4, New Zealand\n\n\nIndia vs Australia\nIndia vs England\nIndia vs New Zealand\nAustralia vs England\nAustralia vs New Zealand\nEngland vs New Zealand\n\n3. Write Pyspark code to mask Email column",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": true,
      "summary": " Match fixers",
      "createdAt": "2025-01-30T11:20:21.131Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679b6075d24f993c6c89366a",
      "submissionId": {
        "_id": "679b6074d24f993c6c893666",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Oracle",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738235899/ewacqkbgpim9jbmpjqcg.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "12. How to upload TB file to S3. How to invoke lambda functions\n\n13. Data bricks realted basic questions\n\n14. Job scheduling pattern in Airflow\n\n15. SCD2 implementation in Pyspark\n\n16. How to handle ETL flow and monitor , fail over scenarios\n\n17. Count of null values in each column\n\n18. Merge to soreted arrays into single array",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " DE theory",
      "createdAt": "2025-01-30T11:20:21.132Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679b6075d24f993c6c89366b",
      "submissionId": {
        "_id": "679b6074d24f993c6c893666",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Oracle",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738235899/ewacqkbgpim9jbmpjqcg.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "1. Hive paritioning\n\n2. Tuple, list and dicts and performance related questions\n\n3. Schema evaluation in Spark",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " DE theory",
      "createdAt": "2025-01-30T11:20:21.132Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679b61eed24f993c6c893674",
      "submissionId": {
        "_id": "679b61edd24f993c6c893672",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Concentrix",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738236185/ac4wcsmkk1noy6mqcurm.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "Write a python code to find Largest Sum Contiguous Subarray\n\n[1, 2, 3, 4, 5] => 15\n[4, -6, 2, 5] => 7",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Subarray largest sum",
      "createdAt": "2025-01-30T11:26:38.018Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679b61eed24f993c6c893676",
      "submissionId": {
        "_id": "679b61edd24f993c6c893672",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Concentrix",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738236185/ac4wcsmkk1noy6mqcurm.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "1. How to delete partitions in Hive\n2. How to use broad cast in Spark SQL\n3. Data modeling..difference between snowflake and star schema\n4. challenge to migrate pyspark app from python 2 to 3\n5. Employee & department tables SQL queries",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Project questions",
      "createdAt": "2025-01-30T11:26:38.022Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679b61eed24f993c6c893675",
      "submissionId": {
        "_id": "679b61edd24f993c6c893672",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Concentrix",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738236185/ac4wcsmkk1noy6mqcurm.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "1. Python lambda implementation, dict and list comprehension\n2. Number of default partions while loading 200GB single csv in Spark\n3. cache and persist and Out of memory scenario questions\n4. AQE in spark\n5. How to improve performance of spark jobs",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " DE theory",
      "createdAt": "2025-01-30T11:26:38.022Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679b61eed24f993c6c893677",
      "submissionId": {
        "_id": "679b61edd24f993c6c893672",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Concentrix",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738236185/ac4wcsmkk1noy6mqcurm.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "5. SQL queries\n\nInput:\nEmpId,EmpName,ManagerId\n1,Ramesh,2\n2,Suresh,3\n3,Mahesh,4\n4,CEO,null\n5,Mallesh,3\n\nOutput:\nEmpName,Level_1_MgrName,Level_2_MgrName,Level_3_MgrName\nRamesh,Suresh,Mahesh,CEO\nSuresh,Mahesh,CEO,null\nMahesh,CEO,null,null\nMallesh,Mahesh,CEO,null\nCEO,null,null,null\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Manager levels of employees",
      "createdAt": "2025-01-30T11:26:38.022Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "679c5a80d24f993c6c893d8a",
      "submissionId": {
        "_id": "679c5a80d24f993c6c893d86",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "LandMark Group",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738299608/ydqnkhwcxpatzjiab9na.png",
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738299609/p5sni29e8g1bvum8mjwa.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "\"Give me the count of records for inner join,left join,right join and full outer join for the below 2 tables.\n\ntable A\nid1\n1\n1\n2\n2\n \ntable B\n \nid1\n1\n1\n1\n4\n2\"\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " SQL Joins",
      "createdAt": "2025-01-31T05:07:12.745Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679c5a80d24f993c6c893d88",
      "submissionId": {
        "_id": "679c5a80d24f993c6c893d86",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "LandMark Group",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738299608/ydqnkhwcxpatzjiab9na.png",
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738299609/p5sni29e8g1bvum8mjwa.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "\"Write a sql query to transform rows to cols witout using pivots given data :\n\nInput:\nemp_id\tsalary_type\tval\n1\tsalary\t10000\n1\tbonus\t5000\n1\thike_prc\t10\n2\tsalary\t15000\n2\tbonus\t7000\n2\thike_prc\t8\n3\tsalary\t12000\n3\tbonus\t6000\n3\thike_prc\t7\n\nOutput:\nemp_id\tsalary\tbonus\thike_prc\n1\t10000\t5000\t10\n2\t15000\t7000\t8\n3\t12000\t6000\t7\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Salary hike percent",
      "createdAt": "2025-01-31T05:07:12.745Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679c5a80d24f993c6c893d8b",
      "submissionId": {
        "_id": "679c5a80d24f993c6c893d86",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "LandMark Group",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738299608/ydqnkhwcxpatzjiab9na.png",
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738299609/p5sni29e8g1bvum8mjwa.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "\"Solve this without using window functions:\n\n\ndate\t\tsale \n2023-10-03\t10   \n2023-10-04\t20     \n2023-10-05\t60   \n2023-10-07\t50   \n2023-10-08\t10   \n\n\ndate\t\tsale\t%var from prev day\n2023-10-03\t10\t\t\n2023-10-04\t20\t\t100\"\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "Sales variance ",
      "createdAt": "2025-01-31T05:07:12.745Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "679c5a80d24f993c6c893d89",
      "submissionId": {
        "_id": "679c5a80d24f993c6c893d86",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "LandMark Group",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738299608/ydqnkhwcxpatzjiab9na.png",
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738299609/p5sni29e8g1bvum8mjwa.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "\"WAP python program:\ninput: l1=[1,2,[3,4,[5,6,7],8],9,10]\noutput: l2=[1,2,3,4,5,6,7,8,9,10]\"\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": "Python print list",
      "createdAt": "2025-01-31T05:07:12.745Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679d7bc7d24f993c6c89404a",
      "submissionId": {
        "_id": "679d7bc6d24f993c6c894046",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Deloitte",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738373609/wsig4czwvc306jnnqrcg.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "3. Find number of instances where signal 1 is greater than 50 and signal 2 is greater than 55\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructType, StructField, StringType, IntegerType\nimport random\n \n# Initialize Spark session\nspark = SparkSession.builder.appName(\"Sample DataFrame\").getOrCreate()\n \n# Define the schema\nschema = StructType([\n    StructField(\"Vehicle Number\", StringType(), True),\n    StructField(\"Time Stamp\", IntegerType(), True),\n    StructField(\"Signal Name\", StringType(), True),\n    StructField(\"Value\", IntegerType(), True)\n])\n \n# Create sample data\ndata = []\nvehicles = [\"V1\", \"V2\"]\nsignals = [\"Signal1\", \"Signal2\", \"Signal3\"]\ntimestamps = [1, 2, 3, 4, 5]\n \nfor vehicle in vehicles:\n    for ts in timestamps:\n        for signal in signals:\n            value = random.randint(1, 100)  # Random value between 1 and 100\n            data.append((vehicle, ts, signal, value))\n \n# Create DataFrame\ndf = spark.createDataFrame(data, schema=schema)\ndf.display()\n\nAns: Explained the logic how to solve using pivot logic but failed to address how to handle for large dataset. ",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Vehicle stops near signal",
      "createdAt": "2025-02-01T01:41:27.103Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "679d7bc7d24f993c6c894049",
      "submissionId": {
        "_id": "679d7bc6d24f993c6c894046",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Deloitte",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738373609/wsig4czwvc306jnnqrcg.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "\n2. In the table defined below show the number of occurances for which the speed between two consecutive time sample changed more than 700 rpm\n\ndf = spark.createDataFrame([(1,2000),(2,2100),(3,4000),(5,4500),(6,60),(7,90),(8,9000)],schema=['time','engrpm'])\n\nAns: \nfrom pyspark.sql import Window as W\nfrom pyspark.sql import functions as F\ndf.withColumn('Speed_lag', F.lag('engrpm').over(W.orderBy(F.col('time').desc()))).withColumn('diff', F.abs(F.col('engrpm') - F.col('speed_lag'))).where('diff >= 700').display()\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Speed lag difference",
      "createdAt": "2025-02-01T01:41:27.103Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "679d7bc7d24f993c6c894048",
      "submissionId": {
        "_id": "679d7bc6d24f993c6c894046",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Deloitte",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738373609/wsig4czwvc306jnnqrcg.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "1. Find maximum call duration using pyspark API (Both incoming and outgoing should be calculated).\n\ndf = spark.createDataFrame([(\"Coimbatore\",\"Thirunelveli\",20),(\"Madurai\",\"Thirunelveli\",15),(\"Madurai\",\"Thootukudi\",150),(\"Madurai\",\"Coimbatore\",15),(\"Coimbatore\",\"Chennai\",15),(\"Tiruchi\",\"Coimbatore\",15)],schema=['Origin','Destination','CallDuration'])\n\nAns:\nfrom pyspark.sql import functions as F\ndf.groupBy('Origin').agg(F.sum('CallDuration').alias('MaxDuration')).sort(F.col('MaxDuration').desc()).display()",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Maximum call duration",
      "createdAt": "2025-02-01T01:41:27.103Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679d9e4bd24f993c6c894067",
      "submissionId": {
        "_id": "679d9e4bd24f993c6c894064",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Cognizant",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738381641/yxaiz27jzehfy4tq2a3u.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "1. You want to view the second highest revenue generated by the product each year. Use Pyspark API to solve the problem\n\nNote: No dataset was given in the interview. Instructed to code in notepad++. \nProviding a sample dataset below for your reference. \ndata = [\n    # Year 2022 - 10 products\n    (2022, \"Electronics\", 12000),\n    (2022, \"Electronics\", 10000),\n    (2022, \"Electronics\", 15000),\n    (2022, \"Clothing 5000),\n    (2022, \"Clothing\", 7000),\n    (2022, \"Clothing\", 6500),\n    (2022, \"Grocery\", 3000),\n    (2022, \"Grocery\", 2500),\n    (2022, \"Grocery\", 3200),\n    (2022, \"Grocery\", 2800),\n\n    # Year 2023 - 10 products\n    (2023, \"Electronics\", 14000),\n    (2023, \"Electronics\", 11000),\n    (2023, \"Electronics\", 16000),\n    (2023, \"Clothing\", 6000),\n    (2023, \"Clothing\", 8000),\n    (2023, \"Clothing\", 7000),\n    (2023, \"Grocery\", 3500),\n    (2023, \"Grocery\", 3000),\n    (2023, \"Grocery\", 3800),\n    (2023, \"Grocery\", 3300),\n\n    # Year 2024 - 10 products\n    (2024, \"Electronics\", 16000),\n    (2024, \"Electronics\", 13000),\n    (2024, \"Electronics\", 17000),\n    (2024, \"Clothing\", 7000),\n    (2024, \"Clothing\", 9000),\n    (2024, \"Clothing\", 7500),\n    (2024, \"Grocery\", 4000),\n    (2024, \"Grocery\", 3500),\n    (2024, \"Grocery, 4200),\n    (2024, \"Grocery\", 3800),\n]\n\n# Define schema\ncolumns = [\"year\", \"product\", \"revenue\"]\n\n# Create DataFrame\ndf = spark.createDataFrame(data, columns)\n\nHint: Need to use Dense_Rank() functio",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Second highest revenue",
      "createdAt": "2025-02-01T04:08:43.563Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679d9e4bd24f993c6c894066",
      "submissionId": {
        "_id": "679d9e4bd24f993c6c894064",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Cognizant",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738381641/yxaiz27jzehfy4tq2a3u.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "1. What are the optimization Techniques you used in your project? How would you identify skew join and steps you will take to solve it?\n\nAns: Cache, Checkpointing, Repartition to distribute data even across partition. Avoiding UDFs if spark has inbuilt operation to handle it. To check data skewness - use spark ui metrics",
      "images": [],
      "category": "project based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Spark optimization techniques",
      "createdAt": "2025-02-01T04:08:43.562Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "679d9e4bd24f993c6c894068",
      "submissionId": {
        "_id": "679d9e4bd24f993c6c894064",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Cognizant",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738381641/yxaiz27jzehfy4tq2a3u.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "What is broadcasting and when to use it. How it helps to complete the task run faster. Write the code to broadcast smaller dataframe to larger dataframe.\n\nAns: sales_df.join(broadcast(products_df), \"product_id\", \"inner\")",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Broadcast join",
      "createdAt": "2025-02-01T04:08:43.563Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a007c0d24f993c6c8944e3",
      "submissionId": {
        "_id": "67a007bfd24f993c6c8944df",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Koantek",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738540609/qkvki1zuqdjejyunjtr2.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Read a JSON file containing salary data, compare two columns (salary1 and salary2), and generate a result based on whether salary1 is greater than salary2. Store the result in a Parquet file.\n[\n  {\"id\": 1, \"salary1\": 50000, \"salary2\": 45000},\n  {\"id\": 2, \"salary1\": 60000, \"salary2\": 70000},\n  {\"id\": 3, \"salary1\": 80000, \"salary2\": 75000},\n  {\"id\": 4, \"salary1\": 45000, \"salary2\": 45000}\n]\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Salary differences",
      "createdAt": "2025-02-03T00:03:12.216Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a007c0d24f993c6c8944e4",
      "submissionId": {
        "_id": "67a007bfd24f993c6c8944df",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Koantek",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738540609/qkvki1zuqdjejyunjtr2.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "\"filters all the elements in the list that has â€˜interviewâ€™ in the element .[\"\"pyspark\"\", \n  \"\"interview\"\", \n  \"\"questions\"\", \n  \"\"at\"\", \n  \"\"interviewbit\"\"]\"\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Filtering Interview",
      "createdAt": "2025-02-03T00:03:12.216Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a007c0d24f993c6c8944e1",
      "submissionId": {
        "_id": "67a007bfd24f993c6c8944df",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Koantek",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738540609/qkvki1zuqdjejyunjtr2.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "\"From the given tables, give the count for left,right,inner and full join\n\nTable-A\n-----\n1\n1\n0\nnull\n \n\nTable-B\n------\n1\n0\nnull\nnull\"\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " SQL Joins",
      "createdAt": "2025-02-03T00:03:12.216Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a007c0d24f993c6c8944e2",
      "submissionId": {
        "_id": "67a007bfd24f993c6c8944df",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Koantek",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738540609/qkvki1zuqdjejyunjtr2.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "\"Read the csv file using Spark API and convert each row into mutiple rows based on hobbies.\n==================\n \nName, Age,hobbies\n \nChandran,28,singing-dancing-reading\n \n\nOutput\n \n===================\n \nName, Age,hobbies\n \nChandran,28,singing\n \nChandran,28,dancing\n \nChandran,28,reading\"\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": "User hobbies ",
      "createdAt": "2025-02-03T00:03:12.216Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a04bf0d24f993c6c89469a",
      "submissionId": {
        "_id": "67a04bf0d24f993c6c894698",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "Canada",
        "ctc": "30L-40L",
        "companyName": "PWC",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738558057/vud7ukrwimjxjhsrjwib.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "# Find the products whose total sales has increased every year\ndata = [\n    (1, 2020, 100), (1, 2021, 200), (1, 2022, 300),\n    (2, 2020, 150), (2, 2021, 120), (2, 2022, 200),\n    (3, 2020, 500), (3, 2021, 700), (3, 2022, 900)\n]\ncolumns = [\"product_id\", \"year\", \"sales\"]\n\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Sales increase every year",
      "createdAt": "2025-02-03T04:54:08.523Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a04bf0d24f993c6c89469d",
      "submissionId": {
        "_id": "67a04bf0d24f993c6c894698",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "Canada",
        "ctc": "30L-40L",
        "companyName": "PWC",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738558057/vud7ukrwimjxjhsrjwib.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "# arr=[25,30,11,15,10]\nperform bubble sort on above array. ",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Bubble sort",
      "createdAt": "2025-02-03T04:54:08.524Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a04bf0d24f993c6c89469b",
      "submissionId": {
        "_id": "67a04bf0d24f993c6c894698",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "Canada",
        "ctc": "30L-40L",
        "companyName": "PWC",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738558057/vud7ukrwimjxjhsrjwib.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "what is the role of Receivers in spark streaming ?\nHow can you optimize a spark streaming Job ?\nHow to convert Parquet format to avro format.  ?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " DE theory",
      "createdAt": "2025-02-03T04:54:08.523Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a04bf0d24f993c6c89469c",
      "submissionId": {
        "_id": "67a04bf0d24f993c6c894698",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "Canada",
        "ctc": "30L-40L",
        "companyName": "PWC",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738558057/vud7ukrwimjxjhsrjwib.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "There are 10 files with different schema in a S3 bucket. design a Generic and robust system to read files and ingest into table with schema enforcement. ",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "Design file system ",
      "createdAt": "2025-02-03T04:54:08.524Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a09a8ad24f993c6c894908",
      "submissionId": {
        "_id": "67a09a8ad24f993c6c894906",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Random trees pvt ltd",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738576851/zqhmcqjzimryvfcsypnq.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "write a recursive cte to generate numbers  from 1to 100.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Recursive CTE",
      "createdAt": "2025-02-03T10:29:30.761Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a09a8ad24f993c6c894909",
      "submissionId": {
        "_id": "67a09a8ad24f993c6c894906",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Random trees pvt ltd",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738576851/zqhmcqjzimryvfcsypnq.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "left join vs right join example",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " SQL Joins",
      "createdAt": "2025-02-03T10:29:30.761Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a09a8ad24f993c6c89490a",
      "submissionId": {
        "_id": "67a09a8ad24f993c6c894906",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Random trees pvt ltd",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738576851/zqhmcqjzimryvfcsypnq.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "write an example dag which schedules everyday at 3am",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " DAG Schedule",
      "createdAt": "2025-02-03T10:29:30.762Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a09a8ad24f993c6c89490b",
      "submissionId": {
        "_id": "67a09a8ad24f993c6c894906",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Random trees pvt ltd",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738576851/zqhmcqjzimryvfcsypnq.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "write a dataflow pipeline using apachebeam which takes csv file as input,transforms and loads into bigquery .",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Apache beam pipeline",
      "createdAt": "2025-02-03T10:29:30.762Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a09a8ad24f993c6c89490c",
      "submissionId": {
        "_id": "67a09a8ad24f993c6c894906",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Random trees pvt ltd",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738576851/zqhmcqjzimryvfcsypnq.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "what is capacitor in bigquery",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Capacitor in bigquery",
      "createdAt": "2025-02-03T10:29:30.762Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a09a8ad24f993c6c89490d",
      "submissionId": {
        "_id": "67a09a8ad24f993c6c894906",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Random trees pvt ltd",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738576851/zqhmcqjzimryvfcsypnq.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "map vs flatmap",
      "images": [],
      "category": "scenario based",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Map Vs Flatmap",
      "createdAt": "2025-02-03T10:29:30.762Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a09a8ad24f993c6c89490e",
      "submissionId": {
        "_id": "67a09a8ad24f993c6c894906",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Random trees pvt ltd",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738576851/zqhmcqjzimryvfcsypnq.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "explain bigquery architecture",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Bigquery architecture",
      "createdAt": "2025-02-03T10:29:30.762Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a09a8ad24f993c6c89490f",
      "submissionId": {
        "_id": "67a09a8ad24f993c6c894906",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Random trees pvt ltd",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738576851/zqhmcqjzimryvfcsypnq.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "anagram code in python ",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Anagram python",
      "createdAt": "2025-02-03T10:29:30.762Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a2eba8d24f993c6c894f86",
      "submissionId": {
        "_id": "67a2eba8d24f993c6c894f84",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Sigmoid",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738730249/abx3hhcjajhgnqkrlub2.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "\n1..Given are ropes of different lengths, the task is to connect these ropes into one rope with minimum cost, such that the cost to connect two ropes is equal to the sum of their lengths.\nExamples:\nInput: arr[] = {5,4,3,2,1} ,Â \nOutput: 33\nExplanation:You are given multiple ropes of different lengths, and the goal is to connect all of them into one single rope. However, there's a cost involved each time you connect two ropes, and the cost is equal to the combined length of those two ropes. Your task is to find a way to connect all the ropes while minimizing the total cost.\nStep-by-Step Explanation:\nInitial array: {5, 4, 3, 2, 1}\n1. Combine the two smallest ropes (1 and 2):\n    * Cost = 1 + 2 = 3\n    * Updated array after combining: {5, 4, 3, 3}\n2. Combine the two smallest ropes (3 and 3):\n    * Cost = 3 + 3 = 6\n    * Updated array after combining: {5, 4, 6}\n3. Combine the two smallest ropes (4 and 5):\n    * Cost = 4 + 5 = 9\n    * Updated array after combining: {6, 9}\n4. Combine the remaining ropes (6 and 9):\n    * Cost = 6 + 9 = 15\n    * Updated array: {15}\nNow we have combined all the ropes into one, so the total cost is the sum of all the individual combination costs:\nTotal cost = 3 + 6 + 9 + 15 = 33\n\nExamples 2:\nInput: arr[] = {4,3,2,6} ,Â \nOutput: 29\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " connect the ropes",
      "createdAt": "2025-02-05T04:40:08.188Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a2eba8d24f993c6c894f88",
      "submissionId": {
        "_id": "67a2eba8d24f993c6c894f84",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Sigmoid",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738730249/abx3hhcjajhgnqkrlub2.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "How to get 3rd highest salary using PySpark & SQL code?\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " 3rd highest salary",
      "createdAt": "2025-02-05T04:40:08.189Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a2eba8d24f993c6c894f87",
      "submissionId": {
        "_id": "67a2eba8d24f993c6c894f84",
        "status": "approved",
        "adminComment": "approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Sigmoid",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738730249/abx3hhcjajhgnqkrlub2.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "\n2.Question: Find the Minimum Number of Platforms Required\nProblem Statement:Given the arrival and departure times of trains at a railway station, find the minimum number of platforms required so that no train has to wait.\nExample:\nInput:Â \narrival = [900, 940, 950, 1100, 1500, 1800]\ndeparture = [910, 1200, 1120, 1130, 1900, 2000]\n\nOutput: 3.\nExample 2\nInput:arrival = [1000, 1015, 1025, 1030, 1100]departure = [1035, 1045, 1040, 1055, 1130]",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Train platforms",
      "createdAt": "2025-02-05T04:40:08.188Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a2edf8d24f993c6c894fd3",
      "submissionId": {
        "_id": "67a2edf8d24f993c6c894fd1",
        "status": "approved",
        "adminComment": "Approved",
        "country": "Canada",
        "ctc": "40L-50L",
        "companyName": "Tech Mahindra",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738730895/aputy5obh5nmquavlgql.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Data Column -> id , name , age, department, salary \n\nFind the top 3 departments with the highest total salary.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Highest salary departments",
      "createdAt": "2025-02-05T04:50:00.844Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a2edf8d24f993c6c894fd5",
      "submissionId": {
        "_id": "67a2edf8d24f993c6c894fd1",
        "status": "approved",
        "adminComment": "Approved",
        "country": "Canada",
        "ctc": "40L-50L",
        "companyName": "Tech Mahindra",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738730895/aputy5obh5nmquavlgql.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "What are the different storage options available to data engineers in Azure?\nWhat is Linked Services in ADF?\nWhat are ways to ingest data from on-premise storage to Azure cloud?\nHow do you maintain version of data ?\n",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " DE theory",
      "createdAt": "2025-02-05T04:50:00.845Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a2edf8d24f993c6c894fd6",
      "submissionId": {
        "_id": "67a2edf8d24f993c6c894fd1",
        "status": "approved",
        "adminComment": "Approved",
        "country": "Canada",
        "ctc": "40L-50L",
        "companyName": "Tech Mahindra",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738730895/aputy5obh5nmquavlgql.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "How do you read a large file like 1 TB and what optimization techniques can be applied. ?",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Read 1TB file ",
      "createdAt": "2025-02-05T04:50:00.845Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a2edf8d24f993c6c894fd4",
      "submissionId": {
        "_id": "67a2edf8d24f993c6c894fd1",
        "status": "approved",
        "adminComment": "Approved",
        "country": "Canada",
        "ctc": "40L-50L",
        "companyName": "Tech Mahindra",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738730895/aputy5obh5nmquavlgql.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "String- 'abbcdaacb'\n\nQuestion - Remove adjacent duplicates. ",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "Remove adjacent duplicates ",
      "createdAt": "2025-02-05T04:50:00.845Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a36ae8d24f993c6c89544b",
      "submissionId": {
        "_id": "67a36ae7d24f993c6c895449",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Sigmoid",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738762607/qgt1zkdih10t2ag4z5ya.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "DSA: Next Greater Element for every element in a given Array\n\nInput: arr[] = [1, 3, 2, 4]\nOutput: [3, 4, 4, -1]\nExplanation: The next larger element to 1 is 3, 3 is 4, 2 is 4 and for 4, since it doesnâ€™t exist, it is -1.\n\n\nInput: arr[] = [6, 8, 0, 1, 3]\nOutput: [8, -1, 1, 3, -1]\nExplanation: The next larger element to 6 is 8, for 8 there is no larger elements hence it is -1, for 0 it is 1 , for 1 it is 3 and then for 3 there is no larger element on right and hence -1.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Next greater element",
      "createdAt": "2025-02-05T13:43:04.008Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a36ae8d24f993c6c89544c",
      "submissionId": {
        "_id": "67a36ae7d24f993c6c895449",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Sigmoid",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738762607/qgt1zkdih10t2ag4z5ya.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "DSA: Search in a Sorted and Rotated Array\n\nQues: Given a sorted and rotated array arr[] of n distinct elements, the task is to find the index of the given key in the array. If the key is not present in the array, return -1.\nExamples: Input: arr[] = [5, 6, 7, 8, 9, 10, 1, 2, 3], key = 3\nOutput: 8\nExplanation: 3 is present at index 8 in arr[].\n\n\nInput: arr[] = [3, 5, 1, 2], key = 6\nOutput: -1\nExplanation: 6 is not present in arr[].",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Index of the key",
      "createdAt": "2025-02-05T13:43:04.008Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a36ae8d24f993c6c89544d",
      "submissionId": {
        "_id": "67a36ae7d24f993c6c895449",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Sigmoid",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738762607/qgt1zkdih10t2ag4z5ya.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Explain how to traverse a tree in DSA and what is leaf node ,root node and balanced tree means",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Traverse a tree",
      "createdAt": "2025-02-05T13:43:04.008Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a36d0ad24f993c6c8954a7",
      "submissionId": {
        "_id": "67a36d0ad24f993c6c8954a5",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "EMIDS",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738763125/jaf20ejo0ejsgyrlbxcj.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Explain Spark Architecture and what will be the cluster configuration if we have a 100 GB file",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Cluster configuration 100GB file",
      "createdAt": "2025-02-05T13:52:10.827Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a36d0ad24f993c6c8954a8",
      "submissionId": {
        "_id": "67a36d0ad24f993c6c8954a5",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "EMIDS",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738763125/jaf20ejo0ejsgyrlbxcj.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "SQL Query for match Fixers:\nId, TeamName\n1, India\n2, Australia\n3, England\n4, New Zealand\n\nThe output should look like this \nIndia vs Australia\nIndia vs England\nIndia vs New Zealand\nAustralia vs England\nAustralia vs New Zealand\nEngland vs New Zealand",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Match Fixers",
      "createdAt": "2025-02-05T13:52:10.827Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a36d0ad24f993c6c8954a9",
      "submissionId": {
        "_id": "67a36d0ad24f993c6c8954a5",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "EMIDS",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738763125/jaf20ejo0ejsgyrlbxcj.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "data = [\n    (\"U1\", \"2024-12-30 10:00:00\", \"LOGIN\"),\n    (\"U1\", \"2024-12-30 10:05:00\", \"BROWSE\"),\n    (\"U1\", \"2024-12-30 10:20:00\", \"LOGOUT\"),\n    (\"U2\", \"2024-12-30 11:00:00\", \"LOGIN\"),\n    (\"U2\", \"2024-12-30 11:15:00\", \"BROWSE\"),\n    (\"U2\", \"2024-12-30 11:30:00\", \"LOGOUT\"),  # Duplicate entry\n    (None, \"2024-12-30 12:00:00\", \"LOGIN\"),   # Missing user_id\n    (\"U3\", None, \"LOGOUT\")                    # Missing timestamp\n]\n\nQues: Determine the top 3 most frequent activity types for each user_id\nWrite above query in both SQL and PySpark",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Frequent activity types",
      "createdAt": "2025-02-05T13:52:10.827Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a4138fd24f993c6c8956ce",
      "submissionId": {
        "_id": "67a4138fd24f993c6c8956cc",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Zeta",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738805862/kgho21kbaxsuvwelaswy.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "sample_data = [{'name': \"SBI\", 'id': 100}, {'name': \"HDFC/D/B\", 'id': 200}, {'name': \"UBI'S\", 'id': 300}]\nexpected output = SBI_100,HDFC/D/B_200,UBI'S_300\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": "Python pattern print ",
      "createdAt": "2025-02-06T01:42:39.882Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a4138fd24f993c6c8956cf",
      "submissionId": {
        "_id": "67a4138fd24f993c6c8956cc",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Zeta",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738805862/kgho21kbaxsuvwelaswy.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Input: 235|0|0|1|99999|1|20230101|0 \nExpected output: 235|0|0|ONE|99999|PERFECT|20230101|0\nWrite a pyspark code to solve this.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": "Pyspark pattern print ",
      "createdAt": "2025-02-06T01:42:39.883Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a4138fd24f993c6c8956d0",
      "submissionId": {
        "_id": "67a4138fd24f993c6c8956cc",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Zeta",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738805862/kgho21kbaxsuvwelaswy.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Input:\nName\tAddress\tEmail\tFloor\tResources\nA\tBangalore\tA@gmail.com  1\tCPU\nA\tBangalore\tA1@gmail.com 1\tCPU\nA\tBangalore\tA2@gmail.com 2\tDESKTOP\nB\tBangalore\tB@gmail.com  2\tDESKTOP\nB\tBangalore\tB1@gmail.com 2\tDESKTOP\nB\tBangalore\tB2@gmail.com 1\tMONITOR\n\nExpected Output:\nName\tTotal_visits\tmost_visited_floor\tresources_used\nA\t           3\t                        1\t                 CPU,DESKTOP\nB\t           3\t                        2\t                 DESKTOP,MONITOR",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "Most visited building floor ",
      "createdAt": "2025-02-06T01:42:39.883Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a4c491d24f993c6c895b13",
      "submissionId": {
        "_id": "67a4c491d24f993c6c895b11",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "ProArch",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738850694/zf0qtil3v6ywvklligzj.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "Question-1:- SQL\nWrite a query to find higest salary of each department.\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Highest salary in dept",
      "createdAt": "2025-02-06T14:17:53.857Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a4c491d24f993c6c895b14",
      "submissionId": {
        "_id": "67a4c491d24f993c6c895b11",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "ProArch",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738850694/zf0qtil3v6ywvklligzj.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "\nQestion-2:- SQL\n\nPROBLEM STATEMENT: In this problem, we are given information about Categories of Chocolates and their Prices. For each category we need to find top 2 sub categories based on it's price:\n\nIf for a category we have a single subcategory then we've to check it's price. \nif the price is >50 then we need to include in o/p\n \n SCRIPTS :\n create table category(\nCategory varchar(50),\nSubCategory varchar(50),\nPrice varchar(50) );\n\ninsert into category values('Chips', 'Bingo', 10), \n('Chips', 'Lays', 40),\n('Chips', 'Kurkure', 60), \n('Choclate', 'Dairy Milk', 120), \n('Choclate', 'Five Star', 40),\n('Choclate', 'Perk', 25), \n('Choclate', 'Munch', 5), \n('Biscuits', 'Oreo', 120)",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Top chocoloates sub-category",
      "createdAt": "2025-02-06T14:17:53.857Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a4c491d24f993c6c895b15",
      "submissionId": {
        "_id": "67a4c491d24f993c6c895b11",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "ProArch",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738850694/zf0qtil3v6ywvklligzj.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "Tell me difference between GROUPBY & HAVING verbally and explain through code also.",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " GroupBy function",
      "createdAt": "2025-02-06T14:17:53.857Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a4d239d24f993c6c895c87",
      "submissionId": {
        "_id": "67a4d239d24f993c6c895c85",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "capgemini",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738854700/ixapjphj8v06iczqfwyl.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "generate an end_date if end date is not availble make it as 31-12-9999\nemp_name country joining_date --emp\nA         IND     12-12-2020\nB         IND     12-12-2021\nA         PAK     12-12-2022\nB         SL      12-12-2024\nA         SL      12-12-2025\n\nexpected output:\nemp_name country joining_date end_date  \nA         IND     12-12-2020  12-12-2022\nB         IND     12-12-2021  12-12-2024\nA         PAK     12-12-2022  12-12-2025\nB         SL      12-12-2024  31-12-9999\nA         SL      12-12-2025  31-12-9999\n\nsolution:\ndf=spark.createDataFrame(data,[\"empid\",\"country\",\"joining_date\"])\ndf.show()\nwind=Window.partitionBy(\"empid\").orderBy(\"joining_date\")\n(df.withColumn(\"end_date\",lead(\"joining_date\").over(wind))\n .withColumn(\"end_date\",when(col(\"end_date\").isNull(),\"12-31-9999\").otherwise(col(\"end_date\"))).show())\ndf.createOrReplaceTempView(\"emp\")\nspark.sql(\"select empid,country,joining_date,coalesce(lead(joining_date) over(partition by empid order by joining_date) ,'12-31-9999')as end_date from emp\").show()\n\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Employee tenture",
      "createdAt": "2025-02-06T15:16:09.656Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a4d239d24f993c6c895c88",
      "submissionId": {
        "_id": "67a4d239d24f993c6c895c85",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "capgemini",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738854700/ixapjphj8v06iczqfwyl.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "write an sql query to delete the duplicates from the table\ndelete from cars\nwhere ctid in ( select max(ctid)\n                from cars\n                group by model, brand\n                having count(1) > 1);",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Duplicate deletion",
      "createdAt": "2025-02-06T15:16:09.656Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a4d239d24f993c6c895c89",
      "submissionId": {
        "_id": "67a4d239d24f993c6c895c85",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "capgemini",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738854700/ixapjphj8v06iczqfwyl.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "write a pyspark program to create match fixtures for the given df.\nsolution:\nfrom turtledemo.sorting_animate import partition\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col,hash\n\n# Create a DataFrame with the teams\nspark = SparkSession.builder.appName(\"null\").master(\"local\").getOrCreate()\n\nteams = [(\"India\",), (\"Pakistan\",), (\"Sri Lanka\",), (\"Bangladesh\",), (\"Australia\",), (\"New Zealand\",)]\nschema = [\"Team\"]  # Schema should be a list of column names\n\ndf_teams = spark.createDataFrame(teams, schema)\ndf_teams1=spark.createDataFrame(teams, [\"Team1\"])\n\ndf_join=df_teams.crossJoin(df_teams1).filter(col(\"Team\") <  col(\"Team1\"))\n\ndf_join.show(100)\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, row_number\nfrom pyspark.sql.window import Window\n\n# Create a Spark session\nspark = SparkSession.builder.appName(\"match_fixtures\").master(\"local\").getOrCreate()\n\n# List of teams\nteams = [(\"India\",), (\"Pakistan\",), (\"Sri Lanka\",), (\"Bangladesh\",), (\"Australia\",), (\"New Zealand\",)]\nschema = [\"Team\"]\n\n# Create DataFrames for teams\ndf_teams = spark.createDataFrame(teams, schema)\ndf_teams1 = spark.createDataFrame(teams, [\"Team1\"])\n\n# Assign row numbers to teams\nwindowSpec = Window.orderBy(\"Team\")\nwindowSpec1 = Window.orderBy(\"Team1\")# Row number will be based on alphabetical order of Team\n\ndf_teams_with_row = df_teams.withColumn(\"row_num\", row_number().over(windowSpec))\ndf_teams1_with_row = df_teams1.withColumn(\"row_num\", row_number().over(windowSpec1))\n\n# Perform a self-join based on the row numbers where Team's row number is less than Team1's\ndf_join1 = df_teams_with_row.join(df_teams1_with_row, df_teams_with_row[\"row_num\"] < df_teams1_with_row[\"row_num\"])\n\n# Select relevant columns and show results\ndf_join1.select(\"Team\",\"Team1\").orderBy(\"Team\").show()\n\ndf_join_left=df_teams.join(df_teams1,df_teams[\"Team\"]!=df_teams1[\"Team1\"],how=\"left\")\ndf_final=(df_join_left.withColumn(\"Hash\",hash(\"Team\")+hash(\"Team1\"))\n .select(\"*\",row_number().over(windowSpec.partitionBy(\"hash\")).alias(\"rank\")).filter(col(\"rank\")==1))\ndf_final.select(\"Team\",\"Team1\").orderBy(\"Team\").show()\n\n\n\n\n\n\n\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": true,
      "summary": "Pyspark match fixes ",
      "createdAt": "2025-02-06T15:16:09.656Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a58a7bd24f993c6c896425",
      "submissionId": {
        "_id": "67a58a7bd24f993c6c896423",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Accordion",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738901546/kqjv2b2vhcav5pm8bfa8.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Problem Summary: Stock-Out Detection at FMCG Plants\n\nAn FMCG company tracks daily stock levels at multiple plants and daily sales at stores. Stores get replenished in real-time from assigned plants, but if a plant runs out of stock, replenishment fails, leading to a stock-out issue.\n\nThe goal is to identify which plants, products, and dates experienced stock-outs (i.e., when stock quantity reached zero at the plant level). This helps predict future stock shortages and optimize inventory management.\n\nKey Data Involved\n\t1.\tDaily Stock Data â€“ Tracks stock levels at the plant level.\n\t2.\tDaily Sales Data â€“ Tracks sales at the store level.\n\t3.\tPlant-Store Mapping â€“ Links stores to their respective plants.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Design stock-out detection",
      "createdAt": "2025-02-07T04:22:19.507Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a58a7bd24f993c6c896426",
      "submissionId": {
        "_id": "67a58a7bd24f993c6c896423",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Accordion",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738901546/kqjv2b2vhcav5pm8bfa8.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "The classic two sum problem\nGiven an array of integers nums and an integer target, return indices of the two numbers such that they add up to target.\n\nYou may assume that each input would have exactly one solution, and you may not use the same element twice.\n\nYou can return the answer in any order.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": "Sum of 2 numbers",
      "createdAt": "2025-02-07T04:22:19.507Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a58a7bd24f993c6c896427",
      "submissionId": {
        "_id": "67a58a7bd24f993c6c896423",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Accordion",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738901546/kqjv2b2vhcav5pm8bfa8.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Questions on Medallion Architecture and Types of Schema star and snowflake schema",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Medallion architecture",
      "createdAt": "2025-02-07T04:22:19.508Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a58a7bd24f993c6c896428",
      "submissionId": {
        "_id": "67a58a7bd24f993c6c896423",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Accordion",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738901546/kqjv2b2vhcav5pm8bfa8.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "was there a scenario where you had to deploy a solution but then roll it back due to some issues or something? Was that some of the experience that you have had?",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Deployment roll back",
      "createdAt": "2025-02-07T04:22:19.508Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a59f57d24f993c6c896597",
      "submissionId": {
        "_id": "67a59f57d24f993c6c896595",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Persistent",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738907187/yhvi54fe2goohyvlm1sy.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": " Show patient_id, diagnosis from admissions. Find patients admitted multiple times for the same diagnosis.\n\nPatient table \n------------------\npatient_id\tINT\nfirst_name\tTEXT\nlast_name\tTEXT\ngender\t    CHAR(1) \nbirth_date\tDATE\ncity\t    TEXT\nprovince_id\tCHAR(2) \nallergies\tTEXT\nheight\t    INT\nweight\t    INT\n\n \nadmissions table \n-----------------\npatient_id\t        INT\nadmission_date\t    DATE\ndischarge_date\t    DATE\ndiagnosis\t        TEXT \nattending_doctor_id\tINT",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "Patients admissions ",
      "createdAt": "2025-02-07T05:51:19.959Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a59f57d24f993c6c896598",
      "submissionId": {
        "_id": "67a59f57d24f993c6c896595",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Persistent",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738907187/yhvi54fe2goohyvlm1sy.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Show the provinces (province_name) that has more patients identified as 'M' than 'F'.\n\nPatient table \n------------------\npatient_id\tINT\nfirst_name\tTEXT\nlast_name\tTEXT\ngender\t    CHAR(1) \nbirth_date\tDATE\ncity\t    TEXT\nprovince_id\tCHAR(2) \nallergies\tTEXT\nheight\t    INT\nweight\t    INT\n\n\nprovince table\n----------------\nprovince_id\t    CHAR(2)\nprovince_name\tTEXT",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": "Provinces of patients ",
      "createdAt": "2025-02-07T05:51:19.959Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a59f57d24f993c6c896599",
      "submissionId": {
        "_id": "67a59f57d24f993c6c896595",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Persistent",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738907187/yhvi54fe2goohyvlm1sy.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "If 1st Jan 2025 is on Monday then find what day it is on 26th Jan 2025. Write Solution in Pyspark.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Republic day pysarpk",
      "createdAt": "2025-02-07T05:51:19.959Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a5a154d24f993c6c8965a7",
      "submissionId": {
        "_id": "67a5a153d24f993c6c8965a5",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Publicis Sapient",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738907741/hbzqimuijmvwfan5umel.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Identify the origin and destination of each customer who traveled in the flight\n\n+-------+---------+---------+-----------+\n|cust_id|flight_id|   origin|destination|\n+-------+---------+---------+-----------+\n|      1|  Flight1|    Delhi|  Hyderabad|\n|      1|  Flight2|Hyderabad|      Kochi|\n|      1|  Flight3|    Kochi|  Mangalore|\n|      2|  Flight1|   Mumbai|    Ayodhya|\n|      2|  Flight2|  Ayodhya|  Gorakhpur|\n+-------+---------+---------+-----------+\n\nWrite solution in SQL and PySpark both.",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "Customer traveled locations",
      "createdAt": "2025-02-07T05:59:48.169Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a5a154d24f993c6c8965a8",
      "submissionId": {
        "_id": "67a5a153d24f993c6c8965a5",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Publicis Sapient",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738907741/hbzqimuijmvwfan5umel.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Input : aaabbcccd\nOutput : a3b2c3d1\n\nWrite logic in python.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " String manpuilation",
      "createdAt": "2025-02-07T05:59:48.169Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a5a154d24f993c6c8965a9",
      "submissionId": {
        "_id": "67a5a153d24f993c6c8965a5",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Publicis Sapient",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738907741/hbzqimuijmvwfan5umel.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "If 1st jan and 2nd jan 2025 is on weekend i.e. Saturday and Sunday then calculate all weekend in month of jan 2025 in pyspark.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " Calendar days calculation",
      "createdAt": "2025-02-07T05:59:48.169Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a5b1fed24f993c6c896651",
      "submissionId": {
        "_id": "67a5b1fed24f993c6c89664f",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Infosys",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738911043/c8rn5bpa57mbe5asoei5.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "SQL: Given a table emp_details, produce a result which tells you all the direct and indirect  reportees of emp_id = 1\n\nInput:\nemp_id | name     | mgr_id\n1             CJ           NULL\n2             EB           1\n3             MB          1\n4             SW          2\n5             YT           NULL\n6             IS            5\n7             DA          4\n\nOutput:\n\nemp_id | name | mgr_id\n2      EB    1\n3      MB    1\n4      SW    2\n7       DA    4",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Employee direct reportees",
      "createdAt": "2025-02-07T07:10:54.712Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a5b1fed24f993c6c896652",
      "submissionId": {
        "_id": "67a5b1fed24f993c6c89664f",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Infosys",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738911043/c8rn5bpa57mbe5asoei5.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Python:\ninput = \"Hello World World is so beautifull if you say Hello\"\n \nFind the no.of occurences of each word and store it a dictionary.\n\nOutput: {'Hello': 2, 'World': 2, 'is': 1, 'so': 1, 'beautifull': 1, 'if': 1, 'you': 1, 'say': 1}",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": "occurrences of words ",
      "createdAt": "2025-02-07T07:10:54.712Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a5b1fed24f993c6c896653",
      "submissionId": {
        "_id": "67a5b1fed24f993c6c89664f",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Infosys",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738911043/c8rn5bpa57mbe5asoei5.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Spark Theory Questions: \n1.Explain your any one previous project in detail.\n2. Explain Spark Architecture in Detail.\n3. Performance optimizations you have done in your project.\n4. Explain about Broadcast variable.\n5. Pyspark:\n\n\"/path/to/csv\"\n\"/path/to/json\"\n\"/path/to/parquet\"\n \nUnion the final dataframe out of above 3 files using pyspark\n",
      "images": [],
      "category": "project based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": "pyspark dataframe",
      "createdAt": "2025-02-07T07:10:54.712Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a5b645d24f993c6c896685",
      "submissionId": {
        "_id": "67a5b645d24f993c6c896681",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "HCL Technologies",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738912332/ovdf80gllxgqxwvjplda.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "ADF Project Questions:\n1. What are all the sources you have connected to in ADF?\n2. What are different types of triggers in ADF and explain them.\n3. Have you worked on any incremental dataload? If so explain them.\n4. What type of operations we can perform using Copy Activity?\n5. What ADF Activities you have used often in your previous project?",
      "images": [],
      "category": "project based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " ADF Properties",
      "createdAt": "2025-02-07T07:29:09.202Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a5b645d24f993c6c896686",
      "submissionId": {
        "_id": "67a5b645d24f993c6c896681",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "HCL Technologies",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738912332/ovdf80gllxgqxwvjplda.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "SQL:\n\nFind all the employees who has salary that is higher than the average salary of their department\n\nemp_id | salary | dep_id\n1           25000     1\n2           30000      1\n3           45000      2\n4           22000      2\n5           50000      3\n\nOutput:\n\nemp_id | dep_id\n2              1\n3              2\n5              3",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Employees salary average",
      "createdAt": "2025-02-07T07:29:09.202Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a5b645d24f993c6c896684",
      "submissionId": {
        "_id": "67a5b645d24f993c6c896681",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "HCL Technologies",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738912332/ovdf80gllxgqxwvjplda.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "The Position is for Azure Datafactory developer.\n1. How to read the latest modified file from ADLS( Explain what activities you will use and walk through the process)\n2. How will you ingest 1 billion records from oracle Source to ADL\n3. Source has 1 billion records, how will you perform incremental load using ADF and store data in ADL.\n4. we have one on-prem oracle database, explain the end to end process on how will you connect to it and move data to ADL.",
      "images": [],
      "category": "scenario based",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " ADL operations",
      "createdAt": "2025-02-07T07:29:09.201Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a5b645d24f993c6c896683",
      "submissionId": {
        "_id": "67a5b645d24f993c6c896681",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "HCL Technologies",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738912332/ovdf80gllxgqxwvjplda.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "SQL: \nproject_details:\n \nproject_id\temp_id\n1\t\t\t1     3\n1\t\t\t2     1\n1\t\t\t3     2\n2\t\t\t1     3\n2\t\t\t4     1\n \nemp_details:\n \nemp_id\t      emp_name\t                   exp_years \n1\t\tJoe\t\t\t\t3\n2\t\tDaniel\t\t\t        1\n3\t\tAndrew\t\t\t        2\n4\t\tTim\t\t\t\t3\n \nFind the employee who's having highest years of experience in each project\n\nOuput: \n\nproject_id  | emp_id | emp_name | exp_years\n1            1      Joe       3\n2            4       Tim      3",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " employee highest experience",
      "createdAt": "2025-02-07T07:29:09.201Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a5e80ad24f993c6c896946",
      "submissionId": {
        "_id": "67a5e80ad24f993c6c896944",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Walmart",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738925509/mdmv4dxyeuoglrhodof0.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Given a table emloyeelogin which has columns empid, time, state\nthe state has 2 values IN and OUT. time is the time at which the employee has either entered or exited the office. Also it is confirmed first he will enter and then exit and he can do this multiple times. We need to find the total time for each emloyee till the time he is in office",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Employee office engage ",
      "createdAt": "2025-02-07T11:01:30.227Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a5e80ad24f993c6c896948",
      "submissionId": {
        "_id": "67a5e80ad24f993c6c896944",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Walmart",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738925509/mdmv4dxyeuoglrhodof0.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "You have a spark job running fine but one day it stops and is taking too long to run . How will you approach to solve this issue",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Spark error solution",
      "createdAt": "2025-02-07T11:01:30.228Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a5e80ad24f993c6c896947",
      "submissionId": {
        "_id": "67a5e80ad24f993c6c896944",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Walmart",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738925509/mdmv4dxyeuoglrhodof0.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Given a string s and a dictionary of strings wordDict, return true if s can be segmented into a space-separated sequence  \nof one or more dictionary words. \nNote that the same word in the dictionary may be reused multiple times in theÂ segmentation.\n\nInput: s = \"walmart\", wordDict = [\"wal\",\"mart\"] \nOutput: true \nExplanation: Return true because \"walmart\" can be segmented as \"wal mart\". \n\nInput: s = \"walmart\", wordDict = [\"wal\",\"marts\"] \nOutput: false\n\nExample 2: \nInput: s = \"applepenapple\", wordDict = [\"apple\",\"pen\"] \nOutput: true \nExplanation: Return true because \"applepenapple\" can be segmented as \"apple pen apple\". \nNote that you are allowed to reuse a dictionaryÂ word.\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": false,
      "summary": "Dictionary words segmentation",
      "createdAt": "2025-02-07T11:01:30.228Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a61a86d24f993c6c896a55",
      "submissionId": {
        "_id": "67a61a86d24f993c6c896a53",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Cognizant",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738938946/bac3gmxhdrxepr8a0ewo.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "you have 2 tables employees and department.\nEmployee has following columns: employee_id (Primary Key),name,department_id,salary\nDepartment has following column : department_id (Primary Key),department_name\nWrite an SQL query to find the second highest salary in each department.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": "Second highest salary",
      "createdAt": "2025-02-07T14:36:54.203Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a61a86d24f993c6c896a56",
      "submissionId": {
        "_id": "67a61a86d24f993c6c896a53",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Cognizant",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738938946/bac3gmxhdrxepr8a0ewo.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "You are given a list of integers. Write a Python program to rearrange the list such that all the zeroes are moved to the end of the list while maintaining the relative order of the non-zero elements. The rearrangement must be done in-place, meaning you cannot use any additional lists or data structures for storage.\nInput : [1, 2, 0, 5, 0, 0, 3]\nOutput : [1,2,5,3,0,0,0]\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " List re-arrangement",
      "createdAt": "2025-02-07T14:36:54.203Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a61a86d24f993c6c896a57",
      "submissionId": {
        "_id": "67a61a86d24f993c6c896a53",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Cognizant",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738938946/bac3gmxhdrxepr8a0ewo.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Why are you using memory tables in mysql to connect to Looker studio. When you can store your data in HDFS also?",
      "images": [],
      "category": "project based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Memory management mysql",
      "createdAt": "2025-02-07T14:36:54.203Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a63691d24f993c6c896ad6",
      "submissionId": {
        "_id": "67a63691d24f993c6c896ad4",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Quantiphi",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738945750/gbkz71vr6sskpjazhcuu.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "1 What will be the result of below - Count(col1), count(*), count(1), count(distinct col1)\n\ncol1 \n12\nabc\ndef\nabc\nSpark\nnull\nnull\nxyz\nnull\n\n\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Count function scenario",
      "createdAt": "2025-02-07T16:36:33.780Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a63691d24f993c6c896ad7",
      "submissionId": {
        "_id": "67a63691d24f993c6c896ad4",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Quantiphi",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738945750/gbkz71vr6sskpjazhcuu.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "2 \tCan we rollback Truncate and Drop \n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Rollback function",
      "createdAt": "2025-02-07T16:36:33.780Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a63691d24f993c6c896ad8",
      "submissionId": {
        "_id": "67a63691d24f993c6c896ad4",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Quantiphi",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738945750/gbkz71vr6sskpjazhcuu.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Given a file with a lot of paragraphs, \n\tWrite code to find the Total number of Uppercase letters\n\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Uppercase letters",
      "createdAt": "2025-02-07T16:36:33.780Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a63763d24f993c6c896ae0",
      "submissionId": {
        "_id": "67a63763d24f993c6c896ade",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Seven Eleven",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738946309/o9rxkaz2akmnq4cygvwf.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "Write a function to count the frequency of each character in a string and return a dictionary.\n\na = \"seveneleven\"\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Frequency of character",
      "createdAt": "2025-02-07T16:40:03.728Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a63763d24f993c6c896ae1",
      "submissionId": {
        "_id": "67a63763d24f993c6c896ade",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Seven Eleven",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738946309/o9rxkaz2akmnq4cygvwf.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "Write a function to find all unique substrings of a given length in a string.\n \ninput_string = \"abcabc\"\nsub_str_len = 3\n \n['abc', 'bca', 'cab']\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Finding Unique substrings",
      "createdAt": "2025-02-07T16:40:03.728Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a63763d24f993c6c896ae2",
      "submissionId": {
        "_id": "67a63763d24f993c6c896ade",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Seven Eleven",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738946309/o9rxkaz2akmnq4cygvwf.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "Match \n\nTeam1 team2 winner\nA\tC\tC\nB\tD\tB\nD\tA\tA\nC\tB\tB\nE\tC\tE\n \n  Query to find the total number of matches\n \n Team matches_played #_wins #_loss\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Total matches query",
      "createdAt": "2025-02-07T16:40:03.728Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a65396d24f993c6c896bcf",
      "submissionId": {
        "_id": "67a65396d24f993c6c896bcd",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "40L-50L",
        "companyName": "Sigmoid",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738952647/a4tmuu3ajjf9v6dplyoq.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "How will you design an app like Split Wise on GCP? Create a High level architecture diagram. The interviewer wanted to asses if the candidate knew the different components for full stack development of an everyday App and wanted to asses the knowledge of different services in GCP.",
      "images": [],
      "category": "others",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "Split wise Design",
      "createdAt": "2025-02-07T18:40:22.699Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a65396d24f993c6c896bd0",
      "submissionId": {
        "_id": "67a65396d24f993c6c896bcd",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "40L-50L",
        "companyName": "Sigmoid",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738952647/a4tmuu3ajjf9v6dplyoq.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "Given a string s containing just the characters '(', ')', '{', '}', '[' and ']', determine if the input string is valid.\n\nAn input string is valid if:\n\nOpen brackets must be closed by the same type of brackets.\nOpen brackets must be closed in the correct order.\nEvery close bracket has a corresponding open bracket of the same type.\n\nExample 1:\n\nInput: s = \"()\"\n\nOutput: true\n\nExample 2:\n\nInput: s = \"()[]{}\"\n\nOutput: true\n\nNote - This is a direct question from Leetcode.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Special Characters",
      "createdAt": "2025-02-07T18:40:22.699Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a65396d24f993c6c896bd1",
      "submissionId": {
        "_id": "67a65396d24f993c6c896bcd",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "40L-50L",
        "companyName": "Sigmoid",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738952647/a4tmuu3ajjf9v6dplyoq.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "1) Explain the end to end architecture of project. Explain the ingestion mechanism, the different processing layers, the Data Quality checks, the platform used. Asked to explain the different Data Quality checks implemented.\n2) Compare using Databricks for a Data warehousing projects versus BigQuery. What are the pros and cons of each solution? Why would you choose one over the other? \n3) Spark internal questions like how to choose the cluster configuration in Databricks - Given a 10GB file, explain your thought process behind choosing a Cluster configuration\n4) What is the small file problem? How do you overcome the same in Databricks. How is the same done in BigQuery?\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Project DE",
      "createdAt": "2025-02-07T18:40:22.700Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a6baa8d24f993c6c896d54",
      "submissionId": {
        "_id": "67a6baa8d24f993c6c896d52",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Goldman Sachs Group",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738980004/hvydezpiwdkwvruwqpxf.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Streaming Data Pipeline Design\n\nYour company collects clickstream data from millions of users across multiple platforms. You need to design a real-time data pipeline that ingests, processes, and stores this data efficiently.\n\nHow would you design this pipeline using GCP services?\nWhat technologies would you use for ingestion, transformation, and storage?\nHow would you handle late-arriving events and out-of-order data?",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Streaming data pipeline design",
      "createdAt": "2025-02-08T02:00:08.152Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a6baa8d24f993c6c896d55",
      "submissionId": {
        "_id": "67a6baa8d24f993c6c896d52",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Goldman Sachs Group",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738980004/hvydezpiwdkwvruwqpxf.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": " Optimizing Joins in PySpark\n\nYou have two large datasets:\n\norders (100M rows) with columns: order_id, customer_id, order_date, amount.\ncustomers (10M rows) with columns: customer_id, name, email.\nYou need to join them efficiently to get the total amount spent by each customer.\n\n1. What type of join strategy would you use?\n2. How would you optimize performance for large-scale joins in PySpark?\n3. How would broadcast joins help, and when should they be avoided?",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Join optimizations",
      "createdAt": "2025-02-08T02:00:08.153Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a6baa8d24f993c6c896d56",
      "submissionId": {
        "_id": "67a6baa8d24f993c6c896d52",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Goldman Sachs Group",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738980004/hvydezpiwdkwvruwqpxf.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Designing a Data Lake & Warehouse for a FinTech Company\n\nA FinTech startup wants to build a data lake for storing raw transaction logs and a data warehouse for analytics and reporting.\n\nRequirements:\nIngest data from multiple sources (Kafka, APIs, Cloud Storage).\nStore raw data in a Data Lake (GCS/S3) and process it into a structured format.\nUse a data warehouse (BigQuery/Snowflake) for BI & dashboards.\nImplement data governance, access control, and security.\n\nQuestions:\nHow would you design the data lake and warehouse architecture?\nWhat file formats (Parquet, Avro, JSON) would you use for efficient querying?\nHow would you partition, cluster, and optimize queries in BigQuery/Snowflake?\nHow would you ensure compliance with security standards (GDPR, PII masking, encryption)",
      "images": [],
      "category": "project based",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " Design Fintect pipeline",
      "createdAt": "2025-02-08T02:00:08.153Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a6e54cd24f993c6c896e73",
      "submissionId": {
        "_id": "67a6e54cd24f993c6c896e71",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Paytm",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738989731/spucpc0rtcsvwarp2aqh.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Given the list of numbers add 1 to the number and return ans in the form of list.",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738990531/m3y7g0xrn3rdsvodeahd.png"
      ],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": "Numbers with addition",
      "createdAt": "2025-02-08T05:02:04.163Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a6e54cd24f993c6c896e74",
      "submissionId": {
        "_id": "67a6e54cd24f993c6c896e71",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Paytm",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738989731/spucpc0rtcsvwarp2aqh.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Q . Given the table information like this asked to get the difference\tbtw them\n\nTable - employee\n\nDate \t\t type\t\tfruits\t\tcost\n2025-01-01\t   1\t\tmango\t100\n2025-01-01\t   2\t\tapple\t\t50\n2025-01-02\t   1\t\tmango\t70\n2025-01-02\t   2\t\tapple\t\t120\n2025-01-03\t   1\t\tmango\t95\n\nHe wants results like below\n\nDate\t\t\tcost(difference abs(mango - apple)\n2025-01-01\t\t50\n2025-01-02\t\t50\n2025-01-03\t\t95\n",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738990651/an52qiqpevjdb0nfmyyb.png"
      ],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": "  Table difference list",
      "createdAt": "2025-02-08T05:02:04.163Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a6e54cd24f993c6c896e75",
      "submissionId": {
        "_id": "67a6e54cd24f993c6c896e71",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Paytm",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738989731/spucpc0rtcsvwarp2aqh.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "2) DSA:-  Remove most consecutive characters â€” used stack\n",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738990848/jiaiy4xzsnhzrvulisdv.png"
      ],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Consecutive characters removal",
      "createdAt": "2025-02-08T05:02:04.163Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a6f10ad24f993c6c896eb1",
      "submissionId": {
        "_id": "67a6f10ad24f993c6c896eaf",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Paytm",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738993802/lksdt4mrb5cjjngkwucm.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "\nQ - Top K frequent elements from leetcode - I have solved this\n",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738993839/gwyancku4ub18gx3yhjw.png"
      ],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "leetcode Frequent elements ",
      "createdAt": "2025-02-08T05:52:10.787Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a6f10ad24f993c6c896eb2",
      "submissionId": {
        "_id": "67a6f10ad24f993c6c896eaf",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Paytm",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738993802/lksdt4mrb5cjjngkwucm.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "\n1) SQL:- pivot the given table below\n\nTable: Sales\nAssume you have a table called sales with the following structure:\n\nElectronics\tTV\t1000\nElectronics   Radio 500\nFurniture\t     Sofa\t1500\n\nFurniture\t    Table\t700\n\nElectronics\t1000\t500\t   0\t               0\nFurniture\t        0\t     \t0\t    1500\t     700\n\n\nDepart ,prod, amountâ€”\n\nOutput - dept , TV,Radio,Sofa,Table\n",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738993894/cozbrqevxkeamtgqchzc.png"
      ],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Electronics sales",
      "createdAt": "2025-02-08T05:52:10.788Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a6f10ad24f993c6c896eb3",
      "submissionId": {
        "_id": "67a6f10ad24f993c6c896eaf",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "Paytm",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1738993802/lksdt4mrb5cjjngkwucm.png"
        ],
        "yoe": "<2",
        "role": "Data Engineer-1"
      },
      "text": "Q - Consecutive Numbers From Leetcode SQL 50\nQ - Exchange Seats from Leetcode SQL 50",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": "Numbers, seats in Leetcode ",
      "createdAt": "2025-02-08T05:52:10.788Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a748d0d24f993c6c89716e",
      "submissionId": {
        "_id": "67a748d0d24f993c6c89716c",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Value Labs",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739016247/bmia4jt1xsrzxthdsrgh.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "Your team has a Data Lake storing structured and semi-structured data. A new field is added to incoming JSON data. How will you handle schema evolution?\n",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739016280/xa48frbf3gas6nz1crjq.png"
      ],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " New column JSON ",
      "createdAt": "2025-02-08T12:06:40.617Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a748d0d24f993c6c89716f",
      "submissionId": {
        "_id": "67a748d0d24f993c6c89716c",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Value Labs",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739016247/bmia4jt1xsrzxthdsrgh.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "Your Kafka-to-Spark Streaming pipeline processes fuel transaction logs from multiple refineries. Suddenly, you notice that 10% of the incoming data contains NULL values in critical fields like fuel_quantity . How will you handle this in real time without stopping the pipeline?",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739016324/vhtbdyibf3afpzgq6g6c.png"
      ],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " NULL values scenario",
      "createdAt": "2025-02-08T12:06:40.617Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a748d0d24f993c6c897170",
      "submissionId": {
        "_id": "67a748d0d24f993c6c89716c",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "30L-40L",
        "companyName": "Value Labs",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739016247/bmia4jt1xsrzxthdsrgh.png"
        ],
        "yoe": "8-12",
        "role": " Lead Data Engineer"
      },
      "text": "You have a Spark job that processes 1 TB of data daily and is taking 5 hours to complete. How will you optimize it?",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739016366/t1nvlpax5cqccfxfzx9y.png"
      ],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Job optimization",
      "createdAt": "2025-02-08T12:06:40.617Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a9ff10d24f993c6c897851",
      "submissionId": {
        "_id": "67a9ff10d24f993c6c89784f",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Bain & Company",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739193779/olhi6atcvjiemfzvzlxq.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write a program to find the length of longest substring without repeating characters\nInput - 'abcabd'\nOutput - 3",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Find repeating characters",
      "createdAt": "2025-02-10T13:28:48.944Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67a9ff10d24f993c6c897852",
      "submissionId": {
        "_id": "67a9ff10d24f993c6c89784f",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Bain & Company",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739193779/olhi6atcvjiemfzvzlxq.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write a program to generate a list with random numbers, given an integer 'n'. The list should contain equal number of negative and positive numbers\nInput - 4\nOutput - [1, -1, 2, -2]\n\nInput - 3\nOutput - [1, -1, 0]",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Random numbers generation",
      "createdAt": "2025-02-10T13:28:48.944Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67a9ff10d24f993c6c897853",
      "submissionId": {
        "_id": "67a9ff10d24f993c6c89784f",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Bain & Company",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739193779/olhi6atcvjiemfzvzlxq.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "How will you decrease cluster costs when you're processing large amounts of data in Spark?",
      "images": [],
      "category": "scenario based",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Spark data optimization",
      "createdAt": "2025-02-10T13:28:48.944Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67aa0049d24f993c6c89785b",
      "submissionId": {
        "_id": "67aa0049d24f993c6c897859",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "ShopSe",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739194271/nflaessws0m0lpl0tjt1.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write a program to generate fibonacci numbers that fall between the two given integers:\nInput : a=20, b=80\nOutput : [21, 34, 55]",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Fibonacci number",
      "createdAt": "2025-02-10T13:34:01.549Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67aa0049d24f993c6c89785c",
      "submissionId": {
        "_id": "67aa0049d24f993c6c897859",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "ShopSe",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739194271/nflaessws0m0lpl0tjt1.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write a program to find common prefix between the strings in a given list:\nInput: ['listy', 'lisriu', 'lisbon']\nOutput: 'lis'",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Find common Prefix",
      "createdAt": "2025-02-10T13:34:01.549Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67aa0049d24f993c6c89785d",
      "submissionId": {
        "_id": "67aa0049d24f993c6c897859",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "ShopSe",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739194271/nflaessws0m0lpl0tjt1.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "How to tackle the data skew problem?",
      "images": [],
      "category": "scenario based",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Data skew ",
      "createdAt": "2025-02-10T13:34:01.549Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67aa3d4ed24f993c6c897cb3",
      "submissionId": {
        "_id": "67aa3d4dd24f993c6c897cb1",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Tech Mahindra",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739207909/sz5gdpuw09e8efyadmy7.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Find factorial of a number in python\n\nSolution: (using recursion)\nFactorial of a number\n\ndef factorial(n):\n\tif n==0 or n==1 :\n\t\treturn 1\n\telse:\n\t\treturn n*factorial(n-1)",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Factorial of number",
      "createdAt": "2025-02-10T17:54:22.022Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67aa3d4ed24f993c6c897cb4",
      "submissionId": {
        "_id": "67aa3d4dd24f993c6c897cb1",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Tech Mahindra",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739207909/sz5gdpuw09e8efyadmy7.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Design a query that identifies the top 5 students based on their scores from a Students table. select only those students who are in the top 5 ranks.\nSolution:\n\nWITH cte AS (\n    SELECT \n        StudentID, \n        Name, \n        Score,\n        RANK() OVER (ORDER BY Score DESC) AS rank\n    FROM Students\n)\nSELECT *\nFROM cte\nWHERE rank <= 5\n\nSample Input (Example Students Table):\n| StudentID | Name      | Score |\n|-----------|-----------|-------|\n| 1         | Alice     | 95    |\n| 2         | Bob       | 88    |\n| 3         | Charlie   | 92    |\n| 4         | David     | 85    |\n| 5         | Eve       | 90    |\n| 6         | Frank     | 87    |\n| 7         | Grace     | 93    |\n| 8         | Henry     | 89    |\n\nSample Output (Top 5 Students):\n| StudentID | Name      | Score | rank |\n|-----------|-----------|-------|------|\n| 1         | Alice     | 95    | 1    |\n| 3         | Charlie   | 92    | 2    |\n| 7         | Grace     | 93    | 3    |\n| 5         | Eve       | 90    | 4    |\n| 2         | Bob       | 88    | 5    |\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Top 5 ranks of students",
      "createdAt": "2025-02-10T17:54:22.022Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67aa3d4ed24f993c6c897cb5",
      "submissionId": {
        "_id": "67aa3d4dd24f993c6c897cb1",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Tech Mahindra",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739207909/sz5gdpuw09e8efyadmy7.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Question:\nGiven a table with a sequence of numbers, find the missing numbers in the range 1 to the maximum number present in the table.\n\nSolution:\nSample Table (Numbers)\nID\n1\n2\n3\n5\n6\n8\nExpected Output (Missing Numbers in Sequence)\nMissing_Number\n4\n7\n\n\nWITH NumberSeries AS (\n    SELECT ROW_NUMBER() OVER (ORDER BY (SELECT NULL)) AS Num\n    FROM master.dbo.spt_values  -- Generates a sequence of numbers (SQL Server)\n)\nSELECT Num AS Missing_Number\nFROM NumberSeries\nLEFT JOIN Numbers N ON NumberSeries.Num = N.ID\nWHERE Num BETWEEN 1 AND (SELECT MAX(ID) FROM Numbers) -- Restricting range\nAND N.ID IS NULL;\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Missing number",
      "createdAt": "2025-02-10T17:54:22.022Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67ac6bd8d24f993c6c898418",
      "submissionId": {
        "_id": "67ac6bd8d24f993c6c898416",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "NeoStats Analytics Solutions.",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739352689/dnkhtbsixe2wp1lzipcc.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Problem Statement:\nYou are given an array of integers arr, its size n, and a number k. The arguments are passed in the order: n, arr, k.\n\nWrite a function findMinMaxSum that computes:\n\nThe maximum possible element in the array after discarding exactly k elements.\nThe minimum possible element in the array after discarding exactly k elements.\nReturn these two values in an array [max, min].\n\nConstraints:\nYou must not use any built-in sorting library function.\nk < n (ensuring at least one element remains in the array after removing k elements).",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": "findMinMaxSum python ",
      "createdAt": "2025-02-12T09:37:28.728Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67ac6bd8d24f993c6c898419",
      "submissionId": {
        "_id": "67ac6bd8d24f993c6c898416",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "NeoStats Analytics Solutions.",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739352689/dnkhtbsixe2wp1lzipcc.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "You are given a string s of length n and an integer k. The arguments are passed in the order: n, s, k.\n\nWrite a function findMinMaxChar that:\n\nFinds the lexicographically largest character in the string after removing exactly k characters.\nFinds the lexicographically smallest character in the string after removing exactly k characters.\nReturn these two characters as an array [maxChar, minChar].\n\nConstraints:\nYou must not use any built-in sorting functions.\nk < n (ensuring at least one character remains in the string after removing k characters).",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " findMinMaxChar python",
      "createdAt": "2025-02-12T09:37:28.728Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67ac6bd8d24f993c6c89841a",
      "submissionId": {
        "_id": "67ac6bd8d24f993c6c898416",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "5L-10L",
        "companyName": "NeoStats Analytics Solutions.",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739352689/dnkhtbsixe2wp1lzipcc.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "You are given a table named sales with the following columns:\n\nColumn Name\tData Type\tDescription\nid\tINT\tUnique identifier for each sale\nname\tVARCHAR\tName of the employee\nmonth\tVARCHAR\tMonth of the sale\nsales\tINT\tSales amount for that month\nSample Data:\nid\tname\tmonth\tsales\n1\txyz\taug\t2000\n2\tabc\tsept\t3000\n1\txyz\tjan\t3000\n2\tabc\tfeb\t4000\n1\txyz\tfeb\t3000\n3\text\tjan\t3000\nQuestion:\nWrite an SQL query to find the top 5 employees based on their total sales across all months.\nIf multiple employees have the same sales amount, they should have the same rank.\n\nUse the RANK() window function to assign ranks based on total sales, and return only the top 5 ranked employees.\n\nExpected Output Format:\nname\ttotal_sales\trank\nxyz\t8000\t1\nabc\t7000\t2\next\t3000\t3",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": "Top 5 employees sales ",
      "createdAt": "2025-02-12T09:37:28.728Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67adf75cd24f993c6c8987d3",
      "submissionId": {
        "_id": "67adf75bd24f993c6c8987d0",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "EPAM System",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739454161/gt71mdwq4qjy51ic1de2.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Input = [2,6,8,9]\nTarget = 11\nfind possible matches and do it in python/scala",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "Possible matches python ",
      "createdAt": "2025-02-13T13:45:00.079Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67adf75cd24f993c6c8987d2",
      "submissionId": {
        "_id": "67adf75bd24f993c6c8987d0",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "EPAM System",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739454161/gt71mdwq4qjy51ic1de2.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "spark optimization techniques",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Spark optimization",
      "createdAt": "2025-02-13T13:45:00.079Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67adf75cd24f993c6c8987d4",
      "submissionId": {
        "_id": "67adf75bd24f993c6c8987d0",
        "status": "approved",
        "adminComment": "Approved!",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "EPAM System",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739454161/gt71mdwq4qjy51ic1de2.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "find duplicates from list using scala/python\n[1,2,3,3,4,6,8]",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Duplicates in list",
      "createdAt": "2025-02-13T13:45:00.079Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67ae200ad24f993c6c8988b5",
      "submissionId": {
        "_id": "67ae200ad24f993c6c8988b1",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "UBS",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739464429/hhvhrbll0na2lhfaz7g4.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write a program to sort array in ascending order.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": "Sort Array ",
      "createdAt": "2025-02-13T16:38:34.277Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67ae200ad24f993c6c8988b8",
      "submissionId": {
        "_id": "67ae200ad24f993c6c8988b1",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "UBS",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739464429/hhvhrbll0na2lhfaz7g4.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "What are traits, Case Class in Scala?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Scala ",
      "createdAt": "2025-02-13T16:38:34.277Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67ae200ad24f993c6c8988ba",
      "submissionId": {
        "_id": "67ae200ad24f993c6c8988b1",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "UBS",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739464429/hhvhrbll0na2lhfaz7g4.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Explain what use of Option[T] and Some[T] is in Scala, and how it helps in handling null or missing values.",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Scala ",
      "createdAt": "2025-02-13T16:38:34.277Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67ae200ad24f993c6c8988b6",
      "submissionId": {
        "_id": "67ae200ad24f993c6c8988b1",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "UBS",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739464429/hhvhrbll0na2lhfaz7g4.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write a SQL query/Spark code to calculate and populate how much hours employee spent inside office for a specific day.\n\ne.g. Input Table\nEmp_id status created\nEMP0001 check_in 2024-11-22 08:00:00\nEMP0002 check_in 2024-11-22 08:00:50\nEMP0001 check_out 2024-11-22 13:00:00\nEMP0002 check_out 2024-11-22 13:01:00\nEMP0001 check_in 2024-11-22 13:31:00\nEMP0002 check_in 2024-11-22 13:33:50\nEMP0001 check_out 2024-11-22 18:03:00\nEMP0002 check_out 2024-11-22 18:04:00\n\nExpected Output:\nEmp_id created time_spend_in office\nEMP0001 2024-11-24 08:00:00 09:32:00\nEMP0002 2024-11-24 08:00:50 09:30:20",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Employee working hours",
      "createdAt": "2025-02-13T16:38:34.277Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67ae200ad24f993c6c8988b7",
      "submissionId": {
        "_id": "67ae200ad24f993c6c8988b1",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "UBS",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739464429/hhvhrbll0na2lhfaz7g4.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "What is Singleton and Companion Objects in Scala.",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Scala ",
      "createdAt": "2025-02-13T16:38:34.277Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67ae200ad24f993c6c8988b9",
      "submissionId": {
        "_id": "67ae200ad24f993c6c8988b1",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "UBS",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739464429/hhvhrbll0na2lhfaz7g4.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "What are design patterns you are aware of in scala and also explain them?\ne.g. Singleton Pattern, Factory Pattern",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Design patterns scala",
      "createdAt": "2025-02-13T16:38:34.277Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67ae200ad24f993c6c8988b3",
      "submissionId": {
        "_id": "67ae200ad24f993c6c8988b1",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "UBS",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739464429/hhvhrbll0na2lhfaz7g4.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write Program to find all the permutations of a string using recursion.\n\ne.g\nInputStr = \"ABC\"\n\noutput:\nABC, ACB, BAC, BCA, CBA, CAB",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Permutation of a String",
      "createdAt": "2025-02-13T16:38:34.277Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67ae200ad24f993c6c8988b4",
      "submissionId": {
        "_id": "67ae200ad24f993c6c8988b1",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "UBS",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739464429/hhvhrbll0na2lhfaz7g4.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write a program read/query data from any type SQL database and write data to a output file.\n\ne.g. Say you have MYSQL DB, write script to perform following steps:\n1) Use any Library/module of your choice\n2) establish connection to DB using connector\n3) execute SQL query\n4) Fetch the query output and store in a file.\nType: problem solving",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " SQL Write & Read",
      "createdAt": "2025-02-13T16:38:34.277Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67aeb1d4d24f993c6c8989cd",
      "submissionId": {
        "_id": "67aeb1d3d24f993c6c8989cb",
        "status": "approved",
        "adminComment": "Approved",
        "country": "United States",
        "ctc": "70L-80L",
        "companyName": "California Govt",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739501037/pgirny7xofijrgokta0w.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Consider there is a OLTP data like MySQL. you need to bring the data from that database to a data warehouse in near realtime. Assume the compute and storage is not a problem. And the data will be transferred in during business hours and there is a lot of read operations that happens during that time. Wht would be your approach?",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "Design OLTP system ",
      "createdAt": "2025-02-14T03:00:36.021Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67aeb1d4d24f993c6c8989cf",
      "submissionId": {
        "_id": "67aeb1d3d24f993c6c8989cb",
        "status": "approved",
        "adminComment": "Approved",
        "country": "United States",
        "ctc": "70L-80L",
        "companyName": "California Govt",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739501037/pgirny7xofijrgokta0w.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "You are designing a batch ETL pipeline that processes daily sales data from an S3 bucket and loads it into a Snowflake data warehouse. The raw data files are in CSV format and contain duplicate records due to data ingestion issues.\n\n\nHow would you design the batch pipeline to efficiently process and deduplicate the data before loading it into Snowflake?\nWhat strategies would you use to handle late-arriving data in batch processing?\nWrite a SQL or Spark query to remove duplicates based on the order_id before inserting the data into Snowflake.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Design ETL sales pipeline",
      "createdAt": "2025-02-14T03:00:36.022Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67aeb1d4d24f993c6c8989ce",
      "submissionId": {
        "_id": "67aeb1d3d24f993c6c8989cb",
        "status": "approved",
        "adminComment": "Approved",
        "country": "United States",
        "ctc": "70L-80L",
        "companyName": "California Govt",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739501037/pgirny7xofijrgokta0w.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "You have a scenario where your database performance is degrading. What would be your approach at database tier and at sever level? How would you approach this problem in solving this?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Database performance degrade",
      "createdAt": "2025-02-14T03:00:36.022Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67af81ded24f993c6c898c54",
      "submissionId": {
        "_id": "67af81ddd24f993c6c898c52",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Exl",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739555079/gkiyzuismtzipnk4kkwu.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Find total number of clocked hours for each employee (inside the office) Flag I means punch in and O means punch out. Employee can do multiple punch in and punch out. For each punch in there will be a punch out.\n input -\nEmp ID  Time    Flag\n114         8:30    I\n114        10:30    O\n114        11:30    I\n114        15:30    O\n115        9:30      I\n115        17:30    O\n\noutput -\n\nEmpId Time\n114    6hrs\n115    8hrs",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Employee working hours",
      "createdAt": "2025-02-14T17:48:14.053Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67af81ded24f993c6c898c56",
      "submissionId": {
        "_id": "67af81ddd24f993c6c898c52",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Exl",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739555079/gkiyzuismtzipnk4kkwu.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "spark optimization techniques and dif between repartition and coalesce",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Spark optimization techniques",
      "createdAt": "2025-02-14T17:48:14.053Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67af81ded24f993c6c898c55",
      "submissionId": {
        "_id": "67af81ddd24f993c6c898c52",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Exl",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739555079/gkiyzuismtzipnk4kkwu.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "input - ['aet','tea','bet','teb','ebt']\noutput - ['aet',tea] , ['teb',ebt','tbe']\nfind all anagrams and group similar words together in a list using scala / python",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Anagrams grouping ",
      "createdAt": "2025-02-14T17:48:14.053Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67b24c06d24f993c6c8991a2",
      "submissionId": {
        "_id": "67b24c05d24f993c6c89919f",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Ecom Express",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739737714/oilly4shci6fvzznj9gh.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write query to Swap the names of students in pairs such that students with odd id get the name of the next id, and students with even id get the name of the previous id.\n\nGiven Student Table\n\nid\t\tname\n1\t\ta\n2\t\tb\n3\t\tc\n4\t\td\n\nExpected output\nid \tname\n1\tb\n2\ta\n3\td\n4\tc",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Swap student names",
      "createdAt": "2025-02-16T20:35:18.009Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67b24c06d24f993c6c8991a3",
      "submissionId": {
        "_id": "67b24c05d24f993c6c89919f",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Ecom Express",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739737714/oilly4shci6fvzznj9gh.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Given Cluster Configuration:6 node, 16 core, 64gb ram \nFind the number of executors and each executor memory",
      "images": [],
      "category": "scenario based",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Cluster configuration",
      "createdAt": "2025-02-16T20:35:18.009Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67b24c06d24f993c6c8991a1",
      "submissionId": {
        "_id": "67b24c05d24f993c6c89919f",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Ecom Express",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739737714/oilly4shci6fvzznj9gh.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Given two teams. Write SQL Query to find the number of match played between different teams.\nSample Dataset\n\nteam1\tteam2\na\tb\na\tc\na\td\nb \tc",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Matches Played",
      "createdAt": "2025-02-16T20:35:18.008Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67b24d70d24f993c6c8991ab",
      "submissionId": {
        "_id": "67b24d70d24f993c6c8991a9",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "GlobalLogic",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739738245/vsngljjzwts1tzkergxy.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Given Device Table as below:\n\nDEVICE_ID\tHOST_ID\t\tPAIRING_TIME\nBT1\t\tTV1\t\t3PM\nBT1\t\tMob1\t\t9AM\nBT1\t\tLP1\t\t6PM\nUSB1\t\tMob1\t\t12PM\n\nWrite sql query to return\nDEVICE_ID\tFIRST_PAIRED_HOST\tFIRST_PAIRED_TIME\tLATEST_PAIRED_HOST\tLATEST_PAIRED_TIME\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Bluetooth paired devices",
      "createdAt": "2025-02-16T20:41:20.796Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67b24d70d24f993c6c8991ac",
      "submissionId": {
        "_id": "67b24d70d24f993c6c8991a9",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "GlobalLogic",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739738245/vsngljjzwts1tzkergxy.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Given Sales Table with Columns:\t\t\t\nitem\tcategory\tyear\tqty_sold\tprice_per_unit\n\nWrite sql query to return\ncategory, year, year_growth\n\nGiven \nrevenue = qty_sold * price_per_unit",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Growth on year basis",
      "createdAt": "2025-02-16T20:41:20.796Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67b24d70d24f993c6c8991ad",
      "submissionId": {
        "_id": "67b24d70d24f993c6c8991a9",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "GlobalLogic",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739738245/vsngljjzwts1tzkergxy.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Given two tables as below\nA\t\tB\nID\t\tID\n\n1\t\t1\n1\t\t1\n1\t\t1\n1\t\t2\n1\t\t3\n1\t\t4\n\nTell me the number of count of all joins (inner, left, outer, full outer) ",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " SQL Joins",
      "createdAt": "2025-02-16T20:41:20.796Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67b30b4bd24f993c6c899313",
      "submissionId": {
        "_id": "67b30b4bd24f993c6c89930f",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Elanco",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739786133/igkd1dwy86iln7tplxsx.png",
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739786134/yeyhu3qxjkrao0plosc3.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "1. Different Types of Join Strategies in Spark\n2. How to optimize a spark job?\n",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Spark DE",
      "createdAt": "2025-02-17T10:11:23.844Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67b30b4bd24f993c6c899311",
      "submissionId": {
        "_id": "67b30b4bd24f993c6c89930f",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Elanco",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739786133/igkd1dwy86iln7tplxsx.png",
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739786134/yeyhu3qxjkrao0plosc3.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "SQL Question\nGiven the reviews table, write a query to retrieve the average star rating for each product, grouped by month. The output should display the month as a numerical value, product ID, and average star rating rounded to two decimal places. Sort the output first by month and then by product ID.\n\nreviews table - review_id, user_id, product_id, review_date, stars\nWas also asked to write the solution in Pyspark as well.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Average product rating",
      "createdAt": "2025-02-17T10:11:23.843Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67b30b4bd24f993c6c899312",
      "submissionId": {
        "_id": "67b30b4bd24f993c6c89930f",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Elanco",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739786133/igkd1dwy86iln7tplxsx.png",
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739786134/yeyhu3qxjkrao0plosc3.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Python Problem\n\nYou are given two lists:\nexpectations: A list where each element represents the minimum card value a person expects.\ncards: A list of available card values.\nEach person can be satisfied if they receive a card with a value greater than or equal to their expectation. However, a card can only be assigned to one person.\n\nYour task is to determine the maximum number of people who can be satisfied by distributing the available cards optimally.\n\nexpectations = [5, 10, 1000]  \ncards = [10, 15, 100] \n\noutput - 2",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": "Distribute available cards",
      "createdAt": "2025-02-17T10:11:23.844Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67b313b2d24f993c6c899325",
      "submissionId": {
        "_id": "67b313b2d24f993c6c899321",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "GIST Impact",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739789115/os8ajztxgolagygpzzet.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "You are given a list of dictionaries where each dictionary represents a product with keys: product_id, category, and price. Write a function to calculate the total price of products in each category and return the results as a dictionary.\n\nInput- products = [\n{\"product_id\": 1, \"category\": \"Electronics\", \"price\": 299.99},\n{\"product_id\": 2, \"category\": \"Electronics\", \"price\": 199.99},\n{\"product_id\": 3, \"category\": \"Clothing\", \"price\": 49.99},\n{\"product_id\": 4, \"category\": \"Clothing\", \"price\": 19.99},\n{\"product_id\": 5, \"category\": \"Books\", \"price\": 9.99}\n]\n\noutput:\n{\n\"Electronics\": 499.98,\n\"Clothing\": 69.98,\n\"Books\": 9.99\n}",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Total product price",
      "createdAt": "2025-02-17T10:47:14.211Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67b313b2d24f993c6c899323",
      "submissionId": {
        "_id": "67b313b2d24f993c6c899321",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "GIST Impact",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739789115/os8ajztxgolagygpzzet.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "You are given a table with employee salary data recorded at different quarters. However, some salary values are missing (NULL or empty).\nYour task is to write an SQL query that fills the missing salary values by carrying forward the last known salary from the previous quarter for each id.\n\nAttached the sample input and output.",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739789122/efmolnoxsvlzw5rhswrm.png"
      ],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Last known salary",
      "createdAt": "2025-02-17T10:47:14.210Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67b313b2d24f993c6c899324",
      "submissionId": {
        "_id": "67b313b2d24f993c6c899321",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "GIST Impact",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739789115/os8ajztxgolagygpzzet.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "You are given a table containing id and cost values. Your task is to compute the running total (cumulative sum) of cost for each id.\n\nAdditionally, analyze the behavior of NULL values in the id column when using window functions with PARTITION BY id.\n\nid cost\n1 10\n2 20\n2 30\nnull 10\n3 20\n3 30",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": "cumulative sum of product ",
      "createdAt": "2025-02-17T10:47:14.211Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67b313b2d24f993c6c899326",
      "submissionId": {
        "_id": "67b313b2d24f993c6c899321",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "GIST Impact",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739789115/os8ajztxgolagygpzzet.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "1. How to optimize a long-running pipeline in Azure Data Factory?\n2. How is the logging and alert mechanism set up in ADF in your project?\n3. Different types of integration runtimes in ADF and when do you use them?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Azure DE",
      "createdAt": "2025-02-17T10:47:14.211Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67b46b06d24f993c6c8997c8",
      "submissionId": {
        "_id": "67b46b06d24f993c6c8997c5",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Amazon",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739876340/gzubqfwl6orsc8i5nwhr.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write a Python program to determine the minimum characters that need to be added to a given string to make it a palindrome.\n\nexample:\nInput: \"abcd\"\nOutput: 3 (\"dcb\" needs to be added, resulting in \"abcdcba\")\n\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " Palindrome character addition",
      "createdAt": "2025-02-18T11:12:06.876Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67b46b06d24f993c6c8997c7",
      "submissionId": {
        "_id": "67b46b06d24f993c6c8997c5",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Amazon",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739876340/gzubqfwl6orsc8i5nwhr.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Table Routes\nStops\n1\n2\n3\n6\n8\n9\n\n\nWrite an SQL query to identify the continuous delivery segments where the driver delivered without skipping a stop. The output should display the start and end stops of each continuous sequence.\n\noutput\nstart         end\n1               3\n8               9",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Driver package delivery",
      "createdAt": "2025-02-18T11:12:06.876Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67b46b06d24f993c6c8997c9",
      "submissionId": {
        "_id": "67b46b06d24f993c6c8997c5",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Amazon",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739876340/gzubqfwl6orsc8i5nwhr.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "How can you efficiently join two large tables while optimizing performance?",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": "Spark optimization ",
      "createdAt": "2025-02-18T11:12:06.877Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67b46f7ad24f993c6c8997e8",
      "submissionId": {
        "_id": "67b46f7ad24f993c6c8997e4",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Broadridge",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739877683/cxkrvnh2xi0btvvzoybh.jpg"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Given a list of countries:\nIndia\nSri Lanka\nBangladesh\nPakistan\nEach country needs to play against every other country once. Generate the output where each match consists of Team A vs Team B",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Matches between countries",
      "createdAt": "2025-02-18T11:31:06.607Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67b46f7ad24f993c6c8997e7",
      "submissionId": {
        "_id": "67b46f7ad24f993c6c8997e4",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Broadridge",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739877683/cxkrvnh2xi0btvvzoybh.jpg"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Executor configuration :\nMemory per executor : 13GB\nCores per Executor : 5 cores\nData processing speed : 256MB of data processed in 20 seconds\nFind total tasks, ideal executors, tasks in parallel and execution time for a 1TB file",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Spark configuration",
      "createdAt": "2025-02-18T11:31:06.607Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67b46f7ad24f993c6c8997e6",
      "submissionId": {
        "_id": "67b46f7ad24f993c6c8997e4",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Broadridge",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739877683/cxkrvnh2xi0btvvzoybh.jpg"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Find the largest common prefix for the list of strings given below:\n[â€œgeeksforgeeksâ€, â€œgeeksâ€, â€œgeekâ€, â€œgeezerâ€]",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Largest prefix",
      "createdAt": "2025-02-18T11:31:06.607Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67b48756d24f993c6c899837",
      "submissionId": {
        "_id": "67b48756d24f993c6c899835",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "scientist technologies",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739884200/xjhaeio6razriquqklx8.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "a=[1,2,3,4,5,5,4,3,2,4,6,7,8,12,11,10,11,45,6,7,3]\nWrite python programme to find the count of occurances",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Occurance of numbers",
      "createdAt": "2025-02-18T13:12:54.909Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67b48756d24f993c6c899838",
      "submissionId": {
        "_id": "67b48756d24f993c6c899835",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "scientist technologies",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739884200/xjhaeio6razriquqklx8.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write python/pyspark code to ingest the data(20GB) which has integer data. Load the data into another source in ascending format",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Data load in ascending order",
      "createdAt": "2025-02-18T13:12:54.909Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67b48756d24f993c6c899839",
      "submissionId": {
        "_id": "67b48756d24f993c6c899835",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "scientist technologies",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739884200/xjhaeio6razriquqklx8.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Explain about role and responsibilies in your current project",
      "images": [],
      "category": "project based",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Project DE",
      "createdAt": "2025-02-18T13:12:54.909Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67b54ff0d24f993c6c899a4f",
      "submissionId": {
        "_id": "67b54ff0d24f993c6c899a4d",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Games24x7",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739935556/thofz0sdc6xs0dfarxzt.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "nums = [{\"dt\":\"2024-08-01\",\"stock\":\"abcd\",\"price\":\"245\",\"volume\":\"1500\"},\n{\"dt\":\"2024-08-02\",\"stock\":\"abcd\",\"price\":\"235\",\"volume\":\"1800\"},\n{\"dt\":\"2024-08-03\",\"stock\":\"abcd\",\"price\":\"240\",\"volume\":\"1400\"},\n{\"dt\":\"2024-08-04\",\"stock\":\"abcd\",\"price\":\"252\",\"volume\":\"1200\"},\n{\"dt\":\"2024-08-05\",\"stock\":\"abcd\",\"price\":\"265\",\"volume\":\"1000\"},\n{\"dt\":\"2024-08-06\",\"stock\":\"abcd\",\"price\":\"215\",\"volume\":\"1000\"}]\n\n\nFind the following - \n1) min_price\n2) max_price\n3) avg_volume\n4) max_profit (buy first then sell)",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Stock price analysis",
      "createdAt": "2025-02-19T03:28:48.354Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67b54ff0d24f993c6c899a50",
      "submissionId": {
        "_id": "67b54ff0d24f993c6c899a4d",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Games24x7",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739935556/thofz0sdc6xs0dfarxzt.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "games -\n+---------------------+---------+---------+----------+------------+\n| tstamp              | user_id | game_id | win_flag | points_won |\n+---------------------+---------+---------+----------+------------+\n| 2024-08-01 00:00:01 |    1000 |       1 |        1 |         50 |\n| 2024-08-02 11:01:00 |    1001 |       2 |        0 |          0 |\n| 2024-08-03 12:53:00 |    1003 |       3 |        1 |         30 |\n| 2024-08-03 14:53:01 |    1000 |       4 |        0 |          0 |\n| 2024-08-03 13:51:01 |    1001 |       5 |        0 |          0 |\n| 2024-08-03 00:53:01 |    1005 |       7 |        0 |          0 |\n| 2024-08-03 00:53:01 |    1006 |       8 |        0 |          0 |\n| 2024-08-03 12:53:00 |    1003 |       9 |        1 |         10 |\n| 2024-08-02 15:01:00 |    1001 |      10 |        1 |         20 |\n+---------------------+---------+---------+----------+------------+\n\n\na) Daily total no. of games played\n\nExpected output - \n+------------+-------------+\n| dt         | total_games |\n+------------+-------------+\n| 2024-08-01 |           1 |\n| 2024-08-02 |           2 |\n| 2024-08-03 |           6 |\n+------------+-------------+",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": " Total games played",
      "createdAt": "2025-02-19T03:28:48.354Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67b54ff0d24f993c6c899a51",
      "submissionId": {
        "_id": "67b54ff0d24f993c6c899a4d",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Games24x7",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739935556/thofz0sdc6xs0dfarxzt.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "\ngames -\n+---------------------+---------+---------+----------+------------+\n| tstamp              | user_id | game_id | win_flag | points_won |\n+---------------------+---------+---------+----------+------------+\n| 2024-08-01 00:00:01 |    1000 |       1 |        1 |         50 |\n| 2024-08-02 11:01:00 |    1001 |       2 |        0 |          0 |\n| 2024-08-03 12:53:00 |    1003 |       3 |        1 |         30 |\n| 2024-08-03 14:53:01 |    1000 |       4 |        0 |          0 |\n| 2024-08-03 13:51:01 |    1001 |       5 |        0 |          0 |\n| 2024-08-03 00:53:01 |    1005 |       7 |        0 |          0 |\n| 2024-08-03 00:53:01 |    1006 |       8 |        0 |          0 |\n| 2024-08-03 12:53:00 |    1003 |       9 |        1 |         10 |\n| 2024-08-02 15:01:00 |    1001 |      10 |        1 |         20 |\n+---------------------+---------+---------+----------+------------+\n\n\nb) Top 3 users having highest win ratio\n\nExpected output - \n+---------+-----------+\n| user_id | win_ratio |\n+---------+-----------+\n|    1003 |    1.0000 |\n|    1000 |    0.5000 |\n|    1001 |    0.3333 |\n+---------+-----------+\n\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": false,
      "summary": "Highest win ratio ",
      "createdAt": "2025-02-19T03:28:48.354Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67b54ff0d24f993c6c899a52",
      "submissionId": {
        "_id": "67b54ff0d24f993c6c899a4d",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Games24x7",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1739935556/thofz0sdc6xs0dfarxzt.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "games -\n+---------------------+---------+---------+----------+------------+\n| tstamp              | user_id | game_id | win_flag | points_won |\n+---------------------+---------+---------+----------+------------+\n| 2024-08-01 00:00:01 |    1000 |       1 |        1 |         50 |\n| 2024-08-02 11:01:00 |    1001 |       2 |        0 |          0 |\n| 2024-08-03 12:53:00 |    1003 |       3 |        1 |         30 |\n| 2024-08-03 14:53:01 |    1000 |       4 |        0 |          0 |\n| 2024-08-03 13:51:01 |    1001 |       5 |        0 |          0 |\n| 2024-08-03 00:53:01 |    1005 |       7 |        0 |          0 |\n| 2024-08-03 00:53:01 |    1006 |       8 |        0 |          0 |\n| 2024-08-03 12:53:00 |    1003 |       9 |        1 |         10 |\n| 2024-08-02 15:01:00 |    1001 |      10 |        1 |         20 |\n+---------------------+---------+---------+----------+------------+\n\n\nc) Leaderboard based on total points won, \nin case of tie consider total number of games played",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Players leaderboard",
      "createdAt": "2025-02-19T03:28:48.355Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67b7d619d24f993c6c899f46",
      "submissionId": {
        "_id": "67b7d619d24f993c6c899f44",
        "status": "approved",
        "adminComment": "Approved",
        "country": "United Kingdom",
        "ctc": "60L-70L",
        "companyName": "JPMorgan Chase",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740100842/bo5chgxnyapslzd3oac2.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Given an input string \"oneplustwominusonemultiply3\" convert it into \"1+2-1*3\" and also generare output of arthemetic operation \"3\" in o(n) time complexity",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740100927/bc2fqmie1bcnlidxjvsq.png"
      ],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Arithmetic operation",
      "createdAt": "2025-02-21T01:25:45.683Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67b7d619d24f993c6c899f47",
      "submissionId": {
        "_id": "67b7d619d24f993c6c899f44",
        "status": "approved",
        "adminComment": "Approved",
        "country": "United Kingdom",
        "ctc": "60L-70L",
        "companyName": "JPMorgan Chase",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740100842/bo5chgxnyapslzd3oac2.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "find the players in olympic table who has won only gold medal and not any other medal in sql ?",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740101060/j8yj0gkwsdbbel5xlz7a.png",
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740101061/aruvkhd7z9dy1tz2uujx.png"
      ],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Olympic players with gold medals",
      "createdAt": "2025-02-21T01:25:45.683Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67b7d619d24f993c6c899f48",
      "submissionId": {
        "_id": "67b7d619d24f993c6c899f44",
        "status": "approved",
        "adminComment": "Approved",
        "country": "United Kingdom",
        "ctc": "60L-70L",
        "companyName": "JPMorgan Chase",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740100842/bo5chgxnyapslzd3oac2.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "What are differnet spark optimization techniques used in your project and when would you decide which to use and how has it helped to improve the spark job performance",
      "images": [],
      "category": "project based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Spark optimizations",
      "createdAt": "2025-02-21T01:25:45.684Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67b7d8e2d24f993c6c899f50",
      "submissionId": {
        "_id": "67b7d8e2d24f993c6c899f4e",
        "status": "approved",
        "adminComment": "Approved",
        "country": "United Kingdom",
        "ctc": "60L-70L",
        "companyName": "Expedia",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740101417/chk1kspcfeapysejwcqk.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "Given an pair of array of string find the common prefix in all the strings and if the next character in string is same as matching character it should be in ouput\ninput : (\"sunnday\",\"sunden\") output : sunnd\ninput : (\"sunnday\",\"suneden\") output : sunn",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740101625/v2at9q1pvdxaj5bahaqb.png"
      ],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Common prefix in strings",
      "createdAt": "2025-02-21T01:37:38.277Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67b7d8e2d24f993c6c899f51",
      "submissionId": {
        "_id": "67b7d8e2d24f993c6c899f4e",
        "status": "approved",
        "adminComment": "Approved",
        "country": "United Kingdom",
        "ctc": "60L-70L",
        "companyName": "Expedia",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740101417/chk1kspcfeapysejwcqk.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "given an array of values find minimum subarray containing k unique values ?\ninput : arr = [2, 2, 1, 1,3,2 ] and k =3\noutput: Minimum subarray containing all unique values: [1, 3, 2]",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740101749/uvo4rzinilyg2fbio7v8.png"
      ],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Min subarray with unique values",
      "createdAt": "2025-02-21T01:37:38.278Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67b7d8e2d24f993c6c899f52",
      "submissionId": {
        "_id": "67b7d8e2d24f993c6c899f4e",
        "status": "approved",
        "adminComment": "Approved",
        "country": "United Kingdom",
        "ctc": "60L-70L",
        "companyName": "Expedia",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740101417/chk1kspcfeapysejwcqk.png"
        ],
        "yoe": "5-8",
        "role": "Senior Data Engineer"
      },
      "text": "explain adaptive query execution and what its befits and elaborate in detail in spark ?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Adaptive query execution",
      "createdAt": "2025-02-21T01:37:38.278Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67b81766d24f993c6c899fb1",
      "submissionId": {
        "_id": "67b81766d24f993c6c899fac",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Fractal",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740116934/d8rwid9q4tj0vdfptux4.jpg",
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740116936/trymu4ieztvqwlhjkvgo.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Spark and Databricks Interview Questions - Fractal Interview\n\n1. What is the difference between Spark's DataFrame and RDD? When should you use one over the other?\n2. Explain how Spark handles data shuffling. What are some ways to optimize shuffle performance?\n3. How does the Catalyst Optimizer improve query performance in Spark?\n4. In Databricks, how would you efficiently process a large dataset stored in Delta Lake with partitioning and Z-order indexing?\n5. How does Adaptive Query Execution (AQE) in Spark 3 improve query performance? Provide a real-world use case where AQE can be beneficial.\n",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740117784/uj0unh5z2vrdl1e8byks.png"
      ],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": "spark and databricks Theory ",
      "createdAt": "2025-02-21T06:04:22.631Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67b81766d24f993c6c899fb0",
      "submissionId": {
        "_id": "67b81766d24f993c6c899fac",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Fractal",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740116934/d8rwid9q4tj0vdfptux4.jpg",
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740116936/trymu4ieztvqwlhjkvgo.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "1. Your database contains millions of records, and a report query is running slowly. How would you optimize it?\n2. A banking application needs to track customer transactions in real-time. How would you design the SQL queries and database schema?\n3. You need to migrate a large table from one database to another without downtime. How would you approach it?\n4. In a retail database, how would you identify customers who havenâ€™t made a purchase in the last 12 months?\n5. How would you implement Slowly Changing Dimensions (SCD) in SQL for a data warehouse environment?\n",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740117700/dlcxu55n053gqwom1nwo.png"
      ],
      "category": "scenario based",
      "difficulty": "Hard",
      "isFree": true,
      "summary": " DE scenario",
      "createdAt": "2025-02-21T06:04:22.631Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67b81766d24f993c6c899fae",
      "submissionId": {
        "_id": "67b81766d24f993c6c899fac",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Fractal",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740116934/d8rwid9q4tj0vdfptux4.jpg",
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740116936/trymu4ieztvqwlhjkvgo.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Find the Second Highest Salary from an Employee Table.\n\nTable Creation:\n\nCREATE TABLE Employee (\n    id INT PRIMARY KEY,\n    name VARCHAR(50),\n    salary INT\n);\n\nSample Input Data:\n\nINSERT INTO Employee (id, name, salary) VALUES\n(1, 'Alice', 90000),\n(2, 'Bob', 85000),\n(3, 'Charlie', 87000),\n(4, 'David', 92000),\n(5, 'Eve', 95000);\n\n\nExpected Output:\n\n| Second_Highest_Salary  |\n|---------------------------|\n| 92000                            |         \n",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740117273/ecmoj17q4spnsmcxqsie.png"
      ],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": "Second highest salary ",
      "createdAt": "2025-02-21T06:04:22.631Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67b81766d24f993c6c899faf",
      "submissionId": {
        "_id": "67b81766d24f993c6c899fac",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "20L-30L",
        "companyName": "Fractal",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740116934/d8rwid9q4tj0vdfptux4.jpg",
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740116936/trymu4ieztvqwlhjkvgo.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Find Employees Who Earn More Than Their Manager\n\nCREATE TABLE Employee (\n    id INT PRIMARY KEY,\n    name VARCHAR(50),\n    salary INT,\n    manager_id INT\n);\n\nINSERT INTO Employee (id, name, salary, manager_id) VALUES\n(1, 'Alice', 90000, 3),\n(2, 'Bob', 85000, 3),\n(3, 'Charlie', 87000, NULL),\n(4, 'David', 95000, 3),\n(5, 'Eve', 98000, 4);\n\nExpected Output:\n\n| name  | salary |\n|-------|--------|\n| David | 95000  |\n| Eve   | 98000  |\n",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740117539/xrm3szn3vg2hi9qpdg1h.png"
      ],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Employees earn more than manager",
      "createdAt": "2025-02-21T06:04:22.631Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67b81d5fd24f993c6c899fba",
      "submissionId": {
        "_id": "67b81d5fd24f993c6c899fb7",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Wipro",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740117961/gvj272r3cbrn2wjqr5ra.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "1.What is normalization, and how do you perform normalization up to the 3rd Normal Form (3NF)?\n2.What is the difference between primary keys and foreign keys in relational databases?\n3. How would you design a database schema for an e-commerce system to store product, order, and customer information?",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740118278/xxrgmwrrdgpwnx3fnxdu.png"
      ],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " DE theory",
      "createdAt": "2025-02-21T06:29:51.369Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67b81d5fd24f993c6c899fbb",
      "submissionId": {
        "_id": "67b81d5fd24f993c6c899fb7",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Wipro",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740117961/gvj272r3cbrn2wjqr5ra.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "1.You are given a list (or array) of integers in Python, and you need to find the largest integer in that array.\n\nInput Data Creation \n\n#Python\n\ninteger_array = [10, 5, 20, 8, 25, 12]  \n\nExpected Output\nThe output should be 25.\n",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740118926/fhauob8vtcxh6efmjm39.png"
      ],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Largest number in array",
      "createdAt": "2025-02-21T06:29:51.369Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67b81d5fd24f993c6c899fb9",
      "submissionId": {
        "_id": "67b81d5fd24f993c6c899fb7",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Wipro",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740117961/gvj272r3cbrn2wjqr5ra.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "1.You need to process a massive log file in Hadoop, where each line represents a user interaction. How would you structure this job to run efficiently on a Hadoop cluster?\n2.Describe how the Hadoop Distributed File System (HDFS) handles data replication and fault tolerance ?\n3.You have a large dataset containing user data and their transactions. How would you process and analyze this dataset in Spark using Data Frames? What operations would you use?",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740118050/smq9oddvpqmwfcu6t32z.png"
      ],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " DE scenario",
      "createdAt": "2025-02-21T06:29:51.369Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67b81d5fd24f993c6c899fbc",
      "submissionId": {
        "_id": "67b81d5fd24f993c6c899fb7",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Wipro",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740117961/gvj272r3cbrn2wjqr5ra.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Find the Third Highest Salary from an Employee Table\n\nTable Creation:\nCREATE TABLE Employee (\n    id INT PRIMARY KEY,\n    name VARCHAR(50),\n    salary INT\n);\n\nSample Input Data:\n\nINSERT INTO Employee (id, name, salary) VALUES (1, 'Avani', 90000),\n(2, 'Rohan', 85000),(3, 'Chaitanya', 87000), (4, 'Dheeraj', 93000),(5, 'Eesha', 95000),\n(7, 'Gaurav', 80000),(9, 'Ishita', 75000),(10, 'Karan', 98000),(12, 'Liam', 70000);\n\nExpected Output:\n\nThird Highest Salary \n\n| Name  |  Salary                 |\n|----------------------------|\n| Dheeraj|     93000            | \n",
      "images": [
        "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740119350/etltdvbzmzgpzc34mt7r.png"
      ],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": "3rd highest salary",
      "createdAt": "2025-02-21T06:29:51.369Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67b85a6fd24f993c6c89a037",
      "submissionId": {
        "_id": "67b85a6fd24f993c6c89a035",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Neenopal",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740134353/geafjin7xtu031swccno.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Among AWS, Azure, and GCP, Which cloud platform will you suggest to the client for building scalable data pipelines and Why ?",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": "Cloud services ",
      "createdAt": "2025-02-21T10:50:23.329Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67b85a6fd24f993c6c89a039",
      "submissionId": {
        "_id": "67b85a6fd24f993c6c89a035",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Neenopal",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740134353/geafjin7xtu031swccno.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Write a query to find all the employees who draw more salary than their respective department's average salary\n\nId     Name          Dept ID   Dept Name   Salary\n1      Alex             02             Finance           20000\n2      Bob              01             Marketing      17500\n3     Carlson        02             Finance            28000\n4     David            03             HR                     15000\n5     Elizabeth     02             Finance            22000\n6     Felix              01             Marketing       30000\n7     Griffith         01             Marketing       26000\n8    Harley            03            HR                     19000\n9    Jaden            03             HR                     15000",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Employees drawing more salary",
      "createdAt": "2025-02-21T10:50:23.329Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67b85a6fd24f993c6c89a038",
      "submissionId": {
        "_id": "67b85a6fd24f993c6c89a035",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Neenopal",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740134353/geafjin7xtu031swccno.jpg"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Given the below data frame, create a new data frame to show the subjectwise score obtained by the students.\n\nId   Name          Marks\n1    Ajay              32|45|39\n2    Jay                36|50|43\n3    Rohit            42|40|48\n\n\nThe output should have following columns - Id, Name, Physics, Chemistry, Maths",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Student subject scores",
      "createdAt": "2025-02-21T10:50:23.329Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67be6994d24f993c6c89aa02",
      "submissionId": {
        "_id": "67be6994d24f993c6c89aa00",
        "status": "approved",
        "adminComment": "Approved",
        "country": "United States",
        "ctc": ">1cr",
        "companyName": "Walmart",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740531327/ecn0ybwqmhynjrjpujhs.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Word Search\n\nGiven an m x n grid of characters board and a string word, return true if word exists in the grid.\nThe word can be constructed from letters of sequentially adjacent cells, where adjacent cells are horizontally or vertically neighboring. The same letter cell may not be used more than once.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": false,
      "summary": " Character board string",
      "createdAt": "2025-02-26T01:08:36.347Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67be6994d24f993c6c89aa03",
      "submissionId": {
        "_id": "67be6994d24f993c6c89aa00",
        "status": "approved",
        "adminComment": "Approved",
        "country": "United States",
        "ctc": ">1cr",
        "companyName": "Walmart",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740531327/ecn0ybwqmhynjrjpujhs.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Valid Anagram\n\nGiven two strings s and t, return true if t is an anagram of s, and false otherwise.",
      "images": [],
      "category": "problem solving",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Valid anagram",
      "createdAt": "2025-02-26T01:08:36.347Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67be6994d24f993c6c89aa04",
      "submissionId": {
        "_id": "67be6994d24f993c6c89aa00",
        "status": "approved",
        "adminComment": "Approved",
        "country": "United States",
        "ctc": ">1cr",
        "companyName": "Walmart",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740531327/ecn0ybwqmhynjrjpujhs.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "What are decorators in python?",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Decorators in python",
      "createdAt": "2025-02-26T01:08:36.347Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67bf07ded24f993c6c89ab34",
      "submissionId": {
        "_id": "67bf07ded24f993c6c89ab32",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Impetus",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740572282/chcgtvbwzgeh5isnvr34.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Below is the sales data for different products over several months.\nWrite a Python Apache beam and perform below operation:\nLoad the data from a CSV file.\nDisplay the total sales for each product.\nFilter out products with total sales less than 500.\nDisplay the top 5 products with the highest sales.\n \n \nproduct,month,sales\nProduct A,2024-01,120 \nProduct B,2024-01,150\nProduct A,2024-02,200\nProduct C,2024-02,300\nProduct B,2024-02,400\nProduct A,2024-03,250\nProduct C,2024-03,350\nProduct B,2024-03,100\nProduct A,2024-04,180\nProduct C,2024-04,200\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Hard",
      "isFree": false,
      "summary": " Sales Product Data",
      "createdAt": "2025-02-26T12:23:58.968Z",
      "__v": 0,
      "isLocked": true
    },
    {
      "_id": "67bf07ded24f993c6c89ab35",
      "submissionId": {
        "_id": "67bf07ded24f993c6c89ab32",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Impetus",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740572282/chcgtvbwzgeh5isnvr34.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "what are sideinputs in apache beam",
      "images": [],
      "category": "theoretical",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " side inputs in apache beam",
      "createdAt": "2025-02-26T12:23:58.968Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67bf07ded24f993c6c89ab36",
      "submissionId": {
        "_id": "67bf07ded24f993c6c89ab32",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Impetus",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740572282/chcgtvbwzgeh5isnvr34.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "do you know about hive",
      "images": [],
      "category": "others",
      "difficulty": "Easy",
      "isFree": true,
      "summary": " Hive",
      "createdAt": "2025-02-26T12:23:58.968Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67bf07ded24f993c6c89ab37",
      "submissionId": {
        "_id": "67bf07ded24f993c6c89ab32",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Impetus",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740572282/chcgtvbwzgeh5isnvr34.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "explain about wildcards in bigquery",
      "images": [],
      "category": "theoretical",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " wildcards in bigquery",
      "createdAt": "2025-02-26T12:23:58.968Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67bf07ded24f993c6c89ab38",
      "submissionId": {
        "_id": "67bf07ded24f993c6c89ab32",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Impetus",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740572282/chcgtvbwzgeh5isnvr34.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "sql question on populationstatistics table\nwhere we have population and we have to partition by city into male and female population under age 30 in bq (table not provided) we have to assume the data (city,age,gender,population are given as columns)\n",
      "images": [],
      "category": "problem solving",
      "difficulty": "Medium",
      "isFree": true,
      "summary": " Population Statistics ",
      "createdAt": "2025-02-26T12:23:58.968Z",
      "__v": 0,
      "isLocked": false
    },
    {
      "_id": "67bf07ded24f993c6c89ab39",
      "submissionId": {
        "_id": "67bf07ded24f993c6c89ab32",
        "status": "approved",
        "adminComment": "Approved",
        "country": "India",
        "ctc": "10L-20L",
        "companyName": "Impetus",
        "verificationImages": [
          "https://res.cloudinary.com/du9dv6nb7/image/upload/v1740572282/chcgtvbwzgeh5isnvr34.png"
        ],
        "yoe": "2-5",
        "role": "Data Engineer-2"
      },
      "text": "Can we partition by string in bigquery?",
      "images": [],
      "category": "scenario based",
      "difficulty": "Medium",
      "isFree": true,
      "summary": "Parition by string ",
      "createdAt": "2025-02-26T12:23:58.968Z",
      "__v": 0,
      "isLocked": false
    }
  ]
}
